================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal sealed class Program(string[] args)
{
    private static readonly string DatabasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private readonly bool _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");
    internal static readonly string[] categoriesArray = ["Electronics", "Accessories", "Components", "Peripherals", "Software"];
    internal static readonly string[] adjectivesArray = ["Premium", "Budget", "Professional", "Gaming", "Wireless", "RGB", "Compact", "Ultra"];
    internal static readonly string[] productsArray = ["Laptop", "Monitor", "Keyboard", "Mouse", "Headset", "Webcam", "Microphone", "Cable"];

    static async Task<int> Main(string[] args)
    {
        var program = new Program(args);
        return await program.RunAsync();
    }

    private async Task<int> RunAsync()
    {
        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(DatabasePath))
            {
                Directory.CreateDirectory(DatabasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers
            services.AddInfrastructureServices(DatabasePath);
            services.AddApplicationServices();

            var serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync(serviceProvider);

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunAutomatedDemoAsync(serviceProvider);
            }
            else
            {
                await RunInteractiveDemoAsync(serviceProvider);
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    await using var context = factory.CreateDbContext(nodeId);

                    // Drop and recreate to ensure clean state
                    await context.Database.EnsureDeletedAsync();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(DatabasePath, $"{nodeId}.db")}";

                        var node = new DatabaseNode(
                            nodeId,
                            connectionString,
                            isPrimary ? 100 : 50,
                            isPrimary
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Database nodes initialized successfully![/]\n");
    }

    private static async Task RunInteractiveDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Interactive Demo[/]\n");

        // Create a few products
        AnsiConsole.MarkupLine("[yellow]Creating sample products...[/]");

        var products = new[]
        {
            ("Gaming Laptop", "High-performance gaming laptop with RTX 4090", 2499.99m, "Electronics"),
            ("Wireless Mouse", "Ergonomic wireless mouse", 49.99m, "Accessories"),
            ("Mechanical Keyboard", "RGB mechanical keyboard", 149.99m, "Accessories"),
        };

        foreach (var (name, desc, price, category) in products)
        {
            var cmd = new CreateProductCommand(name, desc, price, "USD", 100, category);
            var result = await createProductHandler.HandleAsync(cmd);

            if (result.IsSuccess)
            {
                AnsiConsole.MarkupLine($"  [green]âœ“[/] Created: {name}");
            }
        }

        // Display results
        AnsiConsole.MarkupLine("\n[bold underline]Product Catalog:[/]");
        await DisplayProductsAsync(getAllProductsHandler);
    }

    private static async Task RunAutomatedDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var updatePriceHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var deleteProductHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Automated CI/CD Demo - High Volume Data Operations[/]\n");

        var random = new Random(42); // Fixed seed for reproducibility

        // Phase 1: Bulk Product Creation
        await AnsiConsole.Progress()
            .AutoClear(false)
            .Columns(
                new TaskDescriptionColumn(),
                new ProgressBarColumn(),
                new PercentageColumn(),
                new RemainingTimeColumn(),
                new SpinnerColumn())
            .StartAsync(async ctx =>
            {
                var categories = categoriesArray;
                var adjectives = adjectivesArray;
                var products = productsArray;

                var createTask = ctx.AddTask("[yellow]Creating 100 products[/]", maxValue: 100);

                for (int i = 0; i < 1_000; i++)
                {
                    var adjective = adjectives[random.Next(adjectives.Length)];
                    var product = products[random.Next(products.Length)];
                    var category = categories[random.Next(categories.Length)];
                    var name = $"{adjective} {product} {i + 1}";
                    var price = Math.Round((decimal)(random.NextDouble() * 2000 + 10), 2);
                    var stock = random.Next(0, 500);

                    var cmd = new CreateProductCommand(
                        name,
                        $"High-quality {product.ToLower()} for professional use",
                        price,
                        "USD",
                        stock,
                        category
                    );

                    await createProductHandler.HandleAsync(cmd);
                    createTask.Increment(1);
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Created 100 products[/]\n");

        // Phase 2: Statistics
        var productsResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

        if (productsResult.IsSuccess && productsResult.Data is not null)
        {
            var allProducts = productsResult.Data;

            var statsTable = new Table()
                .Border(TableBorder.Rounded)
                .BorderColor(Color.Grey);

            statsTable.AddColumn(new TableColumn("[bold]Metric[/]").Centered());
            statsTable.AddColumn(new TableColumn("[bold]Value[/]").Centered());

            statsTable.AddRow("Total Products", $"[cyan]{allProducts.Count}[/]");
            statsTable.AddRow("Total Stock Units", $"[cyan]{allProducts.Sum(p => p.StockQuantity):N0}[/]");
            statsTable.AddRow("Avg Price", $"[green]${allProducts.Average(p => p.Price.Amount):N2}[/]");
            statsTable.AddRow("Total Inventory Value", $"[green]${allProducts.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]");
            statsTable.AddRow("Categories", $"[yellow]{allProducts.Select(p => p.Category).Distinct().Count()}[/]");

            AnsiConsole.Write(
                new Panel(statsTable)
                    .Header("[bold cyan1]Database Statistics[/]")
                    .BorderColor(Color.Cyan1)
            );

            // Category breakdown
            AnsiConsole.MarkupLine("\n[bold underline]Products by Category:[/]");
            var categoryTable = new Table();
            categoryTable.AddColumn("Category");
            categoryTable.AddColumn("Count");
            categoryTable.AddColumn("Total Value");
            categoryTable.AddColumn("Avg Stock");

            var byCategory = allProducts
                .GroupBy(p => p.Category)
                .OrderByDescending(g => g.Count());

            foreach (var group in byCategory)
            {
                categoryTable.AddRow(
                    group.Key,
                    $"[cyan]{group.Count()}[/]",
                    $"[green]${group.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]",
                    $"{group.Average(p => p.StockQuantity):N0}"
                );
            }

            AnsiConsole.Write(categoryTable);

            // Phase 3: Bulk Updates
            AnsiConsole.MarkupLine("\n[bold yellow]Phase 3: Performing bulk stock updates...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var updateTask = ctx.AddTask("[yellow]Updating stock levels[/]", maxValue: 50);

                    foreach (var product in allProducts.Take(50))
                    {
                        var newStock = random.Next(50, 200);
                        var updateCmd = new UpdateProductStockCommand(product.Id, newStock);
                        await updateStockHandler.HandleAsync(updateCmd);
                        updateTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 50 product stock levels[/]\n");

            // Phase 4: Price adjustments
            AnsiConsole.MarkupLine("[bold yellow]Phase 4: Adjusting prices...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var priceTask = ctx.AddTask("[yellow]Applying price changes[/]", maxValue: 30);

                    foreach (var product in allProducts.Take(30))
                    {
                        var newPrice = Math.Round(product.Price.Amount * (decimal)(random.NextDouble() * 0.4 + 0.8), 2);
                        var updateCmd = new UpdateProductPriceCommand(product.Id, newPrice, "USD");
                        await updatePriceHandler.HandleAsync(updateCmd);
                        priceTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 30 product prices[/]\n");

            // Phase 5: Sample deletions
            AnsiConsole.MarkupLine("[bold yellow]Phase 5: Removing discontinued products...[/]");

            var toDelete = allProducts
                .Where(p => p.StockQuantity == 0)
                .Take(5)
                .ToList();

            foreach (var product in toDelete)
            {
                var deleteCmd = new DeleteProductCommand(product.Id);
                await deleteProductHandler.HandleAsync(deleteCmd);
            }

            AnsiConsole.MarkupLine($"[green]âœ“ Removed {toDelete.Count} discontinued products[/]\n");

            // Final Statistics
            var finalResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

            if (finalResult.IsSuccess && finalResult.Data is not null)
            {
                var finalProducts = finalResult.Data;

                var comparison = new Table()
                    .Border(TableBorder.Rounded)
                    .BorderColor(Color.Green);

                comparison.AddColumn("[bold]Metric[/]");
                comparison.AddColumn("[bold]Before[/]");
                comparison.AddColumn("[bold]After[/]");
                comparison.AddColumn("[bold]Change[/]");

                comparison.AddRow(
                    "Total Products",
                    $"{allProducts.Count}",
                    $"[cyan]{finalProducts.Count}[/]",
                    $"[red]{finalProducts.Count - allProducts.Count:+0;-#}[/]"
                );

                comparison.AddRow(
                    "Total Stock",
                    $"{allProducts.Sum(p => p.StockQuantity):N0}",
                    $"[cyan]{finalProducts.Sum(p => p.StockQuantity):N0}[/]",
                    $"[green]{finalProducts.Sum(p => p.StockQuantity) - allProducts.Sum(p => p.StockQuantity):+#,0;-#,0}[/]"
                );

                AnsiConsole.Write(
                    new Panel(comparison)
                        .Header("[bold green]Before & After Comparison[/]")
                        .BorderColor(Color.Green)
                );
            }

            // Sample data display
            AnsiConsole.MarkupLine("\n[bold underline]Sample Products (Top 10 by Value):[/]");
            var sampleTable = new Table();
            sampleTable.AddColumn("Name");
            sampleTable.AddColumn("Category");
            sampleTable.AddColumn("Price");
            sampleTable.AddColumn("Stock");
            sampleTable.AddColumn("Value");

            foreach (var p in finalResult.Data!.OrderByDescending(p => p.Price.Amount * p.StockQuantity).Take(10))
            {
                sampleTable.AddRow(
                    p.Name.Length > 30 ? p.Name[..27] + "..." : p.Name,
                    p.Category,
                    $"${p.Price.Amount:N2}",
                    p.StockQuantity.ToString(),
                    $"[green]${p.Price.Amount * p.StockQuantity:N2}[/]"
                );
            }

            AnsiConsole.Write(sampleTable);
        }

        AnsiConsole.MarkupLine("\n[bold green]âœ“ Automated demo completed successfully![/]");
        AnsiConsole.MarkupLine("[dim]All operations logged and synchronized across nodes.[/]");
    }

    private static async Task DisplayProductsAsync(GetAllProductsQueryHandler handler)
    {
        var result = await handler.HandleAsync(new GetAllProductsQuery());

        if (result.IsSuccess && result.Data is not null)
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Category");
            table.AddColumn("Price");
            table.AddColumn("Stock");

            foreach (var p in result.Data)
            {
                table.AddRow(
                    p.Name,
                    p.Category,
                    $"${p.Price.Amount} {p.Price.Currency}",
                    p.StockQuantity.ToString()
                );
            }

            AnsiConsole.Write(table);
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed to get products:[/] {result.ErrorMessage}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": "--ci"
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = [];
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory(string databasePath)
{
    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = [];
    private readonly Dictionary<Guid, DateTime> _voteTimers = [];
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal sealed class Program(string[] args)
{
    private static readonly string DatabasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private readonly bool _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");
    internal static readonly string[] categoriesArray = ["Electronics", "Accessories", "Components", "Peripherals", "Software"];
    internal static readonly string[] adjectivesArray = ["Premium", "Budget", "Professional", "Gaming", "Wireless", "RGB", "Compact", "Ultra"];
    internal static readonly string[] productsArray = ["Laptop", "Monitor", "Keyboard", "Mouse", "Headset", "Webcam", "Microphone", "Cable"];

    static async Task<int> Main(string[] args)
    {
        var program = new Program(args);
        return await program.RunAsync();
    }

    private async Task<int> RunAsync()
    {
        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(DatabasePath))
            {
                Directory.CreateDirectory(DatabasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers
            services.AddInfrastructureServices(DatabasePath);
            services.AddApplicationServices();

            var serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync(serviceProvider);

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunAutomatedDemoAsync(serviceProvider);
            }
            else
            {
                await RunInteractiveDemoAsync(serviceProvider);
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    await using var context = factory.CreateDbContext(nodeId);

                    // Drop and recreate to ensure clean state
                    await context.Database.EnsureDeletedAsync();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(DatabasePath, $"{nodeId}.db")}";

                        var node = new DatabaseNode(
                            nodeId,
                            connectionString,
                            isPrimary ? 100 : 50,
                            isPrimary
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Database nodes initialized successfully![/]\n");
    }

    private static async Task RunInteractiveDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Interactive Demo[/]\n");

        // Create a few products
        AnsiConsole.MarkupLine("[yellow]Creating sample products...[/]");

        var products = new[]
        {
            ("Gaming Laptop", "High-performance gaming laptop with RTX 4090", 2499.99m, "Electronics"),
            ("Wireless Mouse", "Ergonomic wireless mouse", 49.99m, "Accessories"),
            ("Mechanical Keyboard", "RGB mechanical keyboard", 149.99m, "Accessories"),
        };

        foreach (var (name, desc, price, category) in products)
        {
            var cmd = new CreateProductCommand(name, desc, price, "USD", 100, category);
            var result = await createProductHandler.HandleAsync(cmd);

            if (result.IsSuccess)
            {
                AnsiConsole.MarkupLine($"  [green]âœ“[/] Created: {name}");
            }
        }

        // Display results
        AnsiConsole.MarkupLine("\n[bold underline]Product Catalog:[/]");
        await DisplayProductsAsync(getAllProductsHandler);
    }

    private static async Task RunAutomatedDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var updatePriceHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var deleteProductHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Automated CI/CD Demo - High Volume Data Operations[/]\n");

        var random = new Random(42); // Fixed seed for reproducibility

        // Phase 1: Bulk Product Creation
        await AnsiConsole.Progress()
            .AutoClear(false)
            .Columns(
                new TaskDescriptionColumn(),
                new ProgressBarColumn(),
                new PercentageColumn(),
                new RemainingTimeColumn(),
                new SpinnerColumn())
            .StartAsync(async ctx =>
            {
                var categories = categoriesArray;
                var adjectives = adjectivesArray;
                var products = productsArray;

                var createTask = ctx.AddTask("[yellow]Creating 100 products[/]", maxValue: 100);

                for (int i = 0; i < 1_000; i++)
                {
                    var adjective = adjectives[random.Next(adjectives.Length)];
                    var product = products[random.Next(products.Length)];
                    var category = categories[random.Next(categories.Length)];
                    var name = $"{adjective} {product} {i + 1}";
                    var price = Math.Round((decimal)(random.NextDouble() * 2000 + 10), 2);
                    var stock = random.Next(0, 500);

                    var cmd = new CreateProductCommand(
                        name,
                        $"High-quality {product.ToLower()} for professional use",
                        price,
                        "USD",
                        stock,
                        category
                    );

                    await createProductHandler.HandleAsync(cmd);
                    createTask.Increment(1);
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Created 100 products[/]\n");

        // Phase 2: Statistics
        var productsResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

        if (productsResult.IsSuccess && productsResult.Data is not null)
        {
            var allProducts = productsResult.Data;

            var statsTable = new Table()
                .Border(TableBorder.Rounded)
                .BorderColor(Color.Grey);

            statsTable.AddColumn(new TableColumn("[bold]Metric[/]").Centered());
            statsTable.AddColumn(new TableColumn("[bold]Value[/]").Centered());

            statsTable.AddRow("Total Products", $"[cyan]{allProducts.Count}[/]");
            statsTable.AddRow("Total Stock Units", $"[cyan]{allProducts.Sum(p => p.StockQuantity):N0}[/]");
            statsTable.AddRow("Avg Price", $"[green]${allProducts.Average(p => p.Price.Amount):N2}[/]");
            statsTable.AddRow("Total Inventory Value", $"[green]${allProducts.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]");
            statsTable.AddRow("Categories", $"[yellow]{allProducts.Select(p => p.Category).Distinct().Count()}[/]");

            AnsiConsole.Write(
                new Panel(statsTable)
                    .Header("[bold cyan1]Database Statistics[/]")
                    .BorderColor(Color.Cyan1)
            );

            // Category breakdown
            AnsiConsole.MarkupLine("\n[bold underline]Products by Category:[/]");
            var categoryTable = new Table();
            categoryTable.AddColumn("Category");
            categoryTable.AddColumn("Count");
            categoryTable.AddColumn("Total Value");
            categoryTable.AddColumn("Avg Stock");

            var byCategory = allProducts
                .GroupBy(p => p.Category)
                .OrderByDescending(g => g.Count());

            foreach (var group in byCategory)
            {
                categoryTable.AddRow(
                    group.Key,
                    $"[cyan]{group.Count()}[/]",
                    $"[green]${group.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]",
                    $"{group.Average(p => p.StockQuantity):N0}"
                );
            }

            AnsiConsole.Write(categoryTable);

            // Phase 3: Bulk Updates
            AnsiConsole.MarkupLine("\n[bold yellow]Phase 3: Performing bulk stock updates...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var updateTask = ctx.AddTask("[yellow]Updating stock levels[/]", maxValue: 50);

                    foreach (var product in allProducts.Take(50))
                    {
                        var newStock = random.Next(50, 200);
                        var updateCmd = new UpdateProductStockCommand(product.Id, newStock);
                        await updateStockHandler.HandleAsync(updateCmd);
                        updateTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 50 product stock levels[/]\n");

            // Phase 4: Price adjustments
            AnsiConsole.MarkupLine("[bold yellow]Phase 4: Adjusting prices...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var priceTask = ctx.AddTask("[yellow]Applying price changes[/]", maxValue: 30);

                    foreach (var product in allProducts.Take(30))
                    {
                        var newPrice = Math.Round(product.Price.Amount * (decimal)(random.NextDouble() * 0.4 + 0.8), 2);
                        var updateCmd = new UpdateProductPriceCommand(product.Id, newPrice, "USD");
                        await updatePriceHandler.HandleAsync(updateCmd);
                        priceTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 30 product prices[/]\n");

            // Phase 5: Sample deletions
            AnsiConsole.MarkupLine("[bold yellow]Phase 5: Removing discontinued products...[/]");

            var toDelete = allProducts
                .Where(p => p.StockQuantity == 0)
                .Take(5)
                .ToList();

            foreach (var product in toDelete)
            {
                var deleteCmd = new DeleteProductCommand(product.Id);
                await deleteProductHandler.HandleAsync(deleteCmd);
            }

            AnsiConsole.MarkupLine($"[green]âœ“ Removed {toDelete.Count} discontinued products[/]\n");

            // Final Statistics
            var finalResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

            if (finalResult.IsSuccess && finalResult.Data is not null)
            {
                var finalProducts = finalResult.Data;

                var comparison = new Table()
                    .Border(TableBorder.Rounded)
                    .BorderColor(Color.Green);

                comparison.AddColumn("[bold]Metric[/]");
                comparison.AddColumn("[bold]Before[/]");
                comparison.AddColumn("[bold]After[/]");
                comparison.AddColumn("[bold]Change[/]");

                comparison.AddRow(
                    "Total Products",
                    $"{allProducts.Count}",
                    $"[cyan]{finalProducts.Count}[/]",
                    $"[red]{finalProducts.Count - allProducts.Count:+0;-#}[/]"
                );

                comparison.AddRow(
                    "Total Stock",
                    $"{allProducts.Sum(p => p.StockQuantity):N0}",
                    $"[cyan]{finalProducts.Sum(p => p.StockQuantity):N0}[/]",
                    $"[green]{finalProducts.Sum(p => p.StockQuantity) - allProducts.Sum(p => p.StockQuantity):+#,0;-#,0}[/]"
                );

                AnsiConsole.Write(
                    new Panel(comparison)
                        .Header("[bold green]Before & After Comparison[/]")
                        .BorderColor(Color.Green)
                );
            }

            // Sample data display
            AnsiConsole.MarkupLine("\n[bold underline]Sample Products (Top 10 by Value):[/]");
            var sampleTable = new Table();
            sampleTable.AddColumn("Name");
            sampleTable.AddColumn("Category");
            sampleTable.AddColumn("Price");
            sampleTable.AddColumn("Stock");
            sampleTable.AddColumn("Value");

            foreach (var p in finalResult.Data!.OrderByDescending(p => p.Price.Amount * p.StockQuantity).Take(10))
            {
                sampleTable.AddRow(
                    p.Name.Length > 30 ? p.Name[..27] + "..." : p.Name,
                    p.Category,
                    $"${p.Price.Amount:N2}",
                    p.StockQuantity.ToString(),
                    $"[green]${p.Price.Amount * p.StockQuantity:N2}[/]"
                );
            }

            AnsiConsole.Write(sampleTable);
        }

        AnsiConsole.MarkupLine("\n[bold green]âœ“ Automated demo completed successfully![/]");
        AnsiConsole.MarkupLine("[dim]All operations logged and synchronized across nodes.[/]");
    }

    private static async Task DisplayProductsAsync(GetAllProductsQueryHandler handler)
    {
        var result = await handler.HandleAsync(new GetAllProductsQuery());

        if (result.IsSuccess && result.Data is not null)
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Category");
            table.AddColumn("Price");
            table.AddColumn("Stock");

            foreach (var p in result.Data)
            {
                table.AddRow(
                    p.Name,
                    p.Category,
                    $"${p.Price.Amount} {p.Price.Currency}",
                    p.StockQuantity.ToString()
                );
            }

            AnsiConsole.Write(table);
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed to get products:[/] {result.ErrorMessage}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": "--ci"
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = [];
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory(string databasePath)
{
    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = [];
    private readonly Dictionary<Guid, DateTime> _voteTimers = [];
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal sealed class Program(string[] args)
{
    private static readonly string DatabasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private readonly bool _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");
    internal static readonly string[] categoriesArray = ["Electronics", "Accessories", "Components", "Peripherals", "Software"];
    internal static readonly string[] adjectivesArray = ["Premium", "Budget", "Professional", "Gaming", "Wireless", "RGB", "Compact", "Ultra"];
    internal static readonly string[] productsArray = ["Laptop", "Monitor", "Keyboard", "Mouse", "Headset", "Webcam", "Microphone", "Cable"];

    static async Task<int> Main(string[] args)
    {
        var program = new Program(args);
        return await program.RunAsync();
    }

    private async Task<int> RunAsync()
    {
        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(DatabasePath))
            {
                Directory.CreateDirectory(DatabasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers
            services.AddInfrastructureServices(DatabasePath);
            services.AddApplicationServices();

            var serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync(serviceProvider);

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunAutomatedDemoAsync(serviceProvider);
            }
            else
            {
                await RunInteractiveDemoAsync(serviceProvider);
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    await using var context = factory.CreateDbContext(nodeId);

                    // Drop and recreate to ensure clean state
                    await context.Database.EnsureDeletedAsync();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(DatabasePath, $"{nodeId}.db")}";

                        var node = new DatabaseNode(
                            nodeId,
                            connectionString,
                            isPrimary ? 100 : 50,
                            isPrimary
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Database nodes initialized successfully![/]\n");
    }

    private static async Task RunInteractiveDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Interactive Demo[/]\n");

        // Create a few products
        AnsiConsole.MarkupLine("[yellow]Creating sample products...[/]");

        var products = new[]
        {
            ("Gaming Laptop", "High-performance gaming laptop with RTX 4090", 2499.99m, "Electronics"),
            ("Wireless Mouse", "Ergonomic wireless mouse", 49.99m, "Accessories"),
            ("Mechanical Keyboard", "RGB mechanical keyboard", 149.99m, "Accessories"),
        };

        foreach (var (name, desc, price, category) in products)
        {
            var cmd = new CreateProductCommand(name, desc, price, "USD", 100, category);
            var result = await createProductHandler.HandleAsync(cmd);

            if (result.IsSuccess)
            {
                AnsiConsole.MarkupLine($"  [green]âœ“[/] Created: {name}");
            }
        }

        // Display results
        AnsiConsole.MarkupLine("\n[bold underline]Product Catalog:[/]");
        await DisplayProductsAsync(getAllProductsHandler);
    }

    private static async Task RunAutomatedDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var updatePriceHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var deleteProductHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Automated CI/CD Demo - High Volume Data Operations[/]\n");

        var random = new Random(42); // Fixed seed for reproducibility

        // Phase 1: Bulk Product Creation
        await AnsiConsole.Progress()
            .AutoClear(false)
            .Columns(
                new TaskDescriptionColumn(),
                new ProgressBarColumn(),
                new PercentageColumn(),
                new RemainingTimeColumn(),
                new SpinnerColumn())
            .StartAsync(async ctx =>
            {
                var categories = categoriesArray;
                var adjectives = adjectivesArray;
                var products = productsArray;

                var createTask = ctx.AddTask("[yellow]Creating 100 products[/]", maxValue: 100);

                for (int i = 0; i < 100; i++)
                {
                    var adjective = adjectives[random.Next(adjectives.Length)];
                    var product = products[random.Next(products.Length)];
                    var category = categories[random.Next(categories.Length)];
                    var name = $"{adjective} {product} {i + 1}";
                    var price = Math.Round((decimal)(random.NextDouble() * 2000 + 10), 2);
                    var stock = random.Next(0, 500);

                    var cmd = new CreateProductCommand(
                        name,
                        $"High-quality {product.ToLower()} for professional use",
                        price,
                        "USD",
                        stock,
                        category
                    );

                    await createProductHandler.HandleAsync(cmd);
                    createTask.Increment(1);
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Created 100 products[/]\n");

        // Phase 2: Statistics
        var productsResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

        if (productsResult.IsSuccess && productsResult.Data is not null)
        {
            var allProducts = productsResult.Data;

            var statsTable = new Table()
                .Border(TableBorder.Rounded)
                .BorderColor(Color.Grey);

            statsTable.AddColumn(new TableColumn("[bold]Metric[/]").Centered());
            statsTable.AddColumn(new TableColumn("[bold]Value[/]").Centered());

            statsTable.AddRow("Total Products", $"[cyan]{allProducts.Count}[/]");
            statsTable.AddRow("Total Stock Units", $"[cyan]{allProducts.Sum(p => p.StockQuantity):N0}[/]");
            statsTable.AddRow("Avg Price", $"[green]${allProducts.Average(p => p.Price.Amount):N2}[/]");
            statsTable.AddRow("Total Inventory Value", $"[green]${allProducts.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]");
            statsTable.AddRow("Categories", $"[yellow]{allProducts.Select(p => p.Category).Distinct().Count()}[/]");

            AnsiConsole.Write(
                new Panel(statsTable)
                    .Header("[bold cyan1]Database Statistics[/]")
                    .BorderColor(Color.Cyan1)
            );

            // Category breakdown
            AnsiConsole.MarkupLine("\n[bold underline]Products by Category:[/]");
            var categoryTable = new Table();
            categoryTable.AddColumn("Category");
            categoryTable.AddColumn("Count");
            categoryTable.AddColumn("Total Value");
            categoryTable.AddColumn("Avg Stock");

            var byCategory = allProducts
                .GroupBy(p => p.Category)
                .OrderByDescending(g => g.Count());

            foreach (var group in byCategory)
            {
                categoryTable.AddRow(
                    group.Key,
                    $"[cyan]{group.Count()}[/]",
                    $"[green]${group.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]",
                    $"{group.Average(p => p.StockQuantity):N0}"
                );
            }

            AnsiConsole.Write(categoryTable);

            // Phase 3: Bulk Updates
            AnsiConsole.MarkupLine("\n[bold yellow]Phase 3: Performing bulk stock updates...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var updateTask = ctx.AddTask("[yellow]Updating stock levels[/]", maxValue: 50);

                    foreach (var product in allProducts.Take(50))
                    {
                        var newStock = random.Next(50, 200);
                        var updateCmd = new UpdateProductStockCommand(product.Id, newStock);
                        await updateStockHandler.HandleAsync(updateCmd);
                        updateTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 50 product stock levels[/]\n");

            // Phase 4: Price adjustments
            AnsiConsole.MarkupLine("[bold yellow]Phase 4: Adjusting prices...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var priceTask = ctx.AddTask("[yellow]Applying price changes[/]", maxValue: 30);

                    foreach (var product in allProducts.Take(30))
                    {
                        var newPrice = Math.Round(product.Price.Amount * (decimal)(random.NextDouble() * 0.4 + 0.8), 2);
                        var updateCmd = new UpdateProductPriceCommand(product.Id, newPrice, "USD");
                        await updatePriceHandler.HandleAsync(updateCmd);
                        priceTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 30 product prices[/]\n");

            // Phase 5: Sample deletions
            AnsiConsole.MarkupLine("[bold yellow]Phase 5: Removing discontinued products...[/]");

            var toDelete = allProducts
                .Where(p => p.StockQuantity == 0)
                .Take(5)
                .ToList();

            foreach (var product in toDelete)
            {
                var deleteCmd = new DeleteProductCommand(product.Id);
                await deleteProductHandler.HandleAsync(deleteCmd);
            }

            AnsiConsole.MarkupLine($"[green]âœ“ Removed {toDelete.Count} discontinued products[/]\n");

            // Final Statistics
            var finalResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

            if (finalResult.IsSuccess && finalResult.Data is not null)
            {
                var finalProducts = finalResult.Data;

                var comparison = new Table()
                    .Border(TableBorder.Rounded)
                    .BorderColor(Color.Green);

                comparison.AddColumn("[bold]Metric[/]");
                comparison.AddColumn("[bold]Before[/]");
                comparison.AddColumn("[bold]After[/]");
                comparison.AddColumn("[bold]Change[/]");

                comparison.AddRow(
                    "Total Products",
                    $"{allProducts.Count}",
                    $"[cyan]{finalProducts.Count}[/]",
                    $"[red]{finalProducts.Count - allProducts.Count:+0;-#}[/]"
                );

                comparison.AddRow(
                    "Total Stock",
                    $"{allProducts.Sum(p => p.StockQuantity):N0}",
                    $"[cyan]{finalProducts.Sum(p => p.StockQuantity):N0}[/]",
                    $"[green]{finalProducts.Sum(p => p.StockQuantity) - allProducts.Sum(p => p.StockQuantity):+#,0;-#,0}[/]"
                );

                AnsiConsole.Write(
                    new Panel(comparison)
                        .Header("[bold green]Before & After Comparison[/]")
                        .BorderColor(Color.Green)
                );
            }

            // Sample data display
            AnsiConsole.MarkupLine("\n[bold underline]Sample Products (Top 10 by Value):[/]");
            var sampleTable = new Table();
            sampleTable.AddColumn("Name");
            sampleTable.AddColumn("Category");
            sampleTable.AddColumn("Price");
            sampleTable.AddColumn("Stock");
            sampleTable.AddColumn("Value");

            foreach (var p in finalResult.Data!.OrderByDescending(p => p.Price.Amount * p.StockQuantity).Take(10))
            {
                sampleTable.AddRow(
                    p.Name.Length > 30 ? p.Name[..27] + "..." : p.Name,
                    p.Category,
                    $"${p.Price.Amount:N2}",
                    p.StockQuantity.ToString(),
                    $"[green]${p.Price.Amount * p.StockQuantity:N2}[/]"
                );
            }

            AnsiConsole.Write(sampleTable);
        }

        AnsiConsole.MarkupLine("\n[bold green]âœ“ Automated demo completed successfully![/]");
        AnsiConsole.MarkupLine("[dim]All operations logged and synchronized across nodes.[/]");
    }

    private static async Task DisplayProductsAsync(GetAllProductsQueryHandler handler)
    {
        var result = await handler.HandleAsync(new GetAllProductsQuery());

        if (result.IsSuccess && result.Data is not null)
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Category");
            table.AddColumn("Price");
            table.AddColumn("Stock");

            foreach (var p in result.Data)
            {
                table.AddRow(
                    p.Name,
                    p.Category,
                    $"${p.Price.Amount} {p.Price.Currency}",
                    p.StockQuantity.ToString()
                );
            }

            AnsiConsole.Write(table);
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed to get products:[/] {result.ErrorMessage}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": ""
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = [];
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory(string databasePath)
{
    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = [];
    private readonly Dictionary<Guid, DateTime> _voteTimers = [];
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal sealed class Program(string[] args)
{
    private static readonly string DatabasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private readonly bool _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");

    static async Task<int> Main(string[] args)
    {
        var program = new Program(args);
        return await program.RunAsync();
    }

    private async Task<int> RunAsync()
    {
        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(DatabasePath))
            {
                Directory.CreateDirectory(DatabasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers
            services.AddInfrastructureServices(DatabasePath);
            services.AddApplicationServices();

            var serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync(serviceProvider);

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunAutomatedDemoAsync(serviceProvider);
            }
            else
            {
                await RunInteractiveDemoAsync(serviceProvider);
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    await using var context = factory.CreateDbContext(nodeId);

                    // Drop and recreate to ensure clean state
                    await context.Database.EnsureDeletedAsync();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(DatabasePath, $"{nodeId}.db")}";

                        var node = new DatabaseNode(
                            nodeId,
                            connectionString,
                            isPrimary ? 100 : 50,
                            isPrimary
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Database nodes initialized successfully![/]\n");
    }

    private async Task RunInteractiveDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Interactive Demo[/]\n");

        // Create a few products
        AnsiConsole.MarkupLine("[yellow]Creating sample products...[/]");

        var products = new[]
        {
            ("Gaming Laptop", "High-performance gaming laptop with RTX 4090", 2499.99m, "Electronics"),
            ("Wireless Mouse", "Ergonomic wireless mouse", 49.99m, "Accessories"),
            ("Mechanical Keyboard", "RGB mechanical keyboard", 149.99m, "Accessories"),
        };

        foreach (var (name, desc, price, category) in products)
        {
            var cmd = new CreateProductCommand(name, desc, price, "USD", 100, category);
            var result = await createProductHandler.HandleAsync(cmd);

            if (result.IsSuccess)
            {
                AnsiConsole.MarkupLine($"  [green]âœ“[/] Created: {name}");
            }
        }

        // Display results
        AnsiConsole.MarkupLine("\n[bold underline]Product Catalog:[/]");
        await DisplayProductsAsync(getAllProductsHandler);
    }

    private async Task RunAutomatedDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var updatePriceHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var deleteProductHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[bold underline cyan1]Automated CI/CD Demo - High Volume Data Operations[/]\n");

        var random = new Random(42); // Fixed seed for reproducibility

        // Phase 1: Bulk Product Creation
        await AnsiConsole.Progress()
            .AutoClear(false)
            .Columns(
                new TaskDescriptionColumn(),
                new ProgressBarColumn(),
                new PercentageColumn(),
                new RemainingTimeColumn(),
                new SpinnerColumn())
            .StartAsync(async ctx =>
            {
                var categories = new[] { "Electronics", "Accessories", "Components", "Peripherals", "Software" };
                var adjectives = new[] { "Premium", "Budget", "Professional", "Gaming", "Wireless", "RGB", "Compact", "Ultra" };
                var products = new[] { "Laptop", "Monitor", "Keyboard", "Mouse", "Headset", "Webcam", "Microphone", "Cable" };

                var createTask = ctx.AddTask("[yellow]Creating 100 products[/]", maxValue: 100);

                for (int i = 0; i < 100; i++)
                {
                    var adjective = adjectives[random.Next(adjectives.Length)];
                    var product = products[random.Next(products.Length)];
                    var category = categories[random.Next(categories.Length)];
                    var name = $"{adjective} {product} {i + 1}";
                    var price = Math.Round((decimal)(random.NextDouble() * 2000 + 10), 2);
                    var stock = random.Next(0, 500);

                    var cmd = new CreateProductCommand(
                        name,
                        $"High-quality {product.ToLower()} for professional use",
                        price,
                        "USD",
                        stock,
                        category
                    );

                    await createProductHandler.HandleAsync(cmd);
                    createTask.Increment(1);
                }
            });

        AnsiConsole.MarkupLine("[green]âœ“ Created 100 products[/]\n");

        // Phase 2: Statistics
        var productsResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

        if (productsResult.IsSuccess && productsResult.Data is not null)
        {
            var allProducts = productsResult.Data;

            var statsTable = new Table()
                .Border(TableBorder.Rounded)
                .BorderColor(Color.Grey);

            statsTable.AddColumn(new TableColumn("[bold]Metric[/]").Centered());
            statsTable.AddColumn(new TableColumn("[bold]Value[/]").Centered());

            statsTable.AddRow("Total Products", $"[cyan]{allProducts.Count}[/]");
            statsTable.AddRow("Total Stock Units", $"[cyan]{allProducts.Sum(p => p.StockQuantity):N0}[/]");
            statsTable.AddRow("Avg Price", $"[green]${allProducts.Average(p => p.Price.Amount):N2}[/]");
            statsTable.AddRow("Total Inventory Value", $"[green]${allProducts.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]");
            statsTable.AddRow("Categories", $"[yellow]{allProducts.Select(p => p.Category).Distinct().Count()}[/]");

            AnsiConsole.Write(
                new Panel(statsTable)
                    .Header("[bold cyan1]Database Statistics[/]")
                    .BorderColor(Color.Cyan1)
            );

            // Category breakdown
            AnsiConsole.MarkupLine("\n[bold underline]Products by Category:[/]");
            var categoryTable = new Table();
            categoryTable.AddColumn("Category");
            categoryTable.AddColumn("Count");
            categoryTable.AddColumn("Total Value");
            categoryTable.AddColumn("Avg Stock");

            var byCategory = allProducts
                .GroupBy(p => p.Category)
                .OrderByDescending(g => g.Count());

            foreach (var group in byCategory)
            {
                categoryTable.AddRow(
                    group.Key,
                    $"[cyan]{group.Count()}[/]",
                    $"[green]${group.Sum(p => p.Price.Amount * p.StockQuantity):N2}[/]",
                    $"{group.Average(p => p.StockQuantity):N0}"
                );
            }

            AnsiConsole.Write(categoryTable);

            // Phase 3: Bulk Updates
            AnsiConsole.MarkupLine("\n[bold yellow]Phase 3: Performing bulk stock updates...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var updateTask = ctx.AddTask("[yellow]Updating stock levels[/]", maxValue: 50);

                    foreach (var product in allProducts.Take(50))
                    {
                        var newStock = random.Next(50, 200);
                        var updateCmd = new UpdateProductStockCommand(product.Id, newStock);
                        await updateStockHandler.HandleAsync(updateCmd);
                        updateTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 50 product stock levels[/]\n");

            // Phase 4: Price adjustments
            AnsiConsole.MarkupLine("[bold yellow]Phase 4: Adjusting prices...[/]");

            await AnsiConsole.Progress()
                .AutoClear(false)
                .StartAsync(async ctx =>
                {
                    var priceTask = ctx.AddTask("[yellow]Applying price changes[/]", maxValue: 30);

                    foreach (var product in allProducts.Take(30))
                    {
                        var newPrice = Math.Round(product.Price.Amount * (decimal)(random.NextDouble() * 0.4 + 0.8), 2);
                        var updateCmd = new UpdateProductPriceCommand(product.Id, newPrice, "USD");
                        await updatePriceHandler.HandleAsync(updateCmd);
                        priceTask.Increment(1);
                    }
                });

            AnsiConsole.MarkupLine("[green]âœ“ Updated 30 product prices[/]\n");

            // Phase 5: Sample deletions
            AnsiConsole.MarkupLine("[bold yellow]Phase 5: Removing discontinued products...[/]");

            var toDelete = allProducts
                .Where(p => p.StockQuantity == 0)
                .Take(5)
                .ToList();

            foreach (var product in toDelete)
            {
                var deleteCmd = new DeleteProductCommand(product.Id);
                await deleteProductHandler.HandleAsync(deleteCmd);
            }

            AnsiConsole.MarkupLine($"[green]âœ“ Removed {toDelete.Count} discontinued products[/]\n");

            // Final Statistics
            var finalResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

            if (finalResult.IsSuccess && finalResult.Data is not null)
            {
                var finalProducts = finalResult.Data;

                var comparison = new Table()
                    .Border(TableBorder.Rounded)
                    .BorderColor(Color.Green);

                comparison.AddColumn("[bold]Metric[/]");
                comparison.AddColumn("[bold]Before[/]");
                comparison.AddColumn("[bold]After[/]");
                comparison.AddColumn("[bold]Change[/]");

                comparison.AddRow(
                    "Total Products",
                    $"{allProducts.Count}",
                    $"[cyan]{finalProducts.Count}[/]",
                    $"[red]{finalProducts.Count - allProducts.Count:+0;-#}[/]"
                );

                comparison.AddRow(
                    "Total Stock",
                    $"{allProducts.Sum(p => p.StockQuantity):N0}",
                    $"[cyan]{finalProducts.Sum(p => p.StockQuantity):N0}[/]",
                    $"[green]{finalProducts.Sum(p => p.StockQuantity) - allProducts.Sum(p => p.StockQuantity):+#,0;-#,0}[/]"
                );

                AnsiConsole.Write(
                    new Panel(comparison)
                        .Header("[bold green]Before & After Comparison[/]")
                        .BorderColor(Color.Green)
                );
            }

            // Sample data display
            AnsiConsole.MarkupLine("\n[bold underline]Sample Products (Top 10 by Value):[/]");
            var sampleTable = new Table();
            sampleTable.AddColumn("Name");
            sampleTable.AddColumn("Category");
            sampleTable.AddColumn("Price");
            sampleTable.AddColumn("Stock");
            sampleTable.AddColumn("Value");

            foreach (var p in finalResult.Data!.OrderByDescending(p => p.Price.Amount * p.StockQuantity).Take(10))
            {
                sampleTable.AddRow(
                    p.Name.Length > 30 ? p.Name[..27] + "..." : p.Name,
                    p.Category,
                    $"${p.Price.Amount:N2}",
                    p.StockQuantity.ToString(),
                    $"[green]${p.Price.Amount * p.StockQuantity:N2}[/]"
                );
            }

            AnsiConsole.Write(sampleTable);
        }

        AnsiConsole.MarkupLine("\n[bold green]âœ“ Automated demo completed successfully![/]");
        AnsiConsole.MarkupLine("[dim]All operations logged and synchronized across nodes.[/]");
    }

    private static async Task DisplayProductsAsync(GetAllProductsQueryHandler handler)
    {
        var result = await handler.HandleAsync(new GetAllProductsQuery());

        if (result.IsSuccess && result.Data is not null)
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Category");
            table.AddColumn("Price");
            table.AddColumn("Stock");

            foreach (var p in result.Data)
            {
                table.AddRow(
                    p.Name,
                    p.Category,
                    $"${p.Price.Amount} {p.Price.Currency}",
                    p.StockQuantity.ToString()
                );
            }

            AnsiConsole.Write(table);
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed to get products:[/] {result.ErrorMessage}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": ""
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal sealed class Program(string[] args)
{
    private static readonly string DatabasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private readonly bool _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");

    static async Task<int> Main(string[] args)
    {
        var program = new Program(args);
        return await program.RunAsync();
    }

    private async Task<int> RunAsync()
    {
        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(DatabasePath))
            {
                Directory.CreateDirectory(DatabasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers (using the actual extension methods from your Infrastructure/Application projects)
            services.AddInfrastructureServices(DatabasePath);
            services.AddApplicationServices();

            var serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync(serviceProvider);

            // 3. Run Demo
            await RunCrudDemoAsync(serviceProvider);

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();

        // Get the factory
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    // Create a context for this specific node
                    var context = factory.CreateDbContext(nodeId);
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(DatabasePath, $"{nodeId}.db")}";

                        // Use the correct constructor signature: (nodeId, connectionString, priority, isPrimary)
                        var node = new DatabaseNode(
                            nodeId,
                            connectionString,
                            isPrimary ? 100 : 50,
                            isPrimary
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }

                    await context.DisposeAsync();
                }
            });

        AnsiConsole.MarkupLine("[green]Database nodes initialized successfully![/]");
    }

    private async Task RunCrudDemoAsync(IServiceProvider serviceProvider)
    {
        using var scope = serviceProvider.CreateScope();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        // Get the handler instances directly
        var createProductHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var updateStockHandler = scope.ServiceProvider.GetRequiredService<UpdateProductStockCommandHandler>();
        var getAllProductsHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();

        // Use the primary node
        await using var context = factory.CreateDbContext("node1");

        AnsiConsole.MarkupLine("[bold underline]CQRS Create & Read Demo[/]");

        // 1. Create Product
        var productName = "High-End Gaming Laptop";

        // Match the constructor signature: (Name, Description, Price, Currency, StockQuantity, Category)
        var createCommand = new CreateProductCommand(
            productName,
            "Powerful Laptop",
            1500.00m,
            "USD",
            50,
            "Electronics"
        );

        AnsiConsole.MarkupLine($"Sending [cyan]CreateProductCommand[/]...");
        var result = await createProductHandler.HandleAsync(createCommand);

        if (result.IsSuccess && result.Data is not null)
        {
            AnsiConsole.MarkupLine($"[green]Success![/] Product ID: {result.Data.Id}");

            // 2. Update Stock
            var updateStockCommand = new UpdateProductStockCommand(
                result.Data.Id,
                75
            );
            await updateStockHandler.HandleAsync(updateStockCommand);

            // 3. Read (Query)
            var productsResult = await getAllProductsHandler.HandleAsync(new GetAllProductsQuery());

            if (productsResult.IsSuccess && productsResult.Data is not null)
            {
                var table = new Table();
                table.AddColumn("Name");
                table.AddColumn("Price");
                table.AddColumn("Stock");
                table.AddColumn("Category");

                foreach (var p in productsResult.Data)
                {
                    table.AddRow(
                        p.Name,
                        $"{p.Price.Amount} {p.Price.Currency}",
                        p.StockQuantity.ToString(),
                        p.Category
                    );
                }

                AnsiConsole.Write(table);
            }
            else
            {
                AnsiConsole.MarkupLine($"[red]Failed to get products:[/] {productsResult.ErrorMessage}");
            }
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed:[/] {result.ErrorMessage}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": ""
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using MediatR;
using Microsoft.EntityFrameworkCore; // Required for EnsureCreatedAsync
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private static bool _isAutomated = false;

    static async Task<int> Main(string[] args)
    {
        _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");

        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(_databasePath))
            {
                Directory.CreateDirectory(_databasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers (These extension methods are in your Infrastructure/Application projects)
            services.AddInfrastructure();
            services.AddApplication();

            _serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync();

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunCrudDemoAsync();
            }
            else
            {
                await RunCrudDemoAsync(); // Running just one demo for simplicity in this fix
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync()
    {
        using var scope = _serviceProvider!.CreateScope();

        // FIX: Request the concrete MultiDbContextFactory, not the interface
        // The interface IDbContextFactory doesn't have 'SetCurrentNodeId', but the concrete class does.
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    // FIX: This method exists on MultiDbContextFactory, not the interface
                    factory.SetCurrentNodeId(nodeId);

                    // We create a context *after* setting the node ID
                    var context = factory.CreateDbContext();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(_databasePath, $"{nodeId}.db")}";

                        // FIX: Use the Constructor, not property setters (properties are private set)
                        var node = new DatabaseNode(
                            nodeId,
                            isPrimary,
                            connectionString,
                            priority: isPrimary ? 100 : 50
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]Database nodes initialized successfully![/]");
    }

    private static async Task RunCrudDemoAsync()
    {
        using var scope = _serviceProvider!.CreateScope();
        var sender = scope.ServiceProvider.GetRequiredService<ISender>();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        // Ensure we are on the primary node
        factory.SetCurrentNodeId("node1");

        AnsiConsole.MarkupLine("[bold underline]CQRS Create & Read Demo[/]");

        // 1. Create Product
        var productName = "High-End Gaming Laptop";

        // FIX: Use the 'Money' Value Object defined in your Domain, not raw decimals
        var price = new Money(1500.00m, "USD");

        // FIX: Match the constructor signature of CreateProductCommand
        // (Name, Description, Sku, Price, WarehouseId)
        var createCommand = new CreateProductCommand(
            productName,
            "Powerful Laptop",
            "GAMING-001",
            price,
            "WH-NY-01"
        );

        AnsiConsole.MarkupLine($"Sending [cyan]CreateProductCommand[/]...");
        var result = await sender.Send(createCommand);

        if (result.IsSuccess)
        {
            AnsiConsole.MarkupLine($"[green]Success![/] Product ID: {result.Value}");
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed:[/] {result.Error}");
            return;
        }

        // 2. Update Stock
        // FIX: Ensure UpdateStockCommand parameters match (Guid, int, string)
        await sender.Send(new UpdateStockCommand(result.Value, 50, "Initial Stock"));

        // 3. Read (Query)
        var products = await sender.Send(new GetAllProductsQuery());

        var table = new Table();
        table.AddColumn("Name");
        table.AddColumn("Price");
        table.AddColumn("Stock");

        foreach (var p in products)
        {
            table.AddRow(
                p.Name,
                $"{p.Price.Amount} {p.Price.Currency}", // Access Money properties
                p.StockQuantity.ToString()
            );
        }

        AnsiConsole.Write(table);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": "--ci"
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
	<PackageReference Include="MediatR" Version="12.2.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using MediatR;
using Microsoft.EntityFrameworkCore; // Required for EnsureCreatedAsync
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");
    private static bool _isAutomated = false;

    static async Task<int> Main(string[] args)
    {
        _isAutomated = args.Any(a => a is "--demo" or "--automated" or "--ci");

        System.Console.Title = "MultiDbSync Demo";
        AnsiConsole.Write(new FigletText("MultiDbSync").Color(Color.Cyan1));

        try
        {
            if (!Directory.Exists(_databasePath))
            {
                Directory.CreateDirectory(_databasePath);
            }

            // 1. Setup Dependency Injection
            var services = new ServiceCollection();

            // Add Logging
            services.AddLogging(configure => configure.AddConsole().SetMinimumLevel(LogLevel.Warning));

            // Add Layers (These extension methods are in your Infrastructure/Application projects)
            services.AddInfrastructure();
            services.AddApplication();

            _serviceProvider = services.BuildServiceProvider();

            // 2. Initialize Databases
            await InitializeDatabaseAsync();

            // 3. Run Demo
            if (_isAutomated)
            {
                await RunCrudDemoAsync();
            }
            else
            {
                await RunCrudDemoAsync(); // Running just one demo for simplicity in this fix
            }

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static async Task InitializeDatabaseAsync()
    {
        using var scope = _serviceProvider!.CreateScope();

        // FIX: Request the concrete MultiDbContextFactory, not the interface
        // The interface IDbContextFactory doesn't have 'SetCurrentNodeId', but the concrete class does.
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        string[] nodes = ["node1", "node2", "node3"];

        await AnsiConsole.Status()
            .StartAsync("Initializing Database Nodes...", async ctx =>
            {
                foreach (var nodeId in nodes)
                {
                    ctx.Status($"Creating [bold]{nodeId}[/]...");

                    // FIX: This method exists on MultiDbContextFactory, not the interface
                    factory.SetCurrentNodeId(nodeId);

                    // We create a context *after* setting the node ID
                    var context = factory.CreateDbContext();
                    await context.Database.EnsureCreatedAsync();

                    if (!context.DatabaseNodes.Any())
                    {
                        var isPrimary = nodeId == "node1";
                        var connectionString = $"Data Source={Path.Combine(_databasePath, $"{nodeId}.db")}";

                        // FIX: Use the Constructor, not property setters (properties are private set)
                        var node = new DatabaseNode(
                            nodeId,
                            isPrimary,
                            connectionString,
                            priority: isPrimary ? 100 : 50
                        );

                        context.DatabaseNodes.Add(node);
                        await context.SaveChangesAsync();
                    }
                }
            });

        AnsiConsole.MarkupLine("[green]Database nodes initialized successfully![/]");
    }

    private static async Task RunCrudDemoAsync()
    {
        using var scope = _serviceProvider!.CreateScope();
        var sender = scope.ServiceProvider.GetRequiredService<ISender>();
        var factory = scope.ServiceProvider.GetRequiredService<MultiDbContextFactory>();

        // Ensure we are on the primary node
        factory.SetCurrentNodeId("node1");

        AnsiConsole.MarkupLine("[bold underline]CQRS Create & Read Demo[/]");

        // 1. Create Product
        var productName = "High-End Gaming Laptop";

        // FIX: Use the 'Money' Value Object defined in your Domain, not raw decimals
        var price = new Money(1500.00m, "USD");

        // FIX: Match the constructor signature of CreateProductCommand
        // (Name, Description, Sku, Price, WarehouseId)
        var createCommand = new CreateProductCommand(
            productName,
            "Powerful Laptop",
            "GAMING-001",
            price,
            "WH-NY-01"
        );

        AnsiConsole.MarkupLine($"Sending [cyan]CreateProductCommand[/]...");
        var result = await sender.Send(createCommand);

        if (result.IsSuccess)
        {
            AnsiConsole.MarkupLine($"[green]Success![/] Product ID: {result.Value}");
        }
        else
        {
            AnsiConsole.MarkupLine($"[red]Failed:[/] {result.Error}");
            return;
        }

        // 2. Update Stock
        // FIX: Ensure UpdateStockCommand parameters match (Guid, int, string)
        await sender.Send(new UpdateStockCommand(result.Value, 50, "Initial Stock"));

        // 3. Read (Query)
        var products = await sender.Send(new GetAllProductsQuery());

        var table = new Table();
        table.AddColumn("Name");
        table.AddColumn("Price");
        table.AddColumn("Stock");

        foreach (var p in products)
        {
            table.AddRow(
                p.Name,
                $"{p.Price.Amount} {p.Price.Currency}", // Access Money properties
                p.StockQuantity.ToString()
            );
        }

        AnsiConsole.Write(table);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": "--ci"
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.Title = "MultiDbSync Demo";

        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            // Force Spectre to use ANSI in VS debug console
            AnsiConsole.Console.Profile.Capabilities.Ansi = true;

            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Automated mode for CI
            if (args.Any(a => a is "--demo" or "--automated" or "--ci"))
            {
                System.Console.WriteLine("Running automated demo mode...");
                await RunAllDemosAsync();
                return 0;
            }

            await RunDemoAsync();
            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            System.Console.ReadLine(); // prevent auto-close
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(b =>
        {
            b.AddConsole();
            b.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var repo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();
        var nodes = await repo.GetAllAsync();

        if (nodes.Count == 0)
        {
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false));
        }

        AnsiConsole.MarkupLine("[green]Database initialized.[/]\n");
    }

    private static async Task RunDemoAsync()
    {
        while (true)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select operation")
                    .AddChoices(new[]
                    {
                        "CRUD Operations",
                        "Database Synchronization",
                        "Quorum Consensus",
                        "Automatic Failover",
                        "Node Health Monitoring",
                        "Run All Demos",
                        "Exit"
                    })
            );

            switch (choice)
            {
                case "CRUD Operations":
                    await RunCrudDemoAsync();
                    break;
                case "Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "Exit":
                    return;
            }
        }
    }

    // STUBS so it compiles if missing
    private static Task RunCrudDemoAsync() => Task.CompletedTask;
    private static Task RunSyncDemoAsync() => Task.CompletedTask;
    private static Task RunQuorumDemoAsync() => Task.CompletedTask;
    private static Task RunFailoverDemoAsync() => Task.CompletedTask;
    private static Task RunHealthCheckDemoAsync() => Task.CompletedTask;
    private static Task RunAllDemosAsync() => Task.CompletedTask;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Properties/launchSettings.json
================================================================================
{
  "profiles": {
    "MultiDbSync.Console": {
      "commandName": "Project",
      "commandLineArgs": "--ci"
    }
  }
}



================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.Title = "MultiDbSync Demo";

        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            // Force Spectre to use ANSI in VS debug console
            AnsiConsole.Console.Profile.Capabilities.Ansi = true;

            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Automated mode for CI
            if (args.Any(a => a is "--demo" or "--automated" or "--ci"))
            {
                System.Console.WriteLine("Running automated demo mode...");
                await RunAllDemosAsync();
                return 0;
            }

            await RunDemoAsync();
            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            System.Console.ReadLine(); // prevent auto-close
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(b =>
        {
            b.AddConsole();
            b.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var repo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();
        var nodes = await repo.GetAllAsync();

        if (nodes.Count == 0)
        {
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false));
        }

        AnsiConsole.MarkupLine("[green]Database initialized.[/]\n");
    }

    private static async Task RunDemoAsync()
    {
        while (true)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select operation")
                    .AddChoices(new[]
                    {
                        "CRUD Operations",
                        "Database Synchronization",
                        "Quorum Consensus",
                        "Automatic Failover",
                        "Node Health Monitoring",
                        "Run All Demos",
                        "Exit"
                    })
            );

            switch (choice)
            {
                case "CRUD Operations":
                    await RunCrudDemoAsync();
                    break;
                case "Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "Exit":
                    return;
            }
        }
    }

    // STUBS so it compiles if missing
    private static Task RunCrudDemoAsync() => Task.CompletedTask;
    private static Task RunSyncDemoAsync() => Task.CompletedTask;
    private static Task RunQuorumDemoAsync() => Task.CompletedTask;
    private static Task RunFailoverDemoAsync() => Task.CompletedTask;
    private static Task RunHealthCheckDemoAsync() => Task.CompletedTask;
    private static Task RunAllDemosAsync() => Task.CompletedTask;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.Title = "MultiDbSync Demo";

        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            // Force Spectre to use ANSI in VS debug console
            AnsiConsole.Console.Profile.Capabilities.Ansi = true;

            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Automated mode for CI
            if (args.Any(a => a is "--demo" or "--automated" or "--ci"))
            {
                System.Console.WriteLine("Running automated demo mode...");
                await RunAllDemosAsync();
                return 0;
            }

            await RunDemoAsync();
            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            System.Console.ReadLine(); // prevent auto-close
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(b =>
        {
            b.AddConsole();
            b.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var repo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();
        var nodes = await repo.GetAllAsync();

        if (nodes.Count == 0)
        {
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false));
        }

        AnsiConsole.MarkupLine("[green]Database initialized.[/]\n");
    }

    private static async Task RunDemoAsync()
    {
        while (true)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select operation")
                    .AddChoices(new[]
                    {
                        "CRUD Operations",
                        "Database Synchronization",
                        "Quorum Consensus",
                        "Automatic Failover",
                        "Node Health Monitoring",
                        "Run All Demos",
                        "Exit"
                    })
            );

            switch (choice)
            {
                case "CRUD Operations":
                    await RunCrudDemoAsync();
                    break;
                case "Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "Exit":
                    return;
            }
        }
    }

    // STUBS so it compiles if missing
    private static Task RunCrudDemoAsync() => Task.CompletedTask;
    private static Task RunSyncDemoAsync() => Task.CompletedTask;
    private static Task RunQuorumDemoAsync() => Task.CompletedTask;
    private static Task RunFailoverDemoAsync() => Task.CompletedTask;
    private static Task RunHealthCheckDemoAsync() => Task.CompletedTask;
    private static Task RunAllDemosAsync() => Task.CompletedTask;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        // HARD BLOCK VALUE OBJECTS FROM ENTITY DISCOVERY
        modelBuilder.Ignore<Address>();
        modelBuilder.Ignore<Money>();
        modelBuilder.Ignore<EmailAddress>();

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.Title = "MultiDbSync Demo";

        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            // Force Spectre to use ANSI in VS debug console
            AnsiConsole.Console.Profile.Capabilities.Ansi = true;

            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Automated mode for CI
            if (args.Any(a => a is "--demo" or "--automated" or "--ci"))
            {
                System.Console.WriteLine("Running automated demo mode...");
                await RunAllDemosAsync();
                return 0;
            }

            await RunDemoAsync();
            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            System.Console.ReadLine(); // prevent auto-close
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(b =>
        {
            b.AddConsole();
            b.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var repo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();
        var nodes = await repo.GetAllAsync();

        if (nodes.Count == 0)
        {
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false));
        }

        AnsiConsole.MarkupLine("[green]Database initialized.[/]\n");
    }

    private static async Task RunDemoAsync()
    {
        while (true)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select operation")
                    .AddChoices(new[]
                    {
                        "CRUD Operations",
                        "Database Synchronization",
                        "Quorum Consensus",
                        "Automatic Failover",
                        "Node Health Monitoring",
                        "Run All Demos",
                        "Exit"
                    })
            );

            switch (choice)
            {
                case "CRUD Operations":
                    await RunCrudDemoAsync();
                    break;
                case "Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "Exit":
                    return;
            }
        }
    }

    // STUBS so it compiles if missing
    private static Task RunCrudDemoAsync() => Task.CompletedTask;
    private static Task RunSyncDemoAsync() => Task.CompletedTask;
    private static Task RunQuorumDemoAsync() => Task.CompletedTask;
    private static Task RunFailoverDemoAsync() => Task.CompletedTask;
    private static Task RunHealthCheckDemoAsync() => Task.CompletedTask;
    private static Task RunAllDemosAsync() => Task.CompletedTask;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        base.OnModelCreating(modelBuilder);

        foreach (var e in modelBuilder.Model.GetEntityTypes())
        {
            Console.WriteLine($"EF ENTITY: {e.Name}");
        }

        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using Spectre.Console;

namespace MultiDbSync.Console;

internal class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.Title = "MultiDbSync Demo";

        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            // Force Spectre to use ANSI in VS debug console
            AnsiConsole.Console.Profile.Capabilities.Ansi = true;

            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Automated mode for CI
            if (args.Any(a => a is "--demo" or "--automated" or "--ci"))
            {
                System.Console.WriteLine("Running automated demo mode...");
                await RunAllDemosAsync();
                return 0;
            }

            await RunDemoAsync();
            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            System.Console.ReadLine(); // prevent auto-close
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(b =>
        {
            b.AddConsole();
            b.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var repo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();
        var nodes = await repo.GetAllAsync();

        if (nodes.Count == 0)
        {
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false));
            await repo.AddAsync(new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false));
        }

        AnsiConsole.MarkupLine("[green]Database initialized.[/]\n");
    }

    private static async Task RunDemoAsync()
    {
        while (true)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select operation")
                    .AddChoices(new[]
                    {
                        "CRUD Operations",
                        "Database Synchronization",
                        "Quorum Consensus",
                        "Automatic Failover",
                        "Node Health Monitoring",
                        "Run All Demos",
                        "Exit"
                    })
            );

            switch (choice)
            {
                case "CRUD Operations":
                    await RunCrudDemoAsync();
                    break;
                case "Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "Exit":
                    return;
            }
        }
    }

    // STUBS so it compiles if missing
    private static Task RunCrudDemoAsync() => Task.CompletedTask;
    private static Task RunSyncDemoAsync() => Task.CompletedTask;
    private static Task RunQuorumDemoAsync() => Task.CompletedTask;
    private static Task RunFailoverDemoAsync() => Task.CompletedTask;
    private static Task RunHealthCheckDemoAsync() => Task.CompletedTask;
    private static Task RunAllDemosAsync() => Task.CompletedTask;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static readonly string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Check for automated mode (for CI/CD and testing)
            if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
            {
                System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
                await RunAllDemosAsync();
                System.Console.WriteLine("\nâœ… All demos completed successfully!");
                return 0;
            }

            // Interactive mode
            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("IsPrimary");
        table.AddColumn("Priority");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary.ToString(),
                node.Priority.ToString());
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Getting sync status...[/yellow]");
        var syncStatus = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"Total Nodes: {syncStatus.TotalNodes}");
        AnsiConsole.MarkupLine($"Successful Syncs: [green]{syncStatus.SuccessfulNodes}[/]");
        AnsiConsole.MarkupLine($"Failed Syncs: [red]{syncStatus.FailedNodes}[/]");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();

        var operationId = Guid.NewGuid();

        AnsiConsole.MarkupLine($"[yellow]Testing quorum consensus for operation: {operationId}[/yellow]");

        var hasConsensus = await quorumService.HasConsensusAsync(operationId);

        AnsiConsole.MarkupLine($"Consensus achieved: [{(hasConsensus ? "green" : "red")}]{hasConsensus}[/]");

        var quorumResult = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"Total Votes: {quorumResult.TotalVotes}");
        AnsiConsole.MarkupLine($"Yes Votes: [green]{quorumResult.YesVotes}[/]");
        AnsiConsole.MarkupLine($"No Votes: [red]{quorumResult.NoVotes}[/]");
        AnsiConsole.MarkupLine($"Decision: {quorumResult.Decision}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current Primary Node: {primaryNode.NodeId}[/yellow]");

            var isNeeded = await failoverService.IsFailoverNeededAsync();
            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs(string failedNodeId, string newPrimaryNodeId) : EventArgs
{
    public string FailedNodeId { get; } = failedNodeId;
    public string NewPrimaryNodeId { get; } = newPrimaryNodeId;
    public DateTime OccurredAt { get; } = DateTime.UtcNow;
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .github/workflows/test.yml
================================================================================
name: Cross-Platform Integration Tests

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  # Build and test on all platforms in parallel
  test-matrix:
    name: Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false  # Continue testing other platforms even if one fails
      matrix:
        include:
          # Linux x64
          - os: ubuntu-latest
            arch: x64
            runtime: linux-x64
            display-name: 'Linux x64'
          
          # Linux ARM64 (GitHub-hosted runners available)
          - os: ubuntu-latest-arm
            arch: arm64
            runtime: linux-arm64
            display-name: 'Linux ARM64'
          
          # Windows x64
          - os: windows-latest
            arch: x64
            runtime: win-x64
            display-name: 'Windows x64'
          
          # Windows ARM64 (GitHub-hosted runners available)
          - os: windows-latest-arm
            arch: arm64
            runtime: win-arm64
            display-name: 'Windows ARM64'
          
          # macOS Intel (x64)
          - os: macos-13
            arch: x64
            runtime: osx-x64
            display-name: 'macOS Intel'
          
          # macOS Apple Silicon (ARM64)
          - os: macos-latest
            arch: arm64
            runtime: osx-arm64
            display-name: 'macOS Apple Silicon'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“Š Display system information
        shell: bash
        run: |
          echo "=== System Information ==="
          echo "OS: ${{ matrix.display-name }}"
          echo "Runner: ${{ runner.os }}"
          echo "Architecture: ${{ matrix.arch }}"
          echo ""
          echo "=== .NET Information ==="
          dotnet --info
          echo ""
          echo "=== Runtime Information ==="
          dotnet --list-runtimes
      
      - name: ðŸ“¦ Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: ðŸ”¨ Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: ðŸ§ª Run unit tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results-${{ matrix.runtime }}.trx"
      
      - name: ðŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.runtime }}
          path: '**/test-results-*.trx'
          retention-days: 7
      
      - name: ðŸš€ Run application demo (automated mode)
        shell: bash
        run: |
          echo "=== Running Application in Automated Mode ==="
          cd MultiDbSync/MultiDbSync.Console
          dotnet run --configuration Release -- --demo
      
      - name: âœ… Verify application ran successfully
        if: success()
        shell: bash
        run: |
          echo "âœ… Application demo completed successfully on ${{ matrix.display-name }}!"
      
      - name: âŒ Application failed
        if: failure()
        shell: bash
        run: |
          echo "âŒ Application demo failed on ${{ matrix.display-name }}"
          exit 1

  # Publish platform-specific executables for smoke testing
  publish-and-test:
    name: Publish & Test ${{ matrix.runtime }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64
          - os: macos-13
            runtime: osx-x64
          - os: macos-latest
            runtime: osx-arm64
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Publish self-contained executable
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: ðŸ§ª Test published executable (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          chmod +x ./publish/${{ matrix.runtime }}/MultiDbSync.Console
          ./publish/${{ matrix.runtime }}/MultiDbSync.Console --demo
      
      - name: ðŸ§ª Test published executable (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          & ".\publish\${{ matrix.runtime }}\MultiDbSync.Console.exe" --demo
      
      - name: ðŸ“¤ Upload published executable
        uses: actions/upload-artifact@v4
        with:
          name: executable-${{ matrix.runtime }}
          path: publish/${{ matrix.runtime }}/*
          retention-days: 7

  # Summary job that depends on all test jobs
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, publish-and-test]
    if: always()
    
    steps:
      - name: ðŸ“Š Check test results
        run: |
          echo "=== Test Matrix Results ==="
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Publish and Test: ${{ needs.publish-and-test.result }}"
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed on all platforms!"
            exit 0
          else
            echo "âŒ Some tests failed. Check individual job results."
            exit 1
          fi
      
      - name: ðŸ“ Generate summary
        if: always()
        run: |
          echo "## ðŸ§ª Cross-Platform Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Test Matrix | Publish & Test |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| All Platforms | ${{ needs.test-matrix.result }} | ${{ needs.publish-and-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.publish-and-test.result }}" == "success" ]]; then
            echo "### âœ… All platforms passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The application successfully built, tested, and ran on:" >> $GITHUB_STEP_SUMMARY
            echo "- Linux x64" >> $GITHUB_STEP_SUMMARY
            echo "- Linux ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows x64" >> $GITHUB_STEP_SUMMARY
            echo "- Windows ARM64" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Intel (x64)" >> $GITHUB_STEP_SUMMARY
            echo "- macOS Apple Silicon (ARM64)" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Some platforms failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check individual job results for details." >> $GITHUB_STEP_SUMMARY
          fi

  # Performance baseline test (optional)
  performance-test:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: ðŸ“¦ Restore and build
        run: |
          dotnet restore ${{ env.SOLUTION_PATH }}
          dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: â±ï¸ Run performance test
        shell: bash
        run: |
          cd MultiDbSync/MultiDbSync.Console
          
          echo "=== Performance Test ==="
          echo "Measuring execution time..."
          
          START_TIME=$(date +%s%N)
          dotnet run --configuration Release -- --demo
          END_TIME=$(date +%s%N)
          
          DURATION_NS=$((END_TIME - START_TIME))
          DURATION_MS=$((DURATION_NS / 1000000))
          DURATION_S=$((DURATION_MS / 1000))
          
          echo "Execution time: ${DURATION_S}.${DURATION_MS:(-3)} seconds"
          echo "PERF_TIME_MS=$DURATION_MS" >> $GITHUB_ENV
      
      - name: ðŸ“Š Performance summary
        run: |
          echo "## â±ï¸ Performance Baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Execution time: **${PERF_TIME_MS}ms**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Platform: Ubuntu Latest (x64)" >> $GITHUB_STEP_SUMMARY
          echo "Configuration: Release" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            // Check for automated mode (for CI/CD and testing)
            if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
            {
                System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
                await RunAllDemosAsync();
                System.Console.WriteLine("\nâœ… All demos completed successfully!");
                return 0;
            }

            // Interactive mode
            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("IsPrimary");
        table.AddColumn("Priority");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary.ToString(),
                node.Priority.ToString());
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Getting sync status...[/yellow]");
        var syncStatus = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"Total Nodes: {syncStatus.TotalNodes}");
        AnsiConsole.MarkupLine($"Successful Syncs: [green]{syncStatus.SuccessfulNodes}[/]");
        AnsiConsole.MarkupLine($"Failed Syncs: [red]{syncStatus.FailedNodes}[/]");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();

        var operationId = Guid.NewGuid();

        AnsiConsole.MarkupLine($"[yellow]Testing quorum consensus for operation: {operationId}[/yellow]");

        var hasConsensus = await quorumService.HasConsensusAsync(operationId);

        AnsiConsole.MarkupLine($"Consensus achieved: [{(hasConsensus ? "green" : "red")}]{hasConsensus}[/]");

        var quorumResult = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"Total Votes: {quorumResult.TotalVotes}");
        AnsiConsole.MarkupLine($"Yes Votes: [green]{quorumResult.YesVotes}[/]");
        AnsiConsole.MarkupLine($"No Votes: [red]{quorumResult.NoVotes}[/]");
        AnsiConsole.MarkupLine($"Decision: {quorumResult.Decision.ToString()}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current Primary Node: {primaryNode.NodeId}[/yellow]");

            var isNeeded = await failoverService.IsFailoverNeededAsync();
            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs : EventArgs
{
    public string FailedNodeId { get; }
    public string NewPrimaryNodeId { get; }
    public DateTime OccurredAt { get; }

    public FailoverEventArgs(string failedNodeId, string newPrimaryNodeId)
    {
        FailedNodeId = failedNodeId;
        NewPrimaryNodeId = newPrimaryNodeId;
        OccurredAt = DateTime.UtcNow;
    }
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: README.md
================================================================================


# Cross-Platform Testing Setup

This package contains files to enable automated cross-platform testing of your MultiDbSync application in GitHub Actions.

## ðŸ“¦ Files Included

1. **`Program.cs`** - Modified console application with automated mode support
2. **`.github/workflows/cross-platform-tests.yml`** - New GitHub Actions workflow for parallel testing
3. **`README-TESTING.md`** - This file

## ðŸš€ Quick Start

### Step 1: Update Program.cs

Replace the existing `MultiDbSync/MultiDbSync.Console/Program.cs` with the provided `Program.cs` file.

**Key changes:**
```csharp
// New automated mode support
if (args.Length > 0 && (args[0] == "--demo" || args[0] == "--automated" || args[0] == "--ci"))
{
    System.Console.WriteLine("\nðŸ¤– Running in AUTOMATED mode (non-interactive)\n");
    await RunAllDemosAsync();
    System.Console.WriteLine("\nâœ… All demos completed successfully!");
    return 0;
}
```

### Step 2: Add GitHub Actions Workflow

Copy `.github/workflows/cross-platform-tests.yml` to your repository at:
```
.github/workflows/cross-platform-tests.yml
```

### Step 3: Push and Watch

```bash
git add .
git commit -m "Add cross-platform testing workflow"
git push
```

GitHub Actions will automatically run tests on all platforms!

## ðŸŽ¯ What Gets Tested

### Platforms Tested:
- âœ… **Linux x64** (ubuntu-latest)
- âœ… **Linux ARM64** (ubuntu-latest-arm)
- âœ… **Windows x64** (windows-latest)
- âœ… **Windows ARM64** (windows-latest-arm)
- âœ… **macOS Intel** (macos-13)
- âœ… **macOS Apple Silicon** (macos-latest / ARM64)

### Test Matrix Jobs:

Each platform runs:
1. **Build & Unit Tests** - Compiles solution and runs xUnit tests
2. **Integration Test** - Runs the full application with `--demo` flag
3. **Publish Test** - Creates self-contained executable and runs it

### Additional Jobs:

- **Performance Baseline** - Measures execution time on Linux
- **Test Summary** - Aggregates all results

## ðŸƒ Running Locally

### Interactive Mode (Original)
```bash
dotnet run --project MultiDbSync/MultiDbSync.Console
# Interactive menu appears
```

### Automated Mode (New)
```bash
# Run all demos and exit
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Also works with these flags:
dotnet run --project MultiDbSync/MultiDbSync.Console -- --automated
dotnet run --project MultiDbSync/MultiDbSync.Console -- --ci
```

### Published Executable
```bash
# Build self-contained executable
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime linux-x64 \
    --self-contained true \
    --output ./publish

# Run automated tests
./publish/MultiDbSync.Console --demo
```

## ðŸ“Š GitHub Actions Workflow Details

### Workflow Triggers:
- âœ… Push to any branch
- âœ… Pull requests
- âœ… Manual dispatch (workflow_dispatch)

### Parallel Execution:
All 6 platform tests run in parallel for maximum speed!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linux     â”‚   Windows   â”‚    macOS    â”‚
â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚  x64 ARM64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All running simultaneously
```

### Job Flow:
```mermaid
graph LR
    A[Push Code] --> B[Test Matrix x6]
    A --> C[Publish & Test x4]
    B --> D[Test Summary]
    C --> D
    A --> E[Performance Test]
```

## ðŸ” Viewing Results

### In GitHub UI:

1. Go to **Actions** tab
2. Click on the workflow run
3. View individual job results
4. Check the **Summary** tab for aggregated results

### Artifacts Available:

- **test-results-{platform}** - xUnit test results (TRX files)
- **executable-{platform}** - Self-contained executables (7 days retention)

## âš™ï¸ Configuration

### Timeout Settings:
```yaml
timeout-minutes: 15  # For test-matrix jobs
timeout-minutes: 20  # For publish-and-test jobs
```

### .NET Version:
```yaml
env:
  DOTNET_VERSION: '10.0.x'
```

### Fail-Fast Behavior:
```yaml
strategy:
  fail-fast: false  # Continue testing all platforms even if one fails
```

## ðŸ› Troubleshooting

### ARM64 Runners Not Available

If you get errors about ARM64 runners:

```yaml
# Comment out these sections:
# - os: ubuntu-latest-arm
# - os: windows-latest-arm
```

GitHub ARM64 runners are in preview and may not be available for all accounts.

### Application Hangs in CI

Make sure you're using the `--demo` flag:
```bash
dotnet run -- --demo  # âœ… Correct
dotnet run            # âŒ Will hang waiting for input
```

### Test Failures

Check individual job logs:
1. Click on failed job
2. Expand failed step
3. Review error messages

Common issues:
- Missing dependencies
- Platform-specific EF Core issues
- File path differences (Windows vs Unix)

## ðŸ“ˆ Performance Monitoring

The workflow includes a performance baseline test that measures execution time:

```yaml
# Example output
Execution time: 2.345 seconds
Platform: Ubuntu Latest (x64)
Configuration: Release
```

Track this over time to catch performance regressions!

## ðŸ”’ Security Notes

### Secrets Usage:
This workflow doesn't require any secrets for basic testing.

For production deployments, add:
```yaml
env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # For releases
```

### Artifact Retention:
```yaml
retention-days: 7  # Adjust based on storage needs
```

## ðŸŽ¨ Customization

### Add New Platforms:

```yaml
matrix:
  include:
    - os: ubuntu-22.04
      arch: x64
      runtime: linux-x64
      display-name: 'Ubuntu 22.04'
```

### Add Custom Tests:

```yaml
- name: Custom Integration Test
  run: |
    dotnet run -- --demo
    # Add your custom validation here
```

### Modify Build Configuration:

```yaml
- name: Build with specific config
  run: |
    dotnet build --configuration Debug
    dotnet build --configuration Release
```

## ðŸ“š Best Practices

1. **Always test locally first:**
   ```bash
   dotnet run -- --demo
   ```

2. **Check logs regularly:**
   - View GitHub Actions logs
   - Monitor test failure patterns

3. **Keep dependencies updated:**
   ```bash
   dotnet list package --outdated
   ```

4. **Use meaningful commit messages:**
   ```bash
   git commit -m "test: Add validation for null customers"
   ```

## ðŸŽ¯ Next Steps

### Recommended Enhancements:

1. **Add Code Coverage:**
   ```yaml
   - name: Generate coverage
     run: dotnet test --collect:"XPlat Code Coverage"
   ```

2. **Add Benchmark Tests:**
   ```yaml
   - name: Run benchmarks
     run: dotnet run --project Benchmarks
   ```

3. **Add Docker Testing:**
   ```yaml
   - name: Test in Docker
     run: |
       docker build -t multidbsync .
       docker run multidbsync --demo
   ```

4. **Add Database Compatibility Tests:**
   - Test with different SQLite versions
   - Test with SQL Server, PostgreSQL

## ðŸ†˜ Support

### Issues?

1. Check existing workflow runs
2. Review job logs
3. Test locally with `--demo` flag
4. Check platform-specific documentation

### Useful Commands:

```bash
# Test build locally
dotnet build MultiDbSync/MultiDbSync.sln --configuration Release

# Test unit tests locally
dotnet test MultiDbSync/MultiDbSync.sln --configuration Release

# Test automated mode locally
dotnet run --project MultiDbSync/MultiDbSync.Console -- --demo

# Publish for specific platform
dotnet publish MultiDbSync/MultiDbSync.Console \
    --configuration Release \
    --runtime win-x64 \
    --self-contained true \
    --output ./publish/win-x64
```

## âœ… Success Criteria

Your workflow is working correctly when:

1. âœ… All 6 platform tests pass (green checkmarks)
2. âœ… Published executables run successfully
3. âœ… Test summary shows all platforms passed
4. âœ… No timeout errors
5. âœ… Performance test completes under 10 minutes

## ðŸŽ‰ Conclusion

You now have comprehensive cross-platform testing for your MultiDbSync application!

**What you get:**
- âœ… Automated testing on 6 platforms
- âœ… Parallel execution for speed
- âœ… Self-contained executable validation
- âœ… Performance baseline tracking
- âœ… Detailed test reports

Happy testing! ðŸš€



## ðŸ¤– AI-Assisted Development

This project includes code generated and assisted by large language models (LLMs) such as Claude. While all code has been reviewed and tested, please be aware that some portions were created with AI assistance.

## License
This project is open source and available under the AGPL license.




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
    <PackageReference Include="Spectre.Console" Version="0.54.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("Is Primary");
        table.AddColumn("Health Score");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary ? "Yes" : "No",
                $"{node.HealthScore:F1}%");
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Forcing synchronization across all nodes...[/yellow]");
        var syncResult = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"[green]Sync Status:[/green]");
        AnsiConsole.MarkupLine($"  Total Nodes: {syncResult.TotalNodes}");
        AnsiConsole.MarkupLine($"  Successful: {syncResult.SuccessfulNodes}");
        AnsiConsole.MarkupLine($"  Failed: {syncResult.FailedNodes}");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var operationId = Guid.NewGuid();
        var operationDescription = "Promote node to primary";

        AnsiConsole.MarkupLine($"[yellow]Requesting vote for operation: {operationDescription}[/yellow]");

        var voteRequested = await quorumService.RequestVoteAsync(operationId, operationDescription);

        AnsiConsole.MarkupLine($"Vote requested: [{(voteRequested ? "green" : "red")}]{voteRequested}[/]");

        var result = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"\n[green]Quorum Result:[/green]");
        AnsiConsole.MarkupLine($"  Total Votes: {result.TotalVotes}");
        AnsiConsole.MarkupLine($"  Yes Votes: {result.YesVotes}");
        AnsiConsole.MarkupLine($"  No Votes: {result.NoVotes}");
        AnsiConsole.MarkupLine($"  Has Consensus: [{(result.HasConsensus ? "green" : "red")}]{result.HasConsensus}[/]");
        AnsiConsole.MarkupLine($"  Decision: {result.Decision}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        failoverService.FailoverOccurred += (sender, args) =>
        {
            AnsiConsole.MarkupLine($"[yellow]Failover Event: {args.FailedNodeId} -> {args.NewPrimaryNodeId}[/yellow]");
        };

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current primary node: {primaryNode.NodeId}[/yellow]");

            AnsiConsole.MarkupLine("[yellow]Checking if failover is needed...[/yellow]");
            var isNeeded = await failoverService.IsFailoverNeededAsync();

            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs : EventArgs
{
    public string FailedNodeId { get; }
    public string NewPrimaryNodeId { get; }
    public DateTime OccurredAt { get; }

    public FailoverEventArgs(string failedNodeId, string newPrimaryNodeId)
    {
        FailedNodeId = failedNodeId;
        NewPrimaryNodeId = newPrimaryNodeId;
        OccurredAt = DateTime.UtcNow;
    }
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.3" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.3">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.4">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="18.0.1" />
    <PackageReference Include="xunit.runner.visualstudio" Version="3.1.5">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.3" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.3" />
    <PackageReference Include="xunit.v3" Version="3.2.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
    <PackageReference Include="Spectre.Console" Version="0.50.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("Is Primary");
        table.AddColumn("Health Score");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary ? "Yes" : "No",
                $"{node.HealthScore:F1}%");
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Forcing synchronization across all nodes...[/yellow]");
        var syncResult = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"[green]Sync Status:[/green]");
        AnsiConsole.MarkupLine($"  Total Nodes: {syncResult.TotalNodes}");
        AnsiConsole.MarkupLine($"  Successful: {syncResult.SuccessfulNodes}");
        AnsiConsole.MarkupLine($"  Failed: {syncResult.FailedNodes}");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var operationId = Guid.NewGuid();
        var operationDescription = "Promote node to primary";

        AnsiConsole.MarkupLine($"[yellow]Requesting vote for operation: {operationDescription}[/yellow]");

        var voteRequested = await quorumService.RequestVoteAsync(operationId, operationDescription);

        AnsiConsole.MarkupLine($"Vote requested: [{(voteRequested ? "green" : "red")}]{voteRequested}[/]");

        var result = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"\n[green]Quorum Result:[/green]");
        AnsiConsole.MarkupLine($"  Total Votes: {result.TotalVotes}");
        AnsiConsole.MarkupLine($"  Yes Votes: {result.YesVotes}");
        AnsiConsole.MarkupLine($"  No Votes: {result.NoVotes}");
        AnsiConsole.MarkupLine($"  Has Consensus: [{(result.HasConsensus ? "green" : "red")}]{result.HasConsensus}[/]");
        AnsiConsole.MarkupLine($"  Decision: {result.Decision}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        failoverService.FailoverOccurred += (sender, args) =>
        {
            AnsiConsole.MarkupLine($"[yellow]Failover Event: {args.FailedNodeId} -> {args.NewPrimaryNodeId}[/yellow]");
        };

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current primary node: {primaryNode.NodeId}[/yellow]");

            AnsiConsole.MarkupLine("[yellow]Checking if failover is needed...[/yellow]");
            var isNeeded = await failoverService.IsFailoverNeededAsync();

            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs : EventArgs
{
    public string FailedNodeId { get; }
    public string NewPrimaryNodeId { get; }
    public DateTime OccurredAt { get; }

    public FailoverEventArgs(string failedNodeId, string newPrimaryNodeId)
    {
        FailedNodeId = failedNodeId;
        NewPrimaryNodeId = newPrimaryNodeId;
        OccurredAt = DateTime.UtcNow;
    }
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.0" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.12.0" />
    <PackageReference Include="xunit" Version="2.9.0" />
    <PackageReference Include="xunit.runner.visualstudio" Version="2.8.2">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  SOLUTION_PATH: 'MultiDbSync/MultiDbSync.sln'
  CONSOLE_PROJECT: 'MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj'

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore ${{ env.SOLUTION_PATH }}
      
      - name: Build solution
        run: dotnet build ${{ env.SOLUTION_PATH }} --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test ${{ env.SOLUTION_PATH }} --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    strategy:
      matrix:
        runtime: 
          - linux-x64
          - linux-arm64
          - win-x64
          - win-arm64
          - osx-x64
          - osx-arm64
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET 10
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish for ${{ matrix.runtime }}
        run: |
          dotnet publish ${{ env.CONSOLE_PROJECT }} \
            --configuration Release \
            --runtime ${{ matrix.runtime }} \
            --self-contained true \
            --output ./publish/${{ matrix.runtime }} \
            /p:PublishSingleFile=true \
            /p:PublishTrimmed=false \
            /p:DebugType=none \
            /p:DebugSymbols=false
      
      - name: Create distribution package for ${{ matrix.runtime }}
        run: |
          cd publish
          if [[ "${{ matrix.runtime }}" == win-* ]]; then
            cd ${{ matrix.runtime }} && zip -r ../${{ matrix.runtime }}.zip . && cd ..
          else
            tar -czf ${{ matrix.runtime }}.tar.gz -C ${{ matrix.runtime }} .
          fi
      
      - name: Upload package
        uses: actions/upload-artifact@v4
        with:
          name: package-${{ matrix.runtime }}
          path: |
            publish/*.tar.gz
            publish/*.zip
          retention-days: 7

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: package-*
          merge-multiple: true
      
      - name: List artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -lah ./artifacts/
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d.%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << 'EOF' > release_notes.md
          # MultiDbSync Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: #${{ github.run_number }}
          - **.NET Version**: 10.0
          
          ## Commit Message
          ```
          ${{ steps.version.outputs.commit_msg }}
          ```
          
          ## Recent Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)' || echo "- Initial release")
          
          ## Platform Packages
          
          This release includes self-contained executables for multiple platforms:
          
          ### Linux
          - **linux-x64.tar.gz** - Linux x64 (Intel/AMD 64-bit)
          - **linux-arm64.tar.gz** - Linux ARM64 (Raspberry Pi 4+, ARM servers)
          
          ### Windows
          - **win-x64.zip** - Windows x64 (Intel/AMD 64-bit)
          - **win-arm64.zip** - Windows ARM64 (Surface Pro X, ARM PCs)
          
          ### macOS
          - **osx-x64.tar.gz** - macOS Intel (Intel Macs)
          - **osx-arm64.tar.gz** - macOS Apple Silicon (M1/M2/M3 Macs)
          
          ## Installation
          
          1. Download the appropriate package for your platform
          2. Extract the archive:
             - Linux/macOS: `tar -xzf <package>.tar.gz`
             - Windows: Use built-in ZIP extractor or `Expand-Archive`
          3. Run the executable:
             - Linux/macOS: `./MultiDbSync.Console` (may need `chmod +x MultiDbSync.Console` first)
             - Windows: `MultiDbSync.Console.exe`
          
          All builds are **self-contained** and include the .NET 10 runtime - no additional installation required!
          
          ## Project Structure
          
          This is a multi-database synchronization system built with CQRS pattern:
          - **MultiDbSync.Domain** - Core domain entities and interfaces
          - **MultiDbSync.Application** - CQRS commands, queries, and handlers
          - **MultiDbSync.Infrastructure** - Data access and repository implementations
          - **MultiDbSync.Console** - Console application entry point
          - **MultiDbSync.Tests** - Unit tests
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/*.tar.gz
            artifacts/*.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## ðŸŽ‰ Release Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Platform Packages" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- linux-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- win-arm64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- osx-arm64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.version.outputs.tag }})" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
    <PackageReference Include="Spectre.Console" Version="0.50.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("Is Primary");
        table.AddColumn("Health Score");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary ? "Yes" : "No",
                $"{node.HealthScore:F1}%");
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Forcing synchronization across all nodes...[/yellow]");
        var syncResult = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"[green]Sync Status:[/green]");
        AnsiConsole.MarkupLine($"  Total Nodes: {syncResult.TotalNodes}");
        AnsiConsole.MarkupLine($"  Successful: {syncResult.SuccessfulNodes}");
        AnsiConsole.MarkupLine($"  Failed: {syncResult.FailedNodes}");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var operationId = Guid.NewGuid();
        var operationDescription = "Promote node to primary";

        AnsiConsole.MarkupLine($"[yellow]Requesting vote for operation: {operationDescription}[/yellow]");

        var voteRequested = await quorumService.RequestVoteAsync(operationId, operationDescription);

        AnsiConsole.MarkupLine($"Vote requested: [{(voteRequested ? "green" : "red")}]{voteRequested}[/]");

        var result = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"\n[green]Quorum Result:[/green]");
        AnsiConsole.MarkupLine($"  Total Votes: {result.TotalVotes}");
        AnsiConsole.MarkupLine($"  Yes Votes: {result.YesVotes}");
        AnsiConsole.MarkupLine($"  No Votes: {result.NoVotes}");
        AnsiConsole.MarkupLine($"  Has Consensus: [{(result.HasConsensus ? "green" : "red")}]{result.HasConsensus}[/]");
        AnsiConsole.MarkupLine($"  Decision: {result.Decision}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        failoverService.FailoverOccurred += (sender, args) =>
        {
            AnsiConsole.MarkupLine($"[yellow]Failover Event: {args.FailedNodeId} -> {args.NewPrimaryNodeId}[/yellow]");
        };

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current primary node: {primaryNode.NodeId}[/yellow]");

            AnsiConsole.MarkupLine("[yellow]Checking if failover is needed...[/yellow]");
            var isNeeded = await failoverService.IsFailoverNeededAsync();

            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs : EventArgs
{
    public string FailedNodeId { get; }
    public string NewPrimaryNodeId { get; }
    public DateTime OccurredAt { get; }

    public FailoverEventArgs(string failedNodeId, string newPrimaryNodeId)
    {
        FailedNodeId = failedNodeId;
        NewPrimaryNodeId = newPrimaryNodeId;
        OccurredAt = DateTime.UtcNow;
    }
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.0" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.12.0" />
    <PackageReference Include="xunit" Version="2.9.0" />
    <PackageReference Include="xunit.runner.visualstudio" Version="2.8.2">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."




================================================================================
FILE: export.ps1
================================================================================
#requires -Version 7.0

<#
.SYNOPSIS
    Dumps all git-tracked files into a single text file for LLM analysis
.DESCRIPTION
    Creates llm/dump.txt containing all files that are:
    - In the git index (tracked)
    - Not deleted in the working copy
    - Not ignored by .gitignore
    Excludes bin/, obj/, and other git-ignored files automatically
#>

param(
    [string]$RepoPath = ".",
    [string]$OutputFile = "llm/dump.txt"
)

# Ensure we're in a git repository
Push-Location $RepoPath
try {
    $isGitRepo = git rev-parse --is-inside-work-tree 2>$null
    if ($isGitRepo -ne "true") {
        Write-Error "Not a git repository: $RepoPath"
        exit 1
    }

    # Create output directory if it doesn't exist
    $outputDir = Split-Path $OutputFile -Parent
    if ($outputDir -and -not (Test-Path $outputDir)) {
        New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        Write-Host "Created directory: $outputDir" -ForegroundColor Green
    }

    # Get all files that are:
    # 1. Tracked by git (in the index)
    # 2. Exist in the working directory (not deleted)
    $trackedFiles = git ls-files | Where-Object {
        Test-Path $_
    }

    if ($trackedFiles.Count -eq 0) {
        Write-Warning "No tracked files found"
        exit 0
    }

    Write-Host "Found $($trackedFiles.Count) tracked files" -ForegroundColor Cyan

    # Create the dump file
    $dumpContent = @()
    $processedCount = 0
    $skippedCount = 0

    foreach ($file in $trackedFiles) {
        # Get absolute path
        $fullPath = Resolve-Path $file -ErrorAction SilentlyContinue
        
        if (-not $fullPath -or -not (Test-Path $fullPath)) {
            $skippedCount++
            continue
        }

        # Try to read the file as text
        try {
            $content = Get-Content -Path $file -Raw -ErrorAction Stop
            
            # Add file separator and content
            $dumpContent += "=" * 80
            $dumpContent += "FILE: $file"
            $dumpContent += "=" * 80
            $dumpContent += $content
            $dumpContent += "`n`n"
            
            $processedCount++
            Write-Host "  âœ“ $file" -ForegroundColor Gray
        }
        catch {
            # Skip binary files or files that can't be read as text
            Write-Host "  âœ— Skipped (binary or unreadable): $file" -ForegroundColor Yellow
            $skippedCount++
        }
    }

    # Write to output file
    $dumpContent | Out-File -FilePath $OutputFile -Encoding UTF8 -Force

    Write-Host "`n" + ("=" * 80) -ForegroundColor Green
    Write-Host "âœ“ Dump created successfully!" -ForegroundColor Green
    Write-Host "  Output: $OutputFile" -ForegroundColor Cyan
    Write-Host "  Processed: $processedCount files" -ForegroundColor Cyan
    Write-Host "  Skipped: $skippedCount files" -ForegroundColor Cyan
    
    $outputFileInfo = Get-Item $OutputFile
    Write-Host "  Size: $([math]::Round($outputFileInfo.Length / 1MB, 2)) MB" -ForegroundColor Cyan
    Write-Host ("=" * 80) -ForegroundColor Green
}
finally {
    Pop-Location
}




================================================================================
FILE: llm/dump.txt
================================================================================
================================================================================
FILE: .github/workflows/build.yml
================================================================================
name: CI/CD - Build, Test, and Release

on:
  push:
    branches:
      - '**'
    tags:
      - 'v*'

env:
  DOTNET_VERSION: '8.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Restore dependencies
        run: dotnet restore
      
      - name: Build solution
        run: dotnet build --configuration Release --no-restore
      
      - name: Run tests
        run: dotnet test --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=test-results.trx" --collect:"XPlat Code Coverage"
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: '**/TestResults/**'
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: '**/bin/Release/**'

  package:
    name: Package Applications
    runs-on: ubuntu-latest
    needs: build-and-test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Publish applications
        run: |
          dotnet publish --configuration Release --output ./publish/linux-x64 --runtime linux-x64 --self-contained true
          dotnet publish --configuration Release --output ./publish/win-x64 --runtime win-x64 --self-contained true
          dotnet publish --configuration Release --output ./publish/osx-x64 --runtime osx-x64 --self-contained true
      
      - name: Create distribution packages
        run: |
          cd publish
          tar -czf linux-x64.tar.gz -C linux-x64 .
          cd win-x64 && zip -r ../win-x64.zip . && cd ..
          tar -czf osx-x64.tar.gz -C osx-x64 .
      
      - name: Upload packages
        uses: actions/upload-artifact@v4
        with:
          name: distribution-packages
          path: |
            publish/*.tar.gz
            publish/*.zip

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: package
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: distribution-packages
          path: ./artifacts
      
      - name: Generate version number
        id: version
        run: |
          # Use timestamp-based versioning for automatic releases
          VERSION="1.0.$(date +'%Y%m%d-%H%M%S')"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "tag=v$VERSION" >> $GITHUB_OUTPUT
          
          # Get commit info for release notes
          COMMIT_SHA=$(git rev-parse --short HEAD)
          COMMIT_MSG=$(git log -1 --pretty=%B)
          AUTHOR=$(git log -1 --pretty=format:'%an')
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "commit_msg<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMIT_MSG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "author=$AUTHOR" >> $GITHUB_OUTPUT
      
      - name: Generate release notes
        id: release_notes
        run: |
          cat << EOF > release_notes.md
          # Release ${{ steps.version.outputs.version }}
          
          ## Build Information
          - **Commit**: ${{ steps.version.outputs.commit_sha }}
          - **Author**: ${{ steps.version.outputs.author }}
          - **Branch**: ${GITHUB_REF#refs/heads/}
          - **Build Date**: $(date +'%Y-%m-%d %H:%M:%S UTC')
          - **Workflow Run**: ${{ github.run_number }}
          
          ## Commit Message
          \`\`\`
          ${{ steps.version.outputs.commit_msg }}
          \`\`\`
          
          ## Changes
          $(git log --oneline -10 --pretty=format:'- %s (%h)')
          
          ## Artifacts
          This release includes the following platform-specific builds:
          - **Linux x64**: Self-contained executable for Linux systems
          - **Windows x64**: Self-contained executable for Windows systems
          - **macOS x64**: Self-contained executable for macOS systems
          
          ## Installation
          1. Download the appropriate package for your platform
          2. Extract the archive
          3. Run the executable
          
          All builds are self-contained and include the .NET runtime.
          EOF
      
      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.version.outputs.tag }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            artifacts/linux-x64.tar.gz
            artifacts/win-x64.zip
            artifacts/osx-x64.tar.gz
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Release Summary
        run: |
          echo "## Release Created Successfully! ðŸŽ‰" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version**: ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tag**: ${{ steps.version.outputs.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ steps.version.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- linux-x64.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "- win-x64.zip" >> $GITHUB_STEP_SUMMARY
          echo "- osx-x64.tar.gz" >> $GITHUB_STEP_SUMMARY




================================================================================
FILE: .gitignore
================================================================================
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from `dotnet new gitignore`

# dotenv files
.env

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET
project.lock.json
project.fragment.lock.json
artifacts/

# Tye
.tye/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
# but not Directory.Build.rsp, as it configures directory-level build defaults
!Directory.Build.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
.idea/

##
## Visual studio for Mac
##


# globs
Makefile.in
*.userprefs
*.usertasks
config.make
config.status
aclocal.m4
install-sh
autom4te.cache/
*.tar.gz
tarballs/
test-results/

# content below from: https://github.com/github/gitignore/blob/main/Global/macOS.gitignore
# General
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon


# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# content below from: https://github.com/github/gitignore/blob/main/Global/Windows.gitignore
# Windows thumbnail cache files
Thumbs.db
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# Windows shortcuts
*.lnk

# Vim temporary swap files
*.swp

.dotnet/




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/CQRS/CqrsBase.cs
================================================================================
namespace MultiDbSync.Application.CQRS;

public sealed record CommandResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static CommandResult<T> Success(T data) => new(true, data, null);
    public static CommandResult<T> Failure(string error) => new(false, default, error);
}

public sealed record QueryResult<T>(
    bool IsSuccess,
    T? Data,
    string? ErrorMessage)
{
    public static QueryResult<T> Success(T data) => new(true, data, null);
    public static QueryResult<T> Failure(string error) => new(false, default, error);
}

public interface ICommandHandler<TCommand, TResult> where TCommand : ICommand
{
    Task<CommandResult<TResult>> HandleAsync(TCommand command, CancellationToken cancellationToken = default);
}

public interface IQueryHandler<TQuery, TResult> where TQuery : IQuery
{
    Task<QueryResult<TResult>> HandleAsync(TQuery query, CancellationToken cancellationToken = default);
}

public interface ICommand
{
    Guid Id { get; }
    DateTime CreatedAt { get; }
}

public interface IQuery
{
}

public abstract record Command : ICommand
{
    public Guid Id { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public abstract record Query : IQuery
{
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/ProductCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Application.Commands;

public sealed record CreateProductCommand(
    string Name,
    string Description,
    decimal Price,
    string Currency,
    int StockQuantity,
    string Category) : Command;

public sealed record UpdateProductPriceCommand(
    Guid ProductId,
    decimal NewPrice,
    string Currency) : Command;

public sealed record UpdateProductStockCommand(
    Guid ProductId,
    int NewQuantity) : Command;

public sealed record AdjustProductStockCommand(
    Guid ProductId,
    int Adjustment) : Command;

public sealed record DeleteProductCommand(Guid ProductId) : Command;

public sealed class CreateProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<CreateProductCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        CreateProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = new Product(
                command.Name,
                command.Description,
                new Money(command.Price, command.Currency),
                command.StockQuantity,
                command.Category);

            await productRepository.AddAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Create,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to create product: {ex.Message}");
        }
    }
}

public sealed class UpdateProductPriceCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductPriceCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductPriceCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdatePrice(new Money(command.NewPrice, command.Currency));

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product price: {ex.Message}");
        }
    }
}

public sealed class UpdateProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<UpdateProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        UpdateProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.UpdateStock(command.NewQuantity);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to update product stock: {ex.Message}");
        }
    }
}

public sealed class AdjustProductStockCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<AdjustProductStockCommand, Product>
{
    public async Task<CommandResult<Product>> HandleAsync(
        AdjustProductStockCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<Product>.Failure("Product not found");

            product.AdjustStock(command.Adjustment);

            await productRepository.UpdateAsync(product, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Update,
                cancellationToken);

            return CommandResult<Product>.Success(product);
        }
        catch (Exception ex)
        {
            return CommandResult<Product>.Failure($"Failed to adjust product stock: {ex.Message}");
        }
    }
}

public sealed class DeleteProductCommandHandler(
    IProductRepository productRepository,
    ISynchronizationService synchronizationService)
    : ICommandHandler<DeleteProductCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        DeleteProductCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(command.ProductId, cancellationToken);
            if (product is null)
                return CommandResult<bool>.Failure("Product not found");

            await productRepository.DeleteAsync(command.ProductId, cancellationToken);

            await synchronizationService.SyncEntityAsync(
                product,
                OperationType.Delete,
                cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to delete product: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Commands/SyncCommands.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Commands;

public sealed record AddDatabaseNodeCommand(
    string NodeId,
    string ConnectionString,
    int Priority = 0,
    bool IsPrimary = false) : Command;

public sealed record RemoveDatabaseNodeCommand(string NodeId) : Command;

public sealed record PromoteNodeCommand(string NodeId) : Command;

public sealed record DemoteNodeCommand(string NodeId) : Command;

public sealed record TriggerSyncCommand(string? NodeId = null) : Command;

public sealed record TriggerFailoverCommand(string? FailedNodeId = null) : Command;

public sealed class AddDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService? healthCheckService = null)
    : ICommandHandler<AddDatabaseNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        AddDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = new DatabaseNode(
                command.NodeId,
                command.ConnectionString,
                command.Priority,
                command.IsPrimary);

            if (healthCheckService is not null)
            {
                var health = await healthCheckService.CheckNodeHealthAsync(
                    command.NodeId,
                    cancellationToken);

                if (health.IsHealthy)
                {
                    node.MarkHealthy();
                }
            }

            await nodeRepository.AddAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to add database node: {ex.Message}");
        }
    }
}

public sealed class RemoveDatabaseNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository)
    : ICommandHandler<RemoveDatabaseNodeCommand, bool>
{
    public async Task<CommandResult<bool>> HandleAsync(
        RemoveDatabaseNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<bool>.Failure("Node not found");

            await nodeRepository.DeleteAsync(command.NodeId, cancellationToken);

            return CommandResult<bool>.Success(true);
        }
        catch (Exception ex)
        {
            return CommandResult<bool>.Failure($"Failed to remove database node: {ex.Message}");
        }
    }
}

public sealed class PromoteNodeCommandHandler(
    IDatabaseNodeRepository nodeRepository,
    IQuorumService quorumService)
    : ICommandHandler<PromoteNodeCommand, DatabaseNode>
{
    public async Task<CommandResult<DatabaseNode>> HandleAsync(
        PromoteNodeCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var node = await nodeRepository.GetByIdAsync(command.NodeId, cancellationToken);
            if (node is null)
                return CommandResult<DatabaseNode>.Failure("Node not found");

            var hasConsensus = await quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
                return CommandResult<DatabaseNode>.Failure("No quorum consensus for promotion");

            var allNodes = await nodeRepository.GetAllAsync(cancellationToken);
            foreach (var n in allNodes.Where(n => n.IsPrimary && n.NodeId != command.NodeId))
            {
                n.DemoteFromPrimary();
                await nodeRepository.UpdateAsync(n, cancellationToken);
            }

            node.PromoteToPrimary();
            await nodeRepository.UpdateAsync(node, cancellationToken);

            return CommandResult<DatabaseNode>.Success(node);
        }
        catch (Exception ex)
        {
            return CommandResult<DatabaseNode>.Failure($"Failed to promote node: {ex.Message}");
        }
    }
}

public sealed class TriggerSyncCommandHandler(
    ISynchronizationService syncService)
    : ICommandHandler<TriggerSyncCommand, SyncResult>
{
    public async Task<CommandResult<SyncResult>> HandleAsync(
        TriggerSyncCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await syncService.ForceSyncAsync(
                command.NodeId ?? string.Empty,
                cancellationToken);

            var result = await syncService.GetSyncStatusAsync(cancellationToken);

            return CommandResult<SyncResult>.Success(result);
        }
        catch (Exception ex)
        {
            return CommandResult<SyncResult>.Failure($"Failed to trigger sync: {ex.Message}");
        }
    }
}

public sealed class TriggerFailoverCommandHandler(
    IFailoverService failoverService)
    : ICommandHandler<TriggerFailoverCommand, string>
{
    public async Task<CommandResult<string>> HandleAsync(
        TriggerFailoverCommand command,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var success = await failoverService.TriggerFailoverAsync(
                command.FailedNodeId ?? string.Empty,
                cancellationToken);

            if (!success)
                return CommandResult<string>.Failure("Failover failed");

            var newPrimary = await failoverService.GetOptimalNodeAsync(cancellationToken);
            return CommandResult<string>.Success(newPrimary ?? "Unknown");
        }
        catch (Exception ex)
        {
            return CommandResult<string>.Failure($"Failed to trigger failover: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.Queries;

namespace MultiDbSync.Application;

public static class DependencyInjection
{
    public static IServiceCollection AddApplicationServices(this IServiceCollection services)
    {
        services.AddCQRSHandlers();
        return services;
    }

    private static IServiceCollection AddCQRSHandlers(this IServiceCollection services)
    {
        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<UpdateProductStockCommandHandler>();
        services.AddSingleton<AdjustProductStockCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();

        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<RemoveDatabaseNodeCommandHandler>();
        services.AddSingleton<PromoteNodeCommandHandler>();
        services.AddSingleton<TriggerSyncCommandHandler>();
        services.AddSingleton<TriggerFailoverCommandHandler>();

        services.AddSingleton<GetProductByIdQueryHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetProductsByCategoryQueryHandler>();
        services.AddSingleton<GetLowStockProductsQueryHandler>();
        services.AddSingleton<SearchProductsQueryHandler>();

        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
        services.AddSingleton<GetPrimaryNodesQueryHandler>();
        services.AddSingleton<GetNodeHealthQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<GetQuorumStatusQueryHandler>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/MultiDbSync.Application.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/ProductQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetProductByIdQuery(Guid ProductId) : Query;

public sealed record GetAllProductsQuery : Query;

public sealed record GetProductsByCategoryQuery(string Category) : Query;

public sealed record GetLowStockProductsQuery(int Threshold = 10) : Query;

public sealed record SearchProductsQuery(string SearchTerm) : Query;

public sealed class GetProductByIdQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductByIdQuery, Product?>
{
    public async Task<QueryResult<Product?>> HandleAsync(
        GetProductByIdQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var product = await productRepository.GetByIdAsync(query.ProductId, cancellationToken);
            return QueryResult<Product?>.Success(product);
        }
        catch (Exception ex)
        {
            return QueryResult<Product?>.Failure($"Failed to get product: {ex.Message}");
        }
    }
}

public sealed class GetAllProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetAllProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetAllProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products: {ex.Message}");
        }
    }
}

public sealed class GetProductsByCategoryQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetProductsByCategoryQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetProductsByCategoryQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetByCategoryAsync(query.Category, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get products by category: {ex.Message}");
        }
    }
}

public sealed class GetLowStockProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<GetLowStockProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        GetLowStockProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var products = await productRepository.GetLowStockProductsAsync(query.Threshold, cancellationToken);
            return QueryResult<IReadOnlyList<Product>>.Success(products);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to get low stock products: {ex.Message}");
        }
    }
}

public sealed class SearchProductsQueryHandler(
    IProductRepository productRepository)
    : IQueryHandler<SearchProductsQuery, IReadOnlyList<Product>>
{
    public async Task<QueryResult<IReadOnlyList<Product>>> HandleAsync(
        SearchProductsQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var allProducts = await productRepository.GetAllAsync(cancellationToken);
            var filteredProducts = allProducts
                .Where(p => p.Name.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase) ||
                           p.Description.Contains(query.SearchTerm, StringComparison.OrdinalIgnoreCase))
                .ToList();

            return QueryResult<IReadOnlyList<Product>>.Success(filteredProducts);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<Product>>.Failure($"Failed to search products: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Application/Queries/SyncQueries.cs
================================================================================
using MultiDbSync.Application.CQRS;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Application.Queries;

public sealed record GetAllNodesQuery : Query;

public sealed record GetHealthyNodesQuery : Query;

public sealed record GetPrimaryNodesQuery : Query;

public sealed record GetNodeHealthQuery(string NodeId) : Query;

public sealed record GetSyncStatusQuery : Query;

public sealed record GetQuorumStatusQuery(Guid OperationId) : Query;

public sealed class GetAllNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetAllNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetAllNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetAllAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get nodes: {ex.Message}");
        }
    }
}

public sealed class GetHealthyNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetHealthyNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetHealthyNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get healthy nodes: {ex.Message}");
        }
    }
}

public sealed class GetPrimaryNodesQueryHandler(
    IDatabaseNodeRepository nodeRepository)
    : IQueryHandler<GetPrimaryNodesQuery, IReadOnlyList<DatabaseNode>>
{
    public async Task<QueryResult<IReadOnlyList<DatabaseNode>>> HandleAsync(
        GetPrimaryNodesQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var nodes = await nodeRepository.GetPrimaryNodesAsync(cancellationToken);
            return QueryResult<IReadOnlyList<DatabaseNode>>.Success(nodes);
        }
        catch (Exception ex)
        {
            return QueryResult<IReadOnlyList<DatabaseNode>>.Failure($"Failed to get primary nodes: {ex.Message}");
        }
    }
}

public sealed class GetNodeHealthQueryHandler(
    IHealthCheckService healthCheckService)
    : IQueryHandler<GetNodeHealthQuery, HealthStatus>
{
    public async Task<QueryResult<HealthStatus>> HandleAsync(
        GetNodeHealthQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var health = await healthCheckService.CheckNodeHealthAsync(
                query.NodeId,
                cancellationToken);

            return QueryResult<HealthStatus>.Success(health);
        }
        catch (Exception ex)
        {
            return QueryResult<HealthStatus>.Failure($"Failed to check node health: {ex.Message}");
        }
    }
}

public sealed class GetSyncStatusQueryHandler(
    ISynchronizationService syncService)
    : IQueryHandler<GetSyncStatusQuery, SyncResult>
{
    public async Task<QueryResult<SyncResult>> HandleAsync(
        GetSyncStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await syncService.GetSyncStatusAsync(cancellationToken);
            return QueryResult<SyncResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<SyncResult>.Failure($"Failed to get sync status: {ex.Message}");
        }
    }
}

public sealed class GetQuorumStatusQueryHandler(
    IQuorumService quorumService)
    : IQueryHandler<GetQuorumStatusQuery, QuorumResult>
{
    public async Task<QueryResult<QuorumResult>> HandleAsync(
        GetQuorumStatusQuery query,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var status = await quorumService.GetQuorumResultAsync(
                query.OperationId,
                cancellationToken);

            return QueryResult<QuorumResult>.Success(status);
        }
        catch (Exception ex)
        {
            return QueryResult<QuorumResult>.Failure($"Failed to get quorum status: {ex.Message}");
        }
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/MultiDbSync.Console.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Console" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
    <PackageReference Include="Spectre.Console" Version="0.50.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Console/Program.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using MultiDbSync.Application;
using MultiDbSync.Application.Commands;
using MultiDbSync.Application.CQRS;
using MultiDbSync.Application.Queries;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using Spectre.Console;

namespace MultiDbSync.Console;

class Program
{
    private static IServiceProvider? _serviceProvider;
    private static string _databasePath = Path.Combine(AppContext.BaseDirectory, "databases");

    static async Task<int> Main(string[] args)
    {
        System.Console.WriteLine("Multi-Database Synchronization System Demo");
        System.Console.WriteLine("============================================\n");

        try
        {
            Directory.CreateDirectory(_databasePath);

            var services = new ServiceCollection();
            ConfigureServices(services);
            _serviceProvider = services.BuildServiceProvider();

            await InitializeDatabaseAsync();

            await RunDemoAsync();

            return 0;
        }
        catch (Exception ex)
        {
            AnsiConsole.WriteException(ex);
            return 1;
        }
    }

    private static void ConfigureServices(IServiceCollection services)
    {
        services.AddLogging(builder =>
        {
            builder.AddConsole();
            builder.SetMinimumLevel(LogLevel.Information);
        });

        services.AddInfrastructureServices(_databasePath);
        services.AddApplicationServices();

        services.AddSingleton<CreateProductCommandHandler>();
        services.AddSingleton<UpdateProductPriceCommandHandler>();
        services.AddSingleton<DeleteProductCommandHandler>();
        services.AddSingleton<GetAllProductsQueryHandler>();
        services.AddSingleton<GetSyncStatusQueryHandler>();
        services.AddSingleton<AddDatabaseNodeCommandHandler>();
        services.AddSingleton<GetAllNodesQueryHandler>();
        services.AddSingleton<GetHealthyNodesQueryHandler>();
    }

    private static async Task InitializeDatabaseAsync()
    {
        AnsiConsole.MarkupLine("[cyan]Initializing database...[/cyan]");

        using var scope = _serviceProvider!.CreateScope();
        var context = scope.ServiceProvider.GetRequiredService<MultiDbContext>();
        await context.Database.EnsureCreatedAsync();

        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();
        if (nodes.Count == 0)
        {
            var node1 = new Domain.Entities.DatabaseNode("node1", "Data Source=node1.db", 1, true);
            var node2 = new Domain.Entities.DatabaseNode("node2", "Data Source=node2.db", 2, false);
            var node3 = new Domain.Entities.DatabaseNode("node3", "Data Source=node3.db", 3, false);

            node1.MarkHealthy();
            node2.MarkHealthy();
            node3.MarkHealthy();

            await nodeRepo.AddAsync(node1);
            await nodeRepo.AddAsync(node2);
            await nodeRepo.AddAsync(node3);
        }

        AnsiConsole.MarkupLine("[green]Database initialized successfully![/green]\n");
    }

    private static async Task RunDemoAsync()
    {
        var exit = false;

        while (!exit)
        {
            var choice = AnsiConsole.Prompt(
                new SelectionPrompt<string>()
                    .Title("Select an operation:")
                    .AddChoices([
                        "1. CRUD Operations (CQRS)",
                        "2. Database Synchronization",
                        "3. Quorum Consensus",
                        "4. Automatic Failover",
                        "5. Node Health Monitoring",
                        "6. Run All Demos",
                        "0. Exit"
                    ]));

            switch (choice)
            {
                case "1. CRUD Operations (CQRS)":
                    await RunCrudDemoAsync();
                    break;
                case "2. Database Synchronization":
                    await RunSyncDemoAsync();
                    break;
                case "3. Quorum Consensus":
                    await RunQuorumDemoAsync();
                    break;
                case "4. Automatic Failover":
                    await RunFailoverDemoAsync();
                    break;
                case "5. Node Health Monitoring":
                    await RunHealthCheckDemoAsync();
                    break;
                case "6. Run All Demos":
                    await RunAllDemosAsync();
                    break;
                case "0. Exit":
                    exit = true;
                    break;
            }
        }
    }

    private static async Task RunCrudDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== CQRS CRUD Operations Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var createHandler = scope.ServiceProvider.GetRequiredService<CreateProductCommandHandler>();
        var getAllHandler = scope.ServiceProvider.GetRequiredService<GetAllProductsQueryHandler>();
        var updateHandler = scope.ServiceProvider.GetRequiredService<UpdateProductPriceCommandHandler>();
        var deleteHandler = scope.ServiceProvider.GetRequiredService<DeleteProductCommandHandler>();

        AnsiConsole.MarkupLine("[yellow]Creating products...[/yellow]");
        var createResult1 = await createHandler.HandleAsync(
            new CreateProductCommand("Laptop", "High-performance laptop", 1299.99m, "USD", 50, "Electronics"));
        var createResult2 = await createHandler.HandleAsync(
            new CreateProductCommand("Mouse", "Wireless mouse", 29.99m, "USD", 200, "Electronics"));
        var createResult3 = await createHandler.HandleAsync(
            new CreateProductCommand("Keyboard", "Mechanical keyboard", 89.99m, "USD", 150, "Electronics"));

        if (createResult1.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult1.Data?.Name} - {createResult1.Data?.Price}[/green]");
        if (createResult2.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult2.Data?.Name} - {createResult2.Data?.Price}[/green]");
        if (createResult3.IsSuccess)
            AnsiConsole.MarkupLine($"[green]Created: {createResult3.Data?.Name} - {createResult3.Data?.Price}[/green]");

        AnsiConsole.MarkupLine("\n[yellow]Querying all products...[/yellow]");
        var getAllResult = await getAllHandler.HandleAsync(new GetAllProductsQuery());

        if (getAllResult.IsSuccess && getAllResult.Data is { })
        {
            var table = new Table();
            table.AddColumn("Name");
            table.AddColumn("Price");
            table.AddColumn("Stock");
            table.AddColumn("Category");

            foreach (var product in getAllResult.Data)
            {
                table.AddRow(
                    product.Name,
                    product.Price.ToString(),
                    product.StockQuantity.ToString(),
                    product.Category);
            }

            AnsiConsole.Write(table);
        }

        if (createResult1.IsSuccess && createResult1.Data is { })
        {
            var productId = createResult1.Data.Id;
            AnsiConsole.MarkupLine($"\n[yellow]Updating price for '{createResult1.Data.Name}'...[/yellow]");

            var updateResult = await updateHandler.HandleAsync(
                new UpdateProductPriceCommand(productId, 1199.99m, "USD"));

            if (updateResult.IsSuccess)
                AnsiConsole.MarkupLine($"[green]Updated price to: {updateResult.Data?.Price}[/green]");

            AnsiConsole.MarkupLine($"\n[yellow]Deleting product...[/yellow]");
            var deleteResult = await deleteHandler.HandleAsync(new DeleteProductCommand(productId));

            if (deleteResult.IsSuccess)
                AnsiConsole.MarkupLine("[green]Product deleted successfully![/green]");
        }

        AnsiConsole.MarkupLine("\n[bold green]CQRS Demo completed![/bold green]\n");
    }

    private static async Task RunSyncDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Database Synchronization Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var syncService = scope.ServiceProvider.GetRequiredService<ISynchronizationService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        var table = new Table();
        table.AddColumn("Node ID");
        table.AddColumn("Status");
        table.AddColumn("Is Primary");
        table.AddColumn("Health Score");

        foreach (var node in nodes)
        {
            table.AddRow(
                node.NodeId,
                node.Status.ToString(),
                node.IsPrimary ? "Yes" : "No",
                $"{node.HealthScore:F1}%");
        }

        AnsiConsole.Write(table);

        AnsiConsole.MarkupLine("\n[yellow]Forcing synchronization across all nodes...[/yellow]");
        var syncResult = await syncService.GetSyncStatusAsync();

        AnsiConsole.MarkupLine($"[green]Sync Status:[/green]");
        AnsiConsole.MarkupLine($"  Total Nodes: {syncResult.TotalNodes}");
        AnsiConsole.MarkupLine($"  Successful: {syncResult.SuccessfulNodes}");
        AnsiConsole.MarkupLine($"  Failed: {syncResult.FailedNodes}");

        AnsiConsole.MarkupLine("\n[bold green]Synchronization Demo completed![/bold green]\n");
    }

    private static async Task RunQuorumDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Quorum Consensus Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var quorumService = scope.ServiceProvider.GetRequiredService<IQuorumService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var operationId = Guid.NewGuid();
        var operationDescription = "Promote node to primary";

        AnsiConsole.MarkupLine($"[yellow]Requesting vote for operation: {operationDescription}[/yellow]");

        var voteRequested = await quorumService.RequestVoteAsync(operationId, operationDescription);

        AnsiConsole.MarkupLine($"Vote requested: [{(voteRequested ? "green" : "red")}]{voteRequested}[/]");

        var result = await quorumService.GetQuorumResultAsync(operationId);

        AnsiConsole.MarkupLine($"\n[green]Quorum Result:[/green]");
        AnsiConsole.MarkupLine($"  Total Votes: {result.TotalVotes}");
        AnsiConsole.MarkupLine($"  Yes Votes: {result.YesVotes}");
        AnsiConsole.MarkupLine($"  No Votes: {result.NoVotes}");
        AnsiConsole.MarkupLine($"  Has Consensus: [{(result.HasConsensus ? "green" : "red")}]{result.HasConsensus}[/]");
        AnsiConsole.MarkupLine($"  Decision: {result.Decision}");

        AnsiConsole.MarkupLine("\n[bold green]Quorum Demo completed![/bold green]\n");
    }

    private static async Task RunFailoverDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Automatic Failover Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var failoverService = scope.ServiceProvider.GetRequiredService<IFailoverService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        failoverService.FailoverOccurred += (sender, args) =>
        {
            AnsiConsole.MarkupLine($"[yellow]Failover Event: {args.FailedNodeId} -> {args.NewPrimaryNodeId}[/yellow]");
        };

        var nodes = await nodeRepo.GetAllAsync();
        var primaryNode = nodes.FirstOrDefault(n => n.IsPrimary);

        if (primaryNode is { })
        {
            AnsiConsole.MarkupLine($"[yellow]Current primary node: {primaryNode.NodeId}[/yellow]");

            AnsiConsole.MarkupLine("[yellow]Checking if failover is needed...[/yellow]");
            var isNeeded = await failoverService.IsFailoverNeededAsync();

            AnsiConsole.MarkupLine($"Failover needed: [{(isNeeded ? "green" : "yellow")}]{isNeeded}[/]");

            var optimalNode = await failoverService.GetOptimalNodeAsync();
            AnsiConsole.MarkupLine($"Optimal node for failover: [green]{optimalNode ?? "None"}[/]");
        }

        AnsiConsole.MarkupLine("\n[bold green]Failover Demo completed![/bold green]\n");
    }

    private static async Task RunHealthCheckDemoAsync()
    {
        AnsiConsole.MarkupLine("\n[bold cyan]=== Node Health Monitoring Demo ===[/bold cyan]\n");

        using var scope = _serviceProvider!.CreateScope();
        var healthCheckService = scope.ServiceProvider.GetRequiredService<IHealthCheckService>();
        var nodeRepo = scope.ServiceProvider.GetRequiredService<IDatabaseNodeRepository>();

        var nodes = await nodeRepo.GetAllAsync();

        foreach (var node in nodes)
        {
            var health = await healthCheckService.CheckNodeHealthAsync(node.NodeId);

            AnsiConsole.MarkupLine($"[yellow]Node: {health.NodeId}[/yellow]");
            AnsiConsole.MarkupLine($"  Is Healthy: [{(health.IsHealthy ? "green" : "red")}]{health.IsHealthy}[/]");
            AnsiConsole.MarkupLine($"  Response Time: {health.ResponseTimeMs:F2}ms");
            if (health.ErrorMessage is { })
                AnsiConsole.MarkupLine($"  Error: [red]{health.ErrorMessage}[/]");
            AnsiConsole.WriteLine();
        }

        AnsiConsole.MarkupLine("[bold green]Health Check Demo completed![/bold green]\n");
    }

    private static async Task RunAllDemosAsync()
    {
        AnsiConsole.MarkupLine("[bold magenta]Running all demos...[/bold magenta]\n");

        await RunCrudDemoAsync();
        await RunSyncDemoAsync();
        await RunQuorumDemoAsync();
        await RunFailoverDemoAsync();
        await RunHealthCheckDemoAsync();

        AnsiConsole.MarkupLine("[bold magenta]=== All Demos Completed! ===[/bold magenta]\n");
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/Entities.cs
================================================================================
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Domain.Entities;

public sealed class Product
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public string Description { get; private set; } = string.Empty;
    public Money Price { get; private set; } = Money.Zero;
    public int StockQuantity { get; private set; }
    public string Category { get; private set; } = string.Empty;
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Product() { }

    public Product(
        string name,
        string description,
        Money price,
        int stockQuantity,
        string category)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Price = price ?? throw new ArgumentNullException(nameof(price));
        StockQuantity = stockQuantity;
        Category = category ?? "General";
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdatePrice(Money newPrice)
    {
        Price = newPrice ?? throw new ArgumentNullException(nameof(newPrice));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateStock(int quantity)
    {
        if (quantity < 0)
            throw new ArgumentException("Stock quantity cannot be negative", nameof(quantity));
        StockQuantity = quantity;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void AdjustStock(int adjustment)
    {
        var newStock = StockQuantity + adjustment;
        if (newStock < 0)
            throw new InvalidOperationException("Insufficient stock");
        StockQuantity = newStock;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateDetails(string name, string description, string category)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Description = description ?? string.Empty;
        Category = category ?? "General";
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}

public sealed class Order
{
    public Guid Id { get; private set; }
    public Guid CustomerId { get; private set; }
    public OrderStatus Status { get; private set; }
    public Money TotalAmount { get; private set; } = Money.Zero;
    public Address ShippingAddress { get; private set; } = null!;
    public DateTime CreatedAt { get; private set; }
    public DateTime? ShippedAt { get; private set; }
    public DateTime? DeliveredAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private readonly List<OrderItem> _items = new();
    public IReadOnlyCollection<OrderItem> Items => _items.AsReadOnly();

    private Order() { }

    public Order(
        Guid customerId,
        Address shippingAddress)
    {
        Id = Guid.NewGuid();
        CustomerId = customerId;
        Status = OrderStatus.Pending;
        ShippingAddress = shippingAddress ?? throw new ArgumentNullException(nameof(shippingAddress));
        TotalAmount = Money.Zero;
        CreatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void AddItem(Product product, int quantity)
    {
        if (quantity <= 0)
            throw new ArgumentException("Quantity must be positive", nameof(quantity));

        var existingItem = _items.FirstOrDefault(i => i.ProductId == product.Id);
        if (existingItem != null)
        {
            existingItem.IncreaseQuantity(quantity);
        }
        else
        {
            _items.Add(new OrderItem(Id, product.Id, product.Price, quantity));
        }

        RecalculateTotal();
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void RemoveItem(Guid productId)
    {
        var item = _items.FirstOrDefault(i => i.ProductId == productId);
        if (item != null)
        {
            _items.Remove(item);
            RecalculateTotal();
            UpdatedAt = DateTime.UtcNow;
            IncrementVersion();
        }
    }

    public void MarkAsShipped()
    {
        if (Status != OrderStatus.Pending)
            throw new InvalidOperationException("Only pending orders can be shipped");
        Status = OrderStatus.Shipped;
        ShippedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void MarkAsDelivered()
    {
        if (Status != OrderStatus.Shipped)
            throw new InvalidOperationException("Only shipped orders can be delivered");
        Status = OrderStatus.Delivered;
        DeliveredAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void Cancel()
    {
        if (Status == OrderStatus.Delivered)
            throw new InvalidOperationException("Cannot cancel delivered orders");
        Status = OrderStatus.Cancelled;
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void RecalculateTotal()
    {
        TotalAmount = _items.Aggregate(
            Money.Zero,
            (total, item) => total + item.Subtotal);
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }

    private DateTime UpdatedAt { get; set; }
}

public sealed class OrderItem
{
    public Guid Id { get; private set; }
    public Guid OrderId { get; private set; }
    public Guid ProductId { get; private set; }
    public Money UnitPrice { get; private set; } = Money.Zero;
    public int Quantity { get; private set; }
    public Money Subtotal => UnitPrice * Quantity;

    private OrderItem() { }

    public OrderItem(Guid orderId, Guid productId, Money unitPrice, int quantity)
    {
        Id = Guid.NewGuid();
        OrderId = orderId;
        ProductId = productId;
        UnitPrice = unitPrice ?? throw new ArgumentNullException(nameof(unitPrice));
        Quantity = quantity;
    }

    public void IncreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        Quantity += amount;
    }

    public void DecreaseQuantity(int amount)
    {
        if (amount <= 0)
            throw new ArgumentException("Amount must be positive", nameof(amount));
        if (amount > Quantity)
            throw new ArgumentException("Cannot decrease more than available quantity", nameof(amount));
        Quantity -= amount;
    }
}

public enum OrderStatus
{
    Pending,
    Shipped,
    Delivered,
    Cancelled
}

public sealed class Customer
{
    public Guid Id { get; private set; }
    public string Name { get; private set; } = string.Empty;
    public EmailAddress Email { get; private set; } = null!;
    public Address? ShippingAddress { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime UpdatedAt { get; private set; }
    public byte[] Version { get; private set; } = [];

    private Customer() { }

    public Customer(string name, EmailAddress email)
    {
        Id = Guid.NewGuid();
        Name = name ?? throw new ArgumentNullException(nameof(name));
        Email = email ?? throw new ArgumentNullException(nameof(email));
        CreatedAt = DateTime.UtcNow;
        UpdatedAt = DateTime.UtcNow;
        Version = Guid.NewGuid().ToByteArray();
    }

    public void UpdateShippingAddress(Address address)
    {
        ShippingAddress = address ?? throw new ArgumentNullException(nameof(address));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    public void UpdateName(string name)
    {
        Name = name ?? throw new ArgumentNullException(nameof(name));
        UpdatedAt = DateTime.UtcNow;
        IncrementVersion();
    }

    private void IncrementVersion()
    {
        Version = Guid.NewGuid().ToByteArray();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Entities/SyncEntities.cs
================================================================================
namespace MultiDbSync.Domain.Entities;

public sealed class DatabaseNode
{
    public string NodeId { get; private set; } = string.Empty;
    public string ConnectionString { get; private set; } = string.Empty;
    public NodeStatus Status { get; private set; }
    public bool IsPrimary { get; private set; }
    public int Priority { get; private set; }
    public DateTime LastHeartbeat { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public int SuccessCount { get; private set; }
    public int FailureCount { get; private set; }
    public double HealthScore => SuccessCount + FailureCount > 0
        ? (double)SuccessCount / (SuccessCount + FailureCount) * 100
        : 100;

    private DatabaseNode() { }

    public DatabaseNode(
        string nodeId,
        string connectionString,
        int priority = 0,
        bool isPrimary = false)
    {
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        ConnectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        Status = NodeStatus.Unknown;
        IsPrimary = isPrimary;
        Priority = priority;
        LastHeartbeat = DateTime.UtcNow;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkHealthy()
    {
        Status = NodeStatus.Healthy;
        LastHeartbeat = DateTime.UtcNow;
        SuccessCount++;
    }

    public void MarkUnhealthy()
    {
        Status = NodeStatus.Unhealthy;
        LastHeartbeat = DateTime.UtcNow;
        FailureCount++;
    }

    public void MarkUnknown()
    {
        Status = NodeStatus.Unknown;
    }

    public void PromoteToPrimary()
    {
        IsPrimary = true;
    }

    public void DemoteFromPrimary()
    {
        IsPrimary = false;
    }

    public bool IsAlive => (DateTime.UtcNow - LastHeartbeat).TotalSeconds < 30;
}

public enum NodeStatus
{
    Unknown,
    Healthy,
    Unhealthy,
    Offline
}

public sealed class SyncOperation
{
    public Guid Id { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public OperationType Type { get; private set; }
    public string EntityType { get; private set; } = string.Empty;
    public string EntityId { get; private set; } = string.Empty;
    public string Payload { get; private set; } = string.Empty;
    public SyncStatus Status { get; private set; }
    public DateTime CreatedAt { get; private set; }
    public DateTime? CompletedAt { get; private set; }
    public string? ErrorMessage { get; private set; }
    public int RetryCount { get; private set; }

    private SyncOperation() { }

    public SyncOperation(
        string nodeId,
        OperationType type,
        string entityType,
        string entityId,
        string payload)
    {
        Id = Guid.NewGuid();
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Type = type;
        EntityType = entityType ?? throw new ArgumentNullException(nameof(entityType));
        EntityId = entityId ?? throw new ArgumentNullException(nameof(entityId));
        Payload = payload ?? throw new ArgumentNullException(nameof(payload));
        Status = SyncStatus.Pending;
        CreatedAt = DateTime.UtcNow;
    }

    public void MarkInProgress()
    {
        Status = SyncStatus.InProgress;
    }

    public void MarkCompleted()
    {
        Status = SyncStatus.Completed;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkFailed(string errorMessage)
    {
        Status = SyncStatus.Failed;
        ErrorMessage = errorMessage;
        CompletedAt = DateTime.UtcNow;
    }

    public void MarkPending()
    {
        Status = SyncStatus.Pending;
        RetryCount++;
    }

    public bool CanRetry => RetryCount < 3 && Status == SyncStatus.Failed;
}

public enum OperationType
{
    Create,
    Update,
    Delete
}

public enum SyncStatus
{
    Pending,
    InProgress,
    Completed,
    Failed
}

public sealed class QuorumVote
{
    public Guid Id { get; private set; }
    public Guid OperationId { get; private set; }
    public string NodeId { get; private set; } = string.Empty;
    public bool Vote { get; private set; }
    public string? Reason { get; private set; }
    public DateTime VotedAt { get; private set; }

    private QuorumVote() { }

    public QuorumVote(
        Guid operationId,
        string nodeId,
        bool vote,
        string? reason = null)
    {
        Id = Guid.NewGuid();
        OperationId = operationId;
        NodeId = nodeId ?? throw new ArgumentNullException(nameof(nodeId));
        Vote = vote;
        Reason = reason;
        VotedAt = DateTime.UtcNow;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IRepositories.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<T> AddAsync(T entity, CancellationToken cancellationToken = default);
    Task UpdateAsync(T entity, CancellationToken cancellationToken = default);
    Task DeleteAsync(Guid id, CancellationToken cancellationToken = default);
    Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default);
}

public interface IProductRepository : IRepository<Product>
{
    Task<IReadOnlyList<Product>> GetByCategoryAsync(string category, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Product>> GetLowStockProductsAsync(int threshold, CancellationToken cancellationToken = default);
    Task<Product?> GetByNameAsync(string name, CancellationToken cancellationToken = default);
}

public interface IOrderRepository : IRepository<Order>
{
    Task<IReadOnlyList<Order>> GetByCustomerIdAsync(Guid customerId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetByStatusAsync(OrderStatus status, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Order>> GetRecentOrdersAsync(int count, CancellationToken cancellationToken = default);
}

public interface ICustomerRepository : IRepository<Customer>
{
    Task<Customer?> GetByEmailAsync(string email, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<Customer>> SearchByNameAsync(string namePattern, CancellationToken cancellationToken = default);
}

public interface ISyncOperationRepository
{
    Task<SyncOperation?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task AddAsync(SyncOperation operation, CancellationToken cancellationToken = default);
    Task UpdateAsync(SyncOperation operation, CancellationToken cancellationToken = default);
}

public interface IDatabaseNodeRepository
{
    Task<DatabaseNode?> GetByIdAsync(string nodeId, CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetAllAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(CancellationToken cancellationToken = default);
    Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(CancellationToken cancellationToken = default);
    Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default);
    Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default);
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/Interfaces/IServices.cs
================================================================================
using MultiDbSync.Domain.Entities;

namespace MultiDbSync.Domain.Interfaces;

public interface ISynchronizationService
{
    Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class;

    Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default);
}

public interface IQuorumService
{
    Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default);

    Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default);

    int GetRequiredVotes();
}

public interface IFailoverService
{
    Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default);

    Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default);

    Task MonitorNodesAsync(CancellationToken cancellationToken = default);

    event EventHandler<FailoverEventArgs>? FailoverOccurred;
}

public interface IHealthCheckService
{
    Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default);

    Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default);

    Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default);
}

public record SyncResult(
    int TotalNodes,
    int SuccessfulNodes,
    int FailedNodes,
    IReadOnlyList<string> Errors);

public record QuorumResult(
    Guid OperationId,
    int TotalVotes,
    int YesVotes,
    int NoVotes,
    bool HasConsensus,
    QuorumDecision Decision);

public record HealthStatus(
    string NodeId,
    bool IsHealthy,
    double ResponseTimeMs,
    string? ErrorMessage);

public class FailoverEventArgs : EventArgs
{
    public string FailedNodeId { get; }
    public string NewPrimaryNodeId { get; }
    public DateTime OccurredAt { get; }

    public FailoverEventArgs(string failedNodeId, string newPrimaryNodeId)
    {
        FailedNodeId = failedNodeId;
        NewPrimaryNodeId = newPrimaryNodeId;
        OccurredAt = DateTime.UtcNow;
    }
}

public enum QuorumDecision
{
    Approved,
    Rejected,
    Pending
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/MultiDbSync.Domain.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Domain/ValueObjects/ValueObjects.cs
================================================================================
namespace MultiDbSync.Domain.ValueObjects;

public sealed record Money(decimal Amount, string Currency)
{
    public static Money Zero => new(0, "USD");

    public static Money operator +(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot add money with different currencies");
        return new Money(left.Amount + right.Amount, left.Currency);
    }

    public static Money operator -(Money left, Money right)
    {
        if (left.Currency != right.Currency)
            throw new InvalidOperationException("Cannot subtract money with different currencies");
        return new Money(left.Amount - right.Amount, left.Currency);
    }

    public static Money operator *(Money money, int multiplier)
    {
        return new Money(money.Amount * multiplier, money.Currency);
    }

    public static Money operator *(int multiplier, Money money)
    {
        return money * multiplier;
    }

    public override string ToString() => $"{Amount:C} {Currency}";
}

public sealed record Address(
    string Street,
    string City,
    string State,
    string PostalCode,
    string Country)
{
    public string FullAddress => $"{Street}, {City}, {State} {PostalCode}, {Country}";
}

public sealed record EmailAddress
{
    public string Value { get; }

    public EmailAddress(string value)
    {
        if (string.IsNullOrWhiteSpace(value))
            throw new ArgumentException("Email cannot be empty", nameof(value));
        if (!value.Contains('@'))
            throw new ArgumentException("Invalid email format", nameof(value));
        Value = value.ToLowerInvariant();
    }

    public static implicit operator string(EmailAddress email) => email.Value;
    public override string ToString() => Value;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Data/MultiDbContext.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;

namespace MultiDbSync.Infrastructure.Data;

public class MultiDbContext(string connectionString) : DbContext
{
    public DbSet<Product> Products => Set<Product>();
    public DbSet<Order> Orders => Set<Order>();
    public DbSet<OrderItem> OrderItems => Set<OrderItem>();
    public DbSet<Customer> Customers => Set<Customer>();
    public DbSet<DatabaseNode> DatabaseNodes => Set<DatabaseNode>();
    public DbSet<SyncOperation> SyncOperations => Set<SyncOperation>();

    private readonly string _connectionString = connectionString;

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        optionsBuilder.UseSqlite(_connectionString);
    }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Product>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Description).HasMaxLength(1000);
            entity.Property(e => e.Category).HasMaxLength(100);
            entity.Property(e => e.Price).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Order>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.TotalAmount).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
            entity.Property(e => e.ShippingAddress).HasConversion(
                v => $"{v.Street}|{v.City}|{v.State}|{v.PostalCode}|{v.Country}",
                v => new Address(v.Split('|')[0], v.Split('|')[1], v.Split('|')[2], v.Split('|')[3], v.Split('|')[4]))
                .HasMaxLength(200);
            entity.HasMany(e => e.Items)
                  .WithOne()
                  .HasForeignKey(e => e.OrderId);
        });

        modelBuilder.Entity<OrderItem>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.UnitPrice).HasConversion(
                v => $"{v.Amount}|{v.Currency}",
                v => new Money(decimal.Parse(v.Split('|')[0]), v.Split('|')[1]))
                .HasMaxLength(50);
        });

        modelBuilder.Entity<Customer>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Name).IsRequired().HasMaxLength(200);
            entity.Property(e => e.Email).HasConversion(
                v => v.Value,
                v => new EmailAddress(v))
                .HasMaxLength(255);
        });

        modelBuilder.Entity<DatabaseNode>(entity =>
        {
            entity.HasKey(e => e.NodeId);
            entity.Property(e => e.ConnectionString).IsRequired();
            entity.Property(e => e.Status).HasConversion<string>();
        });

        modelBuilder.Entity<SyncOperation>(entity =>
        {
            entity.HasKey(e => e.Id);
            entity.Property(e => e.Type).HasConversion<string>();
            entity.Property(e => e.Status).HasConversion<string>();
        });
    }
}

public class MultiDbContextFactory
{
    private readonly string _baseConnectionString;
    private readonly string _databasePath;

    public MultiDbContextFactory(string baseConnectionString, string databasePath)
    {
        _baseConnectionString = baseConnectionString;
        _databasePath = databasePath;
    }

    public MultiDbContext CreateDbContext(string nodeId)
    {
        var dbPath = Path.Combine(_databasePath, $"{nodeId}.db");
        var connectionString = $"Data Source={dbPath}";
        return new MultiDbContext(connectionString);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/DependencyInjection.cs
================================================================================
using Microsoft.Extensions.DependencyInjection;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;
using MultiDbSync.Infrastructure.Services;

namespace MultiDbSync.Infrastructure;

public static class DependencyInjection
{
    public static IServiceCollection AddInfrastructureServices(
        this IServiceCollection services,
        string databasePath)
    {
        services.AddSingleton(_ => new MultiDbContextFactory(
            "Data Source=",
            databasePath));

        services.AddSingleton<MultiDbContext>(sp =>
        {
            var factory = sp.GetRequiredService<MultiDbContextFactory>();
            return factory.CreateDbContext("primary");
        });

        services.AddScoped<IProductRepository, ProductRepository>();
        services.AddScoped<IOrderRepository, OrderRepository>();
        services.AddScoped<ICustomerRepository, CustomerRepository>();
        services.AddScoped<IDatabaseNodeRepository, DatabaseNodeRepository>();
        services.AddScoped<ISyncOperationRepository, SyncOperationRepository>();

        services.AddSingleton<IHealthCheckService, HealthCheckService>();
        services.AddSingleton<IQuorumService, QuorumService>();
        services.AddSingleton<ISynchronizationService, SynchronizationService>();
        services.AddSingleton<IFailoverService, FailoverService>();

        return services;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/MultiDbSync.Infrastructure.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.EntityFrameworkCore.Sqlite" Version="10.0.0" />
    <PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="10.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Options" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Repositories/Repositories.cs
================================================================================
using Microsoft.EntityFrameworkCore;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;

namespace MultiDbSync.Infrastructure.Repositories;

public class Repository<T>(MultiDbContext context) : IRepository<T> where T : class
{
    protected readonly MultiDbContext _context = context;
    protected readonly DbSet<T> _dbSet = context.Set<T>();

    public virtual async Task<T?> GetByIdAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([id], cancellationToken);
    }

    public virtual async Task<IReadOnlyList<T>> GetAllAsync(CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public virtual async Task<T> AddAsync(T entity, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(entity, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
        return entity;
    }

    public virtual async Task UpdateAsync(T entity, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(entity);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public virtual async Task DeleteAsync(Guid id, CancellationToken cancellationToken = default)
    {
        var entity = await GetByIdAsync(id, cancellationToken);
        if (entity is not null)
        {
            _dbSet.Remove(entity);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public virtual async Task<bool> ExistsAsync(Guid id, CancellationToken cancellationToken = default)
    {
        return await GetByIdAsync(id, cancellationToken) is not null;
    }
}

public class ProductRepository(MultiDbContext context)
    : Repository<Product>(context), IProductRepository
{
    public async Task<IReadOnlyList<Product>> GetByCategoryAsync(
        string category,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.Category == category)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Product>> GetLowStockProductsAsync(
        int threshold,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(p => p.StockQuantity <= threshold)
            .ToListAsync(cancellationToken);
    }

    public async Task<Product?> GetByNameAsync(
        string name,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(p => p.Name == name, cancellationToken);
    }
}

public class OrderRepository(MultiDbContext context)
    : Repository<Order>(context), IOrderRepository
{
    public async Task<IReadOnlyList<Order>> GetByCustomerIdAsync(
        Guid customerId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.CustomerId == customerId)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetByStatusAsync(
        OrderStatus status,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(o => o.Status == status)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<Order>> GetRecentOrdersAsync(
        int count,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .OrderByDescending(o => o.CreatedAt)
            .Take(count)
            .ToListAsync(cancellationToken);
    }
}

public class CustomerRepository(MultiDbContext context)
    : Repository<Customer>(context), ICustomerRepository
{
    public async Task<Customer?> GetByEmailAsync(
        string email,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .FirstOrDefaultAsync(c => c.Email.Value == email, cancellationToken);
    }

    public async Task<IReadOnlyList<Customer>> SearchByNameAsync(
        string namePattern,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(c => c.Name.Contains(namePattern))
            .ToListAsync(cancellationToken);
    }
}

public class DatabaseNodeRepository(MultiDbContext context)
    : Repository<DatabaseNode>(context), IDatabaseNodeRepository
{
    public async Task<DatabaseNode?> GetByIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken);
    }

    public override async Task<IReadOnlyList<DatabaseNode>> GetAllAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet.ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetHealthyNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.Status == NodeStatus.Healthy)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<DatabaseNode>> GetPrimaryNodesAsync(
        CancellationToken cancellationToken = default)
    {
        return await _dbSet
            .Where(n => n.IsPrimary)
            .ToListAsync(cancellationToken);
    }

    public new async Task AddAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        await _dbSet.AddAsync(node, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public new async Task UpdateAsync(DatabaseNode node, CancellationToken cancellationToken = default)
    {
        _dbSet.Update(node);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task DeleteAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        var node = await GetByIdAsync(nodeId, cancellationToken);
        if (node is not null)
        {
            _dbSet.Remove(node);
            await _context.SaveChangesAsync(cancellationToken);
        }
    }

    public async Task<bool> ExistsAsync(string nodeId, CancellationToken cancellationToken = default)
    {
        return await _dbSet.FindAsync([nodeId], cancellationToken) is not null;
    }
}

public class SyncOperationRepository(MultiDbContext context)
    : ISyncOperationRepository
{
    private readonly MultiDbContext _context = context;

    public async Task<SyncOperation?> GetByIdAsync(
        Guid id,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations.FindAsync([id], cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetPendingOperationsAsync(
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.Status == SyncStatus.Pending || o.Status == SyncStatus.Failed)
            .OrderBy(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task<IReadOnlyList<SyncOperation>> GetOperationsByNodeIdAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        return await _context.SyncOperations
            .Where(o => o.NodeId == nodeId)
            .OrderByDescending(o => o.CreatedAt)
            .ToListAsync(cancellationToken);
    }

    public async Task AddAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        await _context.SyncOperations.AddAsync(operation, cancellationToken);
        await _context.SaveChangesAsync(cancellationToken);
    }

    public async Task UpdateAsync(
        SyncOperation operation,
        CancellationToken cancellationToken = default)
    {
        _context.SyncOperations.Update(operation);
        await _context.SaveChangesAsync(cancellationToken);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/FailoverService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class FailoverService(
    IDatabaseNodeRepository nodeRepository,
    IHealthCheckService healthCheckService,
    IQuorumService quorumService,
    ILogger<FailoverService> logger)
    : IFailoverService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly IHealthCheckService _healthCheckService = healthCheckService;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<FailoverService> _logger = logger;

    private readonly object _failoverLock = new();
    private CancellationTokenSource? _monitoringCts;

    public event EventHandler<FailoverEventArgs>? FailoverOccurred;

    public async Task<bool> TriggerFailoverAsync(
        string failedNodeId,
        CancellationToken cancellationToken = default)
    {
        lock (_failoverLock)
        {
            if (string.IsNullOrEmpty(failedNodeId))
            {
                _logger.LogWarning("No failed node ID provided");
                return false;
            }
        }

        try
        {
            _logger.LogInformation("Triggering failover for failed node {FailedNodeId}", failedNodeId);

            var failedNode = await _nodeRepository.GetByIdAsync(failedNodeId, cancellationToken);
            if (failedNode is null)
            {
                _logger.LogWarning("Failed node {FailedNodeId} not found", failedNodeId);
                return false;
            }

            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            var nonPrimaryNodes = healthyNodes.Where(n => !n.IsPrimary).ToList();

            if (nonPrimaryNodes.Count == 0)
            {
                _logger.LogError("No healthy non-primary nodes available for failover");
                return false;
            }

            var newPrimary = nonPrimaryNodes
                .OrderByDescending(n => n.Priority)
                .ThenByDescending(n => n.HealthScore)
                .First();

            var hasConsensus = await _quorumService.HasConsensusAsync(
                Guid.NewGuid(),
                cancellationToken);

            if (!hasConsensus)
            {
                _logger.LogWarning("No quorum consensus for failover");
                return false;
            }

            var allNodes = await _nodeRepository.GetAllAsync(cancellationToken);
            foreach (var node in allNodes.Where(n => n.IsPrimary))
            {
                node.DemoteFromPrimary();
                await _nodeRepository.UpdateAsync(node, cancellationToken);
            }

            newPrimary.PromoteToPrimary();
            await _nodeRepository.UpdateAsync(newPrimary, cancellationToken);

            failedNode.MarkUnhealthy();
            await _nodeRepository.UpdateAsync(failedNode, cancellationToken);

            _logger.LogInformation(
                "Failover completed: {FailedNodeId} -> {NewPrimaryNodeId}",
                failedNodeId,
                newPrimary.NodeId);

            FailoverOccurred?.Invoke(
                this,
                new FailoverEventArgs(failedNodeId, newPrimary.NodeId));

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failover failed for node {FailedNodeId}", failedNodeId);
            return false;
        }
    }

    public async Task<string?> GetOptimalNodeAsync(
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
            return null;

        var optimalNode = healthyNodes
            .OrderByDescending(n => n.Priority)
            .ThenByDescending(n => n.HealthScore)
            .First();

        return optimalNode.NodeId;
    }

    public async Task<bool> IsFailoverNeededAsync(
        CancellationToken cancellationToken = default)
    {
        var primaryNodes = await _nodeRepository.GetPrimaryNodesAsync(cancellationToken);

        foreach (var primary in primaryNodes)
        {
            var health = await _healthCheckService.CheckNodeHealthAsync(
                primary.NodeId,
                cancellationToken);

            if (!health.IsHealthy)
                return true;
        }

        return false;
    }

    public async Task MonitorNodesAsync(CancellationToken cancellationToken = default)
    {
        _monitoringCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        _logger.LogInformation("Starting node monitoring");

        try
        {
            while (!_monitoringCts.Token.IsCancellationRequested)
            {
                try
                {
                    var allNodes = await _nodeRepository.GetAllAsync(_monitoringCts.Token);

                    foreach (var node in allNodes)
                    {
                        var health = await _healthCheckService.CheckNodeHealthAsync(
                            node.NodeId,
                            _monitoringCts.Token);

                        if (health.IsHealthy)
                        {
                            node.MarkHealthy();
                        }
                        else
                        {
                            node.MarkUnhealthy();

                            if (node.IsPrimary)
                            {
                                _logger.LogWarning(
                                    "Primary node {NodeId} is unhealthy, triggering failover",
                                    node.NodeId);

                                await TriggerFailoverAsync(node.NodeId, _monitoringCts.Token);
                            }
                        }

                        await _nodeRepository.UpdateAsync(node, _monitoringCts.Token);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
                catch (OperationCanceledException)
                {
                    break;
                }
                catch (Exception ex)
                {
                    _logger.LogError(ex, "Error during node monitoring");
                    await Task.Delay(TimeSpan.FromSeconds(5), _monitoringCts.Token);
                }
            }
        }
        finally
        {
            _logger.LogInformation("Node monitoring stopped");
        }
    }

    public void StopMonitoring()
    {
        _monitoringCts?.Cancel();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/HealthCheckService.cs
================================================================================
using System.Diagnostics;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class HealthCheckService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<HealthCheckService> logger)
    : IHealthCheckService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<HealthCheckService> _logger = logger;

    public async Task<HealthStatus> CheckNodeHealthAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var node = await _nodeRepository.GetByIdAsync(nodeId, cancellationToken);

        if (node is null)
        {
            return new HealthStatus(nodeId, false, 0, "Node not found");
        }

        var stopwatch = Stopwatch.StartNew();

        try
        {
            await Task.Delay(50, cancellationToken);

            stopwatch.Stop();

            var isHealthy = node.IsAlive && node.Status != NodeStatus.Offline;

            _logger.LogDebug("Health check for node {NodeId}: {IsHealthy} ({ResponseTime}ms)",
                nodeId, isHealthy, stopwatch.ElapsedMilliseconds);

            return new HealthStatus(
                nodeId,
                isHealthy,
                stopwatch.ElapsedMilliseconds,
                isHealthy ? null : "Node is not responding");
        }
        catch (Exception ex)
        {
            stopwatch.Stop();

            _logger.LogError(ex, "Health check failed for node {NodeId}", nodeId);

            return new HealthStatus(
                nodeId,
                false,
                stopwatch.ElapsedMilliseconds,
                ex.Message);
        }
    }

    public async Task<IReadOnlyDictionary<string, HealthStatus>> CheckAllNodesAsync(
        CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var results = new Dictionary<string, HealthStatus>();

        foreach (var node in nodes)
        {
            var health = await CheckNodeHealthAsync(node.NodeId, cancellationToken);
            results[node.NodeId] = health;
        }

        return results;
    }

    public async Task<bool> IsNodeHealthyAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        var health = await CheckNodeHealthAsync(nodeId, cancellationToken);
        return health.IsHealthy;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/QuorumService.cs
================================================================================
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;

namespace MultiDbSync.Infrastructure.Services;

public sealed class QuorumService(
    IDatabaseNodeRepository nodeRepository,
    ILogger<QuorumService> logger)
    : IQuorumService
{
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ILogger<QuorumService> _logger = logger;

    private readonly Dictionary<Guid, List<QuorumVote>> _votes = new();
    private readonly Dictionary<Guid, DateTime> _voteTimers = new();
    private readonly TimeSpan _voteTimeout = TimeSpan.FromSeconds(10);

    public async Task<bool> RequestVoteAsync(
        Guid operationId,
        string operationDescription,
        CancellationToken cancellationToken = default)
    {
        var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

        if (healthyNodes.Count == 0)
        {
            _logger.LogWarning("No healthy nodes available for quorum vote");
            return false;
        }

        var votes = new List<QuorumVote>();
        _votes[operationId] = votes;
        _voteTimers[operationId] = DateTime.UtcNow.Add(_voteTimeout);

        _logger.LogInformation("Requesting quorum vote for operation {OperationId}: {Description}",
            operationId, operationDescription);

        foreach (var node in healthyNodes)
        {
            try
            {
                var vote = await CastVoteAsync(operationId, node, cancellationToken);
                votes.Add(vote);

                _logger.LogDebug("Node {NodeId} voted {Vote} for operation {OperationId}",
                    node.NodeId, vote.Vote ? "YES" : "NO", operationId);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to get vote from node {NodeId}", node.NodeId);
            }
        }

        return await HasConsensusAsync(operationId, cancellationToken);
    }

    public async Task<QuorumResult> GetQuorumResultAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        if (!_votes.TryGetValue(operationId, out var votes))
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);
            return new QuorumResult(
                operationId,
                healthyNodes.Count,
                0,
                0,
                false,
                QuorumDecision.Pending);
        }

        var yesVotes = votes.Count(v => v.Vote);
        var noVotes = votes.Count(v => !v.Vote);
        var totalVotes = votes.Count;

        var hasConsensus = totalVotes > 0 && yesVotes > totalVotes / 2;

        var decision = hasConsensus ? QuorumDecision.Approved :
                      noVotes > totalVotes / 2 ? QuorumDecision.Rejected :
                      QuorumDecision.Pending;

        return new QuorumResult(
            operationId,
            totalVotes,
            yesVotes,
            noVotes,
            hasConsensus,
            decision);
    }

    public async Task<bool> HasConsensusAsync(
        Guid operationId,
        CancellationToken cancellationToken = default)
    {
        var result = await GetQuorumResultAsync(operationId, cancellationToken);
        return result.HasConsensus;
    }

    public int GetRequiredVotes()
    {
        return 2;
    }

    private async Task<QuorumVote> CastVoteAsync(
        Guid operationId,
        DatabaseNode node,
        CancellationToken cancellationToken)
    {
        await Task.Delay(50, cancellationToken);

        var vote = new QuorumVote(
            operationId,
            node.NodeId,
            true,
            "Node operational");

        return vote;
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Infrastructure/Services/SynchronizationService.cs
================================================================================
using System.Text.Json;
using Microsoft.Extensions.Logging;
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.Interfaces;
using MultiDbSync.Infrastructure.Data;
using MultiDbSync.Infrastructure.Repositories;

namespace MultiDbSync.Infrastructure.Services;

public sealed class SynchronizationService(
    IEnumerable<MultiDbContext> dbContexts,
    IDatabaseNodeRepository nodeRepository,
    ISyncOperationRepository syncOperationRepository,
    IQuorumService quorumService,
    ILogger<SynchronizationService> logger)
    : ISynchronizationService
{
    private readonly IEnumerable<MultiDbContext> _dbContexts = dbContexts;
    private readonly IDatabaseNodeRepository _nodeRepository = nodeRepository;
    private readonly ISyncOperationRepository _syncOperationRepository = syncOperationRepository;
    private readonly IQuorumService _quorumService = quorumService;
    private readonly ILogger<SynchronizationService> _logger = logger;

    private readonly SemaphoreSlim _syncLock = new(1, 1);

    public async Task<bool> SyncEntityAsync<T>(
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var healthyNodes = await _nodeRepository.GetHealthyNodesAsync(cancellationToken);

            if (healthyNodes.Count == 0)
            {
                _logger.LogWarning("No healthy nodes available for synchronization");
                return false;
            }

            var entityType = typeof(T).Name;
            var entityId = GetEntityId(entity);
            var payload = JsonSerializer.Serialize(entity);

            var successCount = 0;
            var errors = new List<string>();

            foreach (var node in healthyNodes)
            {
                try
                {
                    var syncOperation = new SyncOperation(
                        node.NodeId,
                        operationType,
                        entityType,
                        entityId,
                        payload);

                    await _syncOperationRepository.AddAsync(syncOperation, cancellationToken);

                    await SyncToNodeAsync(node, entity, operationType, cancellationToken);

                    syncOperation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(syncOperation, cancellationToken);

                    node.MarkHealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);

                    successCount++;
                    _logger.LogInformation("Successfully synced {EntityType} to node {NodeId}", entityType, node.NodeId);
                }
                catch (Exception ex)
                {
                    node.MarkUnhealthy();
                    await _nodeRepository.UpdateAsync(node, cancellationToken);
                    errors.Add($"{node.NodeId}: {ex.Message}");
                    _logger.LogError(ex, "Failed to sync to node {NodeId}", node.NodeId);
                }
            }

            return successCount > 0;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<bool> SyncBatchAsync<T>(
        IEnumerable<T> entities,
        OperationType operationType,
        CancellationToken cancellationToken = default) where T : class
    {
        var entityList = entities.ToList();
        var allSuccess = true;

        foreach (var entity in entityList)
        {
            var success = await SyncEntityAsync(entity, operationType, cancellationToken);
            if (!success)
                allSuccess = false;
        }

        return allSuccess;
    }

    public async Task<bool> ForceSyncAsync(
        string nodeId,
        CancellationToken cancellationToken = default)
    {
        await _syncLock.WaitAsync(cancellationToken);
        try
        {
            var pendingOperations = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

            if (!string.IsNullOrEmpty(nodeId))
            {
                pendingOperations = pendingOperations.Where(o => o.NodeId == nodeId).ToList();
            }

            foreach (var operation in pendingOperations)
            {
                try
                {
                    operation.MarkInProgress();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);

                    var entity = JsonSerializer.Deserialize<object>(operation.Payload);

                    _logger.LogInformation("Retrying sync operation {OperationId} to node {NodeId}",
                        operation.Id, operation.NodeId);

                    operation.MarkCompleted();
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
                catch (Exception ex)
                {
                    if (operation.CanRetry)
                    {
                        operation.MarkPending();
                    }
                    else
                    {
                        operation.MarkFailed(ex.Message);
                    }
                    await _syncOperationRepository.UpdateAsync(operation, cancellationToken);
                }
            }

            return true;
        }
        finally
        {
            _syncLock.Release();
        }
    }

    public async Task<SyncResult> GetSyncStatusAsync(CancellationToken cancellationToken = default)
    {
        var nodes = await _nodeRepository.GetAllAsync(cancellationToken);
        var pendingOps = await _syncOperationRepository.GetPendingOperationsAsync(cancellationToken);

        var successfulNodes = nodes.Count(n => n.Status == NodeStatus.Healthy);
        var failedNodes = nodes.Count - successfulNodes;

        return new SyncResult(
            nodes.Count,
            successfulNodes,
            failedNodes,
            pendingOps.Select(o => $"Operation {o.Id}: {o.ErrorMessage}").ToList());
    }

    private async Task SyncToNodeAsync<T>(
        DatabaseNode node,
        T entity,
        OperationType operationType,
        CancellationToken cancellationToken) where T : class
    {
        await Task.Delay(10, cancellationToken);
    }

    private static string GetEntityId(object entity)
    {
        var idProperty = entity.GetType().GetProperty("Id");
        if (idProperty?.GetValue(entity) is Guid guid)
            return guid.ToString();

        return Guid.NewGuid().ToString();
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Application/CqrsTests.cs
================================================================================
using MultiDbSync.Application.CQRS;
using Xunit;

namespace MultiDbSync.Tests.Application;

public class CqrsBaseTests
{
    [Fact]
    public void CommandResult_Success_ShouldReturnSuccessResult()
    {
        var result = CommandResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void CommandResult_Failure_ShouldReturnFailureResult()
    {
        var result = CommandResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Success_ShouldReturnSuccessResult()
    {
        var result = QueryResult<string>.Success("test data");

        Assert.True(result.IsSuccess);
        Assert.Equal("test data", result.Data);
        Assert.Null(result.ErrorMessage);
    }

    [Fact]
    public void QueryResult_Failure_ShouldReturnFailureResult()
    {
        var result = QueryResult<string>.Failure("error message");

        Assert.False(result.IsSuccess);
        Assert.Null(result.Data);
        Assert.Equal("error message", result.ErrorMessage);
    }

    [Fact]
    public void Command_ShouldHaveUniqueId()
    {
        var command1 = new TestCommand();
        var command2 = new TestCommand();

        Assert.NotEqual(Guid.Empty, command1.Id);
        Assert.NotEqual(Guid.Empty, command2.Id);
        Assert.NotEqual(command1.Id, command2.Id);
    }

    [Fact]
    public void Command_ShouldHaveCreationTimestamp()
    {
        var before = DateTime.UtcNow;
        var command = new TestCommand();
        var after = DateTime.UtcNow;

        Assert.InRange(command.CreatedAt, before, after);
    }

    private sealed record TestCommand : Command;
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/Domain/EntityTests.cs
================================================================================
using MultiDbSync.Domain.Entities;
using MultiDbSync.Domain.ValueObjects;
using Xunit;

namespace MultiDbSync.Tests.Domain;

public class ProductTests
{
    [Fact]
    public void CreateProduct_WithValidData_ShouldCreateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.NotEqual(Guid.Empty, product.Id);
        Assert.Equal("Test Product", product.Name);
        Assert.Equal("Test Description", product.Description);
        Assert.Equal(99.99m, product.Price.Amount);
        Assert.Equal(100, product.StockQuantity);
        Assert.Equal("Test Category", product.Category);
    }

    [Fact]
    public void UpdatePrice_WithValidPrice_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdatePrice(new Money(79.99m, "USD"));

        Assert.Equal(79.99m, product.Price.Amount);
        Assert.True(product.UpdatedAt > product.CreatedAt);
    }

    [Fact]
    public void UpdateStock_WithValidQuantity_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateStock(50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void UpdateStock_WithNegativeQuantity_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<ArgumentException>(() => product.UpdateStock(-10));
    }

    [Fact]
    public void AdjustStock_WithPositiveAdjustment_ShouldIncreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(50);

        Assert.Equal(150, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithNegativeAdjustment_ShouldDecreaseStock()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.AdjustStock(-50);

        Assert.Equal(50, product.StockQuantity);
    }

    [Fact]
    public void AdjustStock_WithExcessiveNegative_ShouldThrowException()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        Assert.Throws<InvalidOperationException>(() => product.AdjustStock(-150));
    }

    [Fact]
    public void UpdateDetails_WithValidData_ShouldUpdateSuccessfully()
    {
        var product = new Product(
            "Test Product",
            "Test Description",
            new Money(99.99m, "USD"),
            100,
            "Test Category");

        product.UpdateDetails("New Name", "New Description", "New Category");

        Assert.Equal("New Name", product.Name);
        Assert.Equal("New Description", product.Description);
        Assert.Equal("New Category", product.Category);
    }
}

public class OrderTests
{
    [Fact]
    public void CreateOrder_WithValidData_ShouldCreateSuccessfully()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        Assert.NotEqual(Guid.Empty, order.Id);
        Assert.Equal(OrderStatus.Pending, order.Status);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithValidProduct_ShouldAddItemAndRecalculateTotal()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);

        Assert.Single(order.Items);
        Assert.Equal(100m, order.TotalAmount.Amount);
    }

    [Fact]
    public void AddItem_WithExistingProduct_ShouldIncreaseQuantity()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.AddItem(product, 3);

        Assert.Single(order.Items);
        Assert.Equal(5, order.Items.First().Quantity);
    }

    [Fact]
    public void MarkAsShipped_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.MarkAsShipped();

        Assert.Equal(OrderStatus.Shipped, order.Status);
        Assert.NotNull(order.ShippedAt);
    }

    [Fact]
    public void MarkAsShipped_WhenNotPending_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        Assert.Throws<InvalidOperationException>(() => order.MarkAsShipped());
    }

    [Fact]
    public void MarkAsDelivered_WhenShipped_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();

        order.MarkAsDelivered();

        Assert.Equal(OrderStatus.Delivered, order.Status);
        Assert.NotNull(order.DeliveredAt);
    }

    [Fact]
    public void Cancel_WhenPending_ShouldChangeStatus()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);

        order.Cancel();

        Assert.Equal(OrderStatus.Cancelled, order.Status);
    }

    [Fact]
    public void Cancel_WhenDelivered_ShouldThrowException()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        order.MarkAsShipped();
        order.MarkAsDelivered();

        Assert.Throws<InvalidOperationException>(() => order.Cancel());
    }

    [Fact]
    public void RemoveItem_WithExistingItem_ShouldRemoveAndRecalculate()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");
        var order = new Order(Guid.NewGuid(), address);
        var product = new Product("Test", "Desc", new Money(50m, "USD"), 10, "Cat");

        order.AddItem(product, 2);
        order.RemoveItem(product.Id);

        Assert.Empty(order.Items);
        Assert.Equal(0m, order.TotalAmount.Amount);
    }
}

public class DatabaseNodeTests
{
    [Fact]
    public void CreateNode_WithValidData_ShouldCreateSuccessfully()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        Assert.Equal("node1", node.NodeId);
        Assert.Equal("Data Source=test.db", node.ConnectionString);
        Assert.Equal(1, node.Priority);
        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void MarkHealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();

        Assert.Equal(NodeStatus.Healthy, node.Status);
    }

    [Fact]
    public void MarkUnhealthy_ShouldUpdateStatus()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkUnhealthy();

        Assert.Equal(NodeStatus.Unhealthy, node.Status);
    }

    [Fact]
    public void PromoteToPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.PromoteToPrimary();

        Assert.True(node.IsPrimary);
    }

    [Fact]
    public void DemoteFromPrimary_ShouldUpdatePrimaryFlag()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, true);

        node.DemoteFromPrimary();

        Assert.False(node.IsPrimary);
    }

    [Fact]
    public void HealthScore_ShouldCalculateCorrectly()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);

        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkHealthy();
        node.MarkUnhealthy();

        Assert.Equal(75, node.HealthScore);
    }

    [Fact]
    public void IsAlive_WhenRecentlyHeartbeat_ShouldReturnTrue()
    {
        var node = new DatabaseNode("node1", "Data Source=test.db", 1, false);
        node.MarkHealthy();

        Assert.True(node.IsAlive);
    }
}

public class ValueObjectTests
{
    [Fact]
    public void Money_Add_ShouldSumAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 + money2;

        Assert.Equal(80m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Subtract_ShouldSubtractAmounts()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "USD");

        var result = money1 - money2;

        Assert.Equal(20m, result.Amount);
        Assert.Equal("USD", result.Currency);
    }

    [Fact]
    public void Money_Add_DifferentCurrencies_ShouldThrowException()
    {
        var money1 = new Money(50m, "USD");
        var money2 = new Money(30m, "EUR");

        Assert.Throws<InvalidOperationException>(() => money1 + money2);
    }

    [Fact]
    public void EmailAddress_WithValidEmail_ShouldCreateSuccessfully()
    {
        var email = new EmailAddress("test@example.com");

        Assert.Equal("test@example.com", email.Value);
    }

    [Fact]
    public void EmailAddress_WithInvalidEmail_ShouldThrowException()
    {
        Assert.Throws<ArgumentException>(() => new EmailAddress("invalid-email"));
    }

    [Fact]
    public void Address_FullAddress_ShouldReturnFormattedAddress()
    {
        var address = new Address("123 Main St", "City", "State", "12345", "USA");

        Assert.Equal("123 Main St, City, State 12345, USA", address.FullAddress);
    }
}




================================================================================
FILE: MultiDbSync/MultiDbSync.Tests/MultiDbSync.Tests.csproj
================================================================================
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <LangVersion>latest</LangVersion>
    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="coverlet.collector" Version="6.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.12.0" />
    <PackageReference Include="xunit" Version="2.9.0" />
    <PackageReference Include="xunit.runner.visualstudio" Version="2.8.2">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.0" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="10.0.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\MultiDbSync.Domain\MultiDbSync.Domain.csproj" />
    <ProjectReference Include="..\MultiDbSync.Application\MultiDbSync.Application.csproj" />
    <ProjectReference Include="..\MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj" />
  </ItemGroup>

</Project>




================================================================================
FILE: MultiDbSync/MultiDbSync.sln
================================================================================
Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.0.31903.59
MinimumVisualStudioVersion = 10.0.40219.1
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Domain", "MultiDbSync.Domain\MultiDbSync.Domain.csproj", "{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Application", "MultiDbSync.Application\MultiDbSync.Application.csproj", "{B2C3D4E5-F6A7-8901-BCDE-F12345678901}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Infrastructure", "MultiDbSync.Infrastructure\MultiDbSync.Infrastructure.csproj", "{C3D4E5F6-A7B8-9012-CDEF-123456789012}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Console", "MultiDbSync.Console\MultiDbSync.Console.csproj", "{D4E5F6A7-B8C9-0123-DEF0-234567890123}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "MultiDbSync.Tests", "MultiDbSync.Tests\MultiDbSync.Tests.csproj", "{E5F6A7B8-C9D0-1234-EF01-345678901234}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Release|Any CPU = Release|Any CPU
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{A1B2C3D4-E5F6-7890-ABCD-EF1234567890}.Release|Any CPU.Build.0 = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{B2C3D4E5-F6A7-8901-BCDE-F12345678901}.Release|Any CPU.Build.0 = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C3D4E5F6-A7B8-9012-CDEF-123456789012}.Release|Any CPU.Build.0 = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{D4E5F6A7-B8C9-0123-DEF0-234567890123}.Release|Any CPU.Build.0 = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{E5F6A7B8-C9D0-1234-EF01-345678901234}.Release|Any CPU.Build.0 = Release|Any CPU
	EndGlobalSection
EndGlobal




================================================================================
FILE: dotnet-install.sh
================================================================================
#!/usr/bin/env bash
# Copyright (c) .NET Foundation and contributors. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.
#

# Stop script on NZEC
set -e
# Stop script if unbound variable found (use ${var:-} if intentional)
set -u
# By default cmd1 | cmd2 returns exit code of cmd2 regardless of cmd1 success
# This is causing it to fail
set -o pipefail

# Use in the the functions: eval $invocation
invocation='say_verbose "Calling: ${yellow:-}${FUNCNAME[0]} ${green:-}$*${normal:-}"'

# standard output may be used as a return value in the functions
# we need a way to write text on the screen in the functions so that
# it won't interfere with the return value.
# Exposing stream 3 as a pipe to standard output of the script itself
exec 3>&1

# Setup some colors to use. These need to work in fairly limited shells, like the Ubuntu Docker container where there are only 8 colors.
# See if stdout is a terminal
if [ -t 1 ] && command -v tput > /dev/null; then
    # see if it supports colors
    ncolors=$(tput colors || echo 0)
    if [ -n "$ncolors" ] && [ $ncolors -ge 8 ]; then
        bold="$(tput bold       || echo)"
        normal="$(tput sgr0     || echo)"
        black="$(tput setaf 0   || echo)"
        red="$(tput setaf 1     || echo)"
        green="$(tput setaf 2   || echo)"
        yellow="$(tput setaf 3  || echo)"
        blue="$(tput setaf 4    || echo)"
        magenta="$(tput setaf 5 || echo)"
        cyan="$(tput setaf 6    || echo)"
        white="$(tput setaf 7   || echo)"
    fi
fi

say_warning() {
    printf "%b\n" "${yellow:-}dotnet_install: Warning: $1${normal:-}" >&3
}

say_err() {
    printf "%b\n" "${red:-}dotnet_install: Error: $1${normal:-}" >&2
}

say() {
    # using stream 3 (defined in the beginning) to not interfere with stdout of functions
    # which may be used as return value
    printf "%b\n" "${cyan:-}dotnet-install:${normal:-} $1" >&3
}

say_verbose() {
    if [ "$verbose" = true ]; then
        say "$1"
    fi
}

# This platform list is finite - if the SDK/Runtime has supported Linux distribution-specific assets,
#   then and only then should the Linux distribution appear in this list.
# Adding a Linux distribution to this list does not imply distribution-specific support.
get_legacy_os_name_from_platform() {
    eval $invocation

    platform="$1"
    case "$platform" in
        "centos.7")
            echo "centos"
            return 0
            ;;
        "debian.8")
            echo "debian"
            return 0
            ;;
        "debian.9")
            echo "debian.9"
            return 0
            ;;
        "fedora.23")
            echo "fedora.23"
            return 0
            ;;
        "fedora.24")
            echo "fedora.24"
            return 0
            ;;
        "fedora.27")
            echo "fedora.27"
            return 0
            ;;
        "fedora.28")
            echo "fedora.28"
            return 0
            ;;
        "opensuse.13.2")
            echo "opensuse.13.2"
            return 0
            ;;
        "opensuse.42.1")
            echo "opensuse.42.1"
            return 0
            ;;
        "opensuse.42.3")
            echo "opensuse.42.3"
            return 0
            ;;
        "rhel.7"*)
            echo "rhel"
            return 0
            ;;
        "ubuntu.14.04")
            echo "ubuntu"
            return 0
            ;;
        "ubuntu.16.04")
            echo "ubuntu.16.04"
            return 0
            ;;
        "ubuntu.16.10")
            echo "ubuntu.16.10"
            return 0
            ;;
        "ubuntu.18.04")
            echo "ubuntu.18.04"
            return 0
            ;;
        "alpine.3.4.3")
            echo "alpine"
            return 0
            ;;
    esac
    return 1
}

get_legacy_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ -n "$runtime_id" ]; then
        echo $(get_legacy_os_name_from_platform "${runtime_id%-*}" || echo "${runtime_id%-*}")
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            os=$(get_legacy_os_name_from_platform "$ID${VERSION_ID:+.${VERSION_ID}}" || echo "")
            if [ -n "$os" ]; then
                echo "$os"
                return 0
            fi
        fi
    fi

    say_verbose "Distribution specific OS name and version could not be detected: UName = $uname"
    return 1
}

get_linux_platform_name() {
    eval $invocation

    if [ -n "$runtime_id" ]; then
        echo "${runtime_id%-*}"
        return 0
    else
        if [ -e /etc/os-release ]; then
            . /etc/os-release
            echo "$ID${VERSION_ID:+.${VERSION_ID}}"
            return 0
        elif [ -e /etc/redhat-release ]; then
            local redhatRelease=$(</etc/redhat-release)
            if [[ $redhatRelease == "CentOS release 6."* || $redhatRelease == "Red Hat Enterprise Linux "*" release 6."* ]]; then
                echo "rhel.6"
                return 0
            fi
        fi
    fi

    say_verbose "Linux specific platform name and version could not be detected: UName = $uname"
    return 1
}

is_musl_based_distro() {
    (ldd --version 2>&1 || true) | grep -q musl
}

get_current_os_name() {
    eval $invocation

    local uname=$(uname)
    if [ "$uname" = "Darwin" ]; then
        echo "osx"
        return 0
    elif [ "$uname" = "FreeBSD" ]; then
        echo "freebsd"
        return 0
    elif [ "$uname" = "Linux" ]; then
        local linux_platform_name=""
        linux_platform_name="$(get_linux_platform_name)" || true

        if [ "$linux_platform_name" = "rhel.6" ]; then
            echo $linux_platform_name
            return 0
        elif is_musl_based_distro; then
            echo "linux-musl"
            return 0
        elif [ "$linux_platform_name" = "linux-musl" ]; then
            echo "linux-musl"
            return 0
        else
            echo "linux"
            return 0
        fi
    fi

    say_err "OS name could not be detected: UName = $uname"
    return 1
}

machine_has() {
    eval $invocation

    command -v "$1" > /dev/null 2>&1
    return $?
}

check_min_reqs() {
    local hasMinimum=false
    if machine_has "curl"; then
        hasMinimum=true
    elif machine_has "wget"; then
        hasMinimum=true
    fi

    if [ "$hasMinimum" = "false" ]; then
        say_err "curl (recommended) or wget are required to download dotnet. Install missing prerequisite to proceed."
        return 1
    fi
    return 0
}

# args:
# input - $1
to_lowercase() {
    #eval $invocation

    echo "$1" | tr '[:upper:]' '[:lower:]'
    return 0
}

# args:
# input - $1
remove_trailing_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input%/}"
    return 0
}

# args:
# input - $1
remove_beginning_slash() {
    #eval $invocation

    local input="${1:-}"
    echo "${input#/}"
    return 0
}

# args:
# root_path - $1
# child_path - $2 - this parameter can be empty
combine_paths() {
    eval $invocation

    # TODO: Consider making it work with any number of paths. For now:
    if [ ! -z "${3:-}" ]; then
        say_err "combine_paths: Function takes two parameters."
        return 1
    fi

    local root_path="$(remove_trailing_slash "$1")"
    local child_path="$(remove_beginning_slash "${2:-}")"
    say_verbose "combine_paths: root_path=$root_path"
    say_verbose "combine_paths: child_path=$child_path"
    echo "$root_path/$child_path"
    return 0
}

get_machine_architecture() {
    eval $invocation

    if command -v uname > /dev/null; then
        CPUName=$(uname -m)
        case $CPUName in
        armv1*|armv2*|armv3*|armv4*|armv5*|armv6*)
            echo "armv6-or-below"
            return 0
            ;;
        armv*l)
            echo "arm"
            return 0
            ;;
        aarch64|arm64)
            if [ "$(getconf LONG_BIT)" -lt 64 ]; then
                # This is 32-bit OS running on 64-bit CPU (for example Raspberry Pi OS)
                echo "arm"
                return 0
            fi
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
        riscv64)
            echo "riscv64"
            return 0
            ;;
        powerpc|ppc)
            echo "ppc"
            return 0
            ;;
        esac
    fi

    # Always default to 'x64'
    echo "x64"
    return 0
}

# args:
# architecture - $1
get_normalized_architecture_from_architecture() {
    eval $invocation

    local architecture="$(to_lowercase "$1")"

    if [[ $architecture == \<auto\> ]]; then
        machine_architecture="$(get_machine_architecture)"
        if [[ "$machine_architecture" == "armv6-or-below" ]]; then
            say_err "Architecture \`$machine_architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
            return 1
        fi

        echo $machine_architecture
        return 0
    fi

    case "$architecture" in
        amd64|x64)
            echo "x64"
            return 0
            ;;
        arm)
            echo "arm"
            return 0
            ;;
        arm64)
            echo "arm64"
            return 0
            ;;
        s390x)
            echo "s390x"
            return 0
            ;;
        ppc64le)
            echo "ppc64le"
            return 0
            ;;
        loongarch64)
            echo "loongarch64"
            return 0
            ;;
    esac

    say_err "Architecture \`$architecture\` not supported. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues"
    return 1
}

# args:
# version - $1
# channel - $2
# architecture - $3
get_normalized_architecture_for_specific_sdk_version() {
    eval $invocation

    local is_version_support_arm64="$(is_arm64_supported "$1")"
    local is_channel_support_arm64="$(is_arm64_supported "$2")"
    local architecture="$3";
    local osname="$(get_current_os_name)"

    if [ "$osname" == "osx" ] && [ "$architecture" == "arm64" ] && { [ "$is_version_support_arm64" = false ] || [ "$is_channel_support_arm64" = false ]; }; then
        #check if rosetta is installed
        if [ "$(/usr/bin/pgrep oahd >/dev/null 2>&1;echo $?)" -eq 0 ]; then 
            say_verbose "Changing user architecture from '$architecture' to 'x64' because .NET SDKs prior to version 6.0 do not support arm64." 
            echo "x64"
            return 0;
        else
            say_err "Architecture \`$architecture\` is not supported for .NET SDK version \`$version\`. Please install Rosetta to allow emulation of the \`$architecture\` .NET SDK on this platform"
            return 1
        fi
    fi

    echo "$architecture"
    return 0
}

# args:
# version or channel - $1
is_arm64_supported() {
    # Extract the major version by splitting on the dot
    major_version="${1%%.*}"

    # Check if the major version is a valid number and less than 6
    case "$major_version" in
        [0-9]*)  
            if [ "$major_version" -lt 6 ]; then
                echo false
                return 0
            fi
            ;;
    esac

    echo true
    return 0
}

# args:
# user_defined_os - $1
get_normalized_os() {
    eval $invocation

    local osname="$(to_lowercase "$1")"
    if [ ! -z "$osname" ]; then
        case "$osname" in
            osx | freebsd | rhel.6 | linux-musl | linux)
                echo "$osname"
                return 0
                ;;
            macos)
                osname='osx'
                echo "$osname"
                return 0
                ;;
            *)
                say_err "'$user_defined_os' is not a supported value for --os option, supported values are: osx, macos, linux, linux-musl, freebsd, rhel.6. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    else
        osname="$(get_current_os_name)" || return 1
    fi
    echo "$osname"
    return 0
}

# args:
# quality - $1
get_normalized_quality() {
    eval $invocation

    local quality="$(to_lowercase "$1")"
    if [ ! -z "$quality" ]; then
        case "$quality" in
            daily | preview)
                echo "$quality"
                return 0
                ;;
            ga)
                #ga quality is available without specifying quality, so normalizing it to empty
                return 0
                ;;
            *)
                say_err "'$quality' is not a supported value for --quality option. Supported values are: daily, preview, ga. If you think this is a bug, report it at https://github.com/dotnet/install-scripts/issues."
                return 1
                ;;
        esac
    fi
    return 0
}

# args:
# channel - $1
get_normalized_channel() {
    eval $invocation

    local channel="$(to_lowercase "$1")"

    if [[ $channel == current ]]; then
        say_warning 'Value "Current" is deprecated for -Channel option. Use "STS" instead.'
    fi

    if [[ $channel == release/* ]]; then
        say_warning 'Using branch name with -Channel option is no longer supported with newer releases. Use -Quality option with a channel in X.Y format instead.';
    fi

    if [ ! -z "$channel" ]; then
        case "$channel" in
            lts)
                echo "LTS"
                return 0
                ;;
            sts)
                echo "STS"
                return 0
                ;;
            current)
                echo "STS"
                return 0
                ;;
            *)
                echo "$channel"
                return 0
                ;;
        esac
    fi

    return 0
}

# args:
# runtime - $1
get_normalized_product() {
    eval $invocation

    local product=""
    local runtime="$(to_lowercase "$1")"
    if [[ "$runtime" == "dotnet" ]]; then
        product="dotnet-runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        product="aspnetcore-runtime"
    elif [ -z "$runtime" ]; then
        product="dotnet-sdk"
    fi
    echo "$product"
    return 0
}

# The version text returned from the feeds is a 1-line or 2-line string:
# For the SDK and the dotnet runtime (2 lines):
# Line 1: # commit_hash
# Line 2: # 4-part version
# For the aspnetcore runtime (1 line):
# Line 1: # 4-part version

# args:
# version_text - stdin
get_version_from_latestversion_file_content() {
    eval $invocation

    cat | tail -n 1 | sed 's/\r$//'
    return 0
}

# args:
# install_root - $1
# relative_path_to_package - $2
# specific_version - $3
is_dotnet_package_installed() {
    eval $invocation

    local install_root="$1"
    local relative_path_to_package="$2"
    local specific_version="${3//[$'\t\r\n']}"

    local dotnet_package_path="$(combine_paths "$(combine_paths "$install_root" "$relative_path_to_package")" "$specific_version")"
    say_verbose "is_dotnet_package_installed: dotnet_package_path=$dotnet_package_path"

    if [ -d "$dotnet_package_path" ]; then
        return 0
    else
        return 1
    fi
}

# args:
# downloaded file - $1
# remote_file_size - $2
validate_remote_local_file_sizes() 
{
    eval $invocation

    local downloaded_file="$1"
    local remote_file_size="$2"
    local file_size=''

    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        file_size="$(stat -c '%s' "$downloaded_file")"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # hardcode in order to avoid conflicts with GNU stat
        file_size="$(/usr/bin/stat -f '%z' "$downloaded_file")"
    fi  
    
    if [ -n "$file_size" ]; then
        say "Downloaded file size is $file_size bytes."

        if [ -n "$remote_file_size" ] && [ -n "$file_size" ]; then
            if [ "$remote_file_size" -ne "$file_size" ]; then
                say "The remote and local file sizes are not equal. The remote file size is $remote_file_size bytes and the local size is $file_size bytes. The local package may be corrupted."
            else
                say "The remote and local file sizes are equal."
            fi
        fi
        
    else
        say "Either downloaded or local package size can not be measured. One of them may be corrupted."      
    fi 
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
get_version_from_latestversion_file() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"

    local version_file_url=null
    if [[ "$runtime" == "dotnet" ]]; then
        version_file_url="$azure_feed/Runtime/$channel/latest.version"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        version_file_url="$azure_feed/aspnetcore/Runtime/$channel/latest.version"
    elif [ -z "$runtime" ]; then
         version_file_url="$azure_feed/Sdk/$channel/latest.version"
    else
        say_err "Invalid value for \$runtime"
        return 1
    fi
    say_verbose "get_version_from_latestversion_file: latest url: $version_file_url"

    download "$version_file_url" || return $?
    return 0
}

# args:
# json_file - $1
parse_globaljson_file_for_version() {
    eval $invocation

    local json_file="$1"
    if [ ! -f "$json_file" ]; then
        say_err "Unable to find \`$json_file\`"
        return 1
    fi

    sdk_section=$(cat "$json_file" | tr -d "\r" | awk '/"sdk"/,/}/')
    if [ -z "$sdk_section" ]; then
        say_err "Unable to parse the SDK node in \`$json_file\`"
        return 1
    fi

    sdk_list=$(echo $sdk_section | awk -F"[{}]" '{print $2}')
    sdk_list=${sdk_list//[\" ]/}
    sdk_list=${sdk_list//,/$'\n'}

    local version_info=""
    while read -r line; do
      IFS=:
      while read -r key value; do
        if [[ "$key" == "version" ]]; then
          version_info=$value
        fi
      done <<< "$line"
    done <<< "$sdk_list"
    if [ -z "$version_info" ]; then
        say_err "Unable to find the SDK:version node in \`$json_file\`"
        return 1
    fi

    unset IFS;
    echo "$version_info"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# version - $4
# json_file - $5
get_specific_version_from_version() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local version="$(to_lowercase "$4")"
    local json_file="$5"

    if [ -z "$json_file" ]; then
        if [[ "$version" == "latest" ]]; then
            local version_info
            version_info="$(get_version_from_latestversion_file "$azure_feed" "$channel" "$normalized_architecture" false)" || return 1
            say_verbose "get_specific_version_from_version: version_info=$version_info"
            echo "$version_info" | get_version_from_latestversion_file_content
            return 0
        else
            echo "$version"
            return 0
        fi
    else
        local version_info
        version_info="$(parse_globaljson_file_for_version "$json_file")" || return 1
        echo "$version_info"
        return 0
    fi
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
# normalized_os - $5
construct_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"
    local specific_product_version="$(get_specific_product_version "$1" "$4")"
    local osname="$5"

    local download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        download_link="$azure_feed/Runtime/$specific_version/dotnet-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        download_link="$azure_feed/aspnetcore/Runtime/$specific_version/aspnetcore-runtime-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    elif [ -z "$runtime" ]; then
        download_link="$azure_feed/Sdk/$specific_version/dotnet-sdk-$specific_product_version-$osname-$normalized_architecture.tar.gz"
    else
        return 1
    fi

    echo "$download_link"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# download link - $3 (optional)
get_specific_product_version() {
    # If we find a 'productVersion.txt' at the root of any folder, we'll use its contents
    # to resolve the version of what's in the folder, superseding the specified version.
    # if 'productVersion.txt' is missing but download link is already available, product version will be taken from download link
    eval $invocation

    local azure_feed="$1"
    local specific_version="${2//[$'\t\r\n']}"
    local package_download_link=""
    if [ $# -gt 2  ]; then
        local package_download_link="$3"
    fi
    local specific_product_version=null

    # Try to get the version number, using the productVersion.txt file located next to the installer file.
    local download_links=($(get_specific_product_version_url "$azure_feed" "$specific_version" true "$package_download_link")
        $(get_specific_product_version_url "$azure_feed" "$specific_version" false "$package_download_link"))

    for download_link in "${download_links[@]}"
    do
        say_verbose "Checking for the existence of $download_link"

        if machine_has "curl"
        then
            if ! specific_product_version=$(curl -sL --fail "${download_link}${feed_credential}" 2>&1); then
                continue
            else
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi

        elif machine_has "wget"
        then
            specific_product_version=$(wget -qO- "${download_link}${feed_credential}" 2>&1)
            if [ $? = 0 ]; then
                echo "${specific_product_version//[$'\t\r\n']}"
                return 0
            fi
        fi
    done
    
    # Getting the version number with productVersion.txt has failed. Try parsing the download link for a version number.
    say_verbose "Failed to get the version using productVersion.txt file. Download link will be parsed instead."
    specific_product_version="$(get_product_specific_version_from_download_link "$package_download_link" "$specific_version")"
    echo "${specific_product_version//[$'\t\r\n']}"
    return 0
}

# args:
# azure_feed - $1
# specific_version - $2
# is_flattened - $3
# download link - $4 (optional)
get_specific_product_version_url() {
    eval $invocation

    local azure_feed="$1"
    local specific_version="$2"
    local is_flattened="$3"
    local package_download_link=""
    if [ $# -gt 3  ]; then
        local package_download_link="$4"
    fi

    local pvFileName="productVersion.txt"
    if [ "$is_flattened" = true ]; then
        if [ -z "$runtime" ]; then
            pvFileName="sdk-productVersion.txt"
        elif [[ "$runtime" == "dotnet" ]]; then
            pvFileName="runtime-productVersion.txt"
        else
            pvFileName="$runtime-productVersion.txt"
        fi
    fi

    local download_link=null

    if [ -z "$package_download_link" ]; then
        if [[ "$runtime" == "dotnet" ]]; then
            download_link="$azure_feed/Runtime/$specific_version/${pvFileName}"
        elif [[ "$runtime" == "aspnetcore" ]]; then
            download_link="$azure_feed/aspnetcore/Runtime/$specific_version/${pvFileName}"
        elif [ -z "$runtime" ]; then
            download_link="$azure_feed/Sdk/$specific_version/${pvFileName}"
        else
            return 1
        fi
    else
        download_link="${package_download_link%/*}/${pvFileName}"
    fi

    say_verbose "Constructed productVersion link: $download_link"
    echo "$download_link"
    return 0
}

# args:
# download link - $1
# specific version - $2
get_product_specific_version_from_download_link()
{
    eval $invocation

    local download_link="$1"
    local specific_version="$2"
    local specific_product_version="" 

    if [ -z "$download_link" ]; then
        echo "$specific_version"
        return 0
    fi

    #get filename
    filename="${download_link##*/}"

    #product specific version follows the product name
    #for filename 'dotnet-sdk-3.1.404-linux-x64.tar.gz': the product version is 3.1.404
    IFS='-'
    read -ra filename_elems <<< "$filename"
    count=${#filename_elems[@]}
    if [[ "$count" -gt 2 ]]; then
        specific_product_version="${filename_elems[2]}"
    else
        specific_product_version=$specific_version
    fi
    unset IFS;
    echo "$specific_product_version"
    return 0
}

# args:
# azure_feed - $1
# channel - $2
# normalized_architecture - $3
# specific_version - $4
construct_legacy_download_link() {
    eval $invocation

    local azure_feed="$1"
    local channel="$2"
    local normalized_architecture="$3"
    local specific_version="${4//[$'\t\r\n']}"

    local distro_specific_osname
    distro_specific_osname="$(get_legacy_os_name)" || return 1

    local legacy_download_link=null
    if [[ "$runtime" == "dotnet" ]]; then
        legacy_download_link="$azure_feed/Runtime/$specific_version/dotnet-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    elif [ -z "$runtime" ]; then
        legacy_download_link="$azure_feed/Sdk/$specific_version/dotnet-dev-$distro_specific_osname-$normalized_architecture.$specific_version.tar.gz"
    else
        return 1
    fi

    echo "$legacy_download_link"
    return 0
}

get_user_install_path() {
    eval $invocation

    if [ ! -z "${DOTNET_INSTALL_DIR:-}" ]; then
        echo "$DOTNET_INSTALL_DIR"
    else
        echo "$HOME/.dotnet"
    fi
    return 0
}

# args:
# install_dir - $1
resolve_installation_path() {
    eval $invocation

    local install_dir=$1
    if [ "$install_dir" = "<auto>" ]; then
        local user_install_path="$(get_user_install_path)"
        say_verbose "resolve_installation_path: user_install_path=$user_install_path"
        echo "$user_install_path"
        return 0
    fi

    echo "$install_dir"
    return 0
}

# args:
# relative_or_absolute_path - $1
get_absolute_path() {
    eval $invocation

    local relative_or_absolute_path=$1
    echo "$(cd "$(dirname "$1")" && pwd -P)/$(basename "$1")"
    return 0
}

# args:
# override - $1 (boolean, true or false)
get_cp_options() {
    eval $invocation

    local override="$1"
    local override_switch=""

    if [ "$override" = false ]; then
        override_switch="-n"

        # create temporary files to check if 'cp -u' is supported
        tmp_dir="$(mktemp -d)"
        tmp_file="$tmp_dir/testfile"
        tmp_file2="$tmp_dir/testfile2"

        touch "$tmp_file"

        # use -u instead of -n if it's available
        if cp -u "$tmp_file" "$tmp_file2" 2>/dev/null; then
            override_switch="-u"
        fi

        # clean up
        rm -f "$tmp_file" "$tmp_file2"
        rm -rf "$tmp_dir"
    fi

    echo "$override_switch"
}

# args:
# input_files - stdin
# root_path - $1
# out_path - $2
# override - $3
copy_files_or_dirs_from_list() {
    eval $invocation

    local root_path="$(remove_trailing_slash "$1")"
    local out_path="$(remove_trailing_slash "$2")"
    local override="$3"
    local override_switch="$(get_cp_options "$override")"

    cat | uniq | while read -r file_path; do
        local path="$(remove_beginning_slash "${file_path#$root_path}")"
        local target="$out_path/$path"
        if [ "$override" = true ] || (! ([ -d "$target" ] || [ -e "$target" ])); then
            mkdir -p "$out_path/$(dirname "$path")"
            if [ -d "$target" ]; then
                rm -rf "$target"
            fi
            cp -R $override_switch "$root_path/$path" "$target"
        fi
    done
}

# args:
# zip_uri - $1
get_remote_file_size() {
    local zip_uri="$1"

    if machine_has "curl"; then
        file_size=$(curl -sI  "$zip_uri" | grep -i content-length | awk '{ num = $2 + 0; print num }')
    elif machine_has "wget"; then
        file_size=$(wget --spider --server-response -O /dev/null "$zip_uri" 2>&1 | grep -i 'Content-Length:' | awk '{ num = $2 + 0; print num }')
    else
        say "Neither curl nor wget is available on this system."
        return
    fi

    if [ -n "$file_size" ]; then
        say "Remote file $zip_uri size is $file_size bytes."
        echo "$file_size"
    else
        say_verbose "Content-Length header was not extracted for $zip_uri."
        echo ""
    fi
}

# args:
# zip_path - $1
# out_path - $2
# remote_file_size - $3
extract_dotnet_package() {
    eval $invocation

    local zip_path="$1"
    local out_path="$2"
    local remote_file_size="$3"

    local temp_out_path="$(mktemp -d "$temporary_file_template")"

    local failed=false
    tar -xzf "$zip_path" -C "$temp_out_path" > /dev/null || failed=true

    local folders_with_version_regex='^.*/[0-9]+\.[0-9]+[^/]+/'
    find "$temp_out_path" -type f | grep -Eo "$folders_with_version_regex" | sort | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" false
    find "$temp_out_path" -type f | grep -Ev "$folders_with_version_regex" | copy_files_or_dirs_from_list "$temp_out_path" "$out_path" "$override_non_versioned_files"
    
    validate_remote_local_file_sizes "$zip_path" "$remote_file_size"
    
    rm -rf "$temp_out_path"
    if [ -z ${keep_zip+x} ]; then
        rm -f "$zip_path" && say_verbose "Temporary archive file $zip_path was removed"
    fi

    if [ "$failed" = true ]; then
        say_err "Extraction failed"
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header()
{
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    local failed=false
    local response
    if machine_has "curl"; then
        get_http_header_curl $remote_path $disable_feed_credential || failed=true
    elif machine_has "wget"; then
        get_http_header_wget $remote_path $disable_feed_credential || failed=true
    else
        failed=true
    fi
    if [ "$failed" = true ]; then
        say_verbose "Failed to get HTTP header: '$remote_path'."
        return 1
    fi
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_curl() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    curl_options="-I -sSL --retry 5 --retry-delay 2 --connect-timeout 15 "
    curl $curl_options "$remote_path_with_credential" 2>&1 || return 1
    return 0
}

# args:
# remote_path - $1
# disable_feed_credential - $2
get_http_header_wget() {
    eval $invocation
    local remote_path="$1"
    local disable_feed_credential="$2"
    local wget_options="-q -S --spider --tries 5 "

    local wget_options_extra=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    remote_path_with_credential="$remote_path"
    if [ "$disable_feed_credential" = false ]; then
        remote_path_with_credential+="$feed_credential"
    fi

    wget $wget_options $wget_options_extra "$remote_path_with_credential" 2>&1

    return $?
}

# args:
# remote_path - $1
# [out_path] - $2 - stdout if not provided
download() {
    eval $invocation

    local remote_path="$1"
    local out_path="${2:-}"

    if [[ "$remote_path" != "http"* ]]; then
        cp "$remote_path" "$out_path"
        return $?
    fi

    local failed=false
    local attempts=0
    while [ $attempts -lt 3 ]; do
        attempts=$((attempts+1))
        failed=false
        if machine_has "curl"; then
            downloadcurl "$remote_path" "$out_path" || failed=true
        elif machine_has "wget"; then
            downloadwget "$remote_path" "$out_path" || failed=true
        else
            say_err "Missing dependency: neither curl nor wget was found."
            exit 1
        fi

        if [ "$failed" = false ] || [ $attempts -ge 3 ] || { [ -n "${http_code-}" ] && [ "${http_code}" = "404" ]; }; then
            break
        fi

        say "Download attempt #$attempts has failed: ${http_code-} ${download_error_msg-}"
        say "Attempt #$((attempts+1)) will start in $((attempts*10)) seconds."
        sleep $((attempts*10))
    done

    if [ "$failed" = true ]; then
        say_verbose "Download failed: $remote_path"
        return 1
    fi
    return 0
}

# Updates global variables $http_code and $download_error_msg
downloadcurl() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling curl to avoid logging feed_credential
    # Avoid passing URI with credentials to functions: note, most of them echoing parameters of invocation in verbose output.
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local curl_options="--retry 20 --retry-delay 2 --connect-timeout 15 -sSL -f --create-dirs "
    local curl_exit_code=0;
    if [ -z "$out_path" ]; then
        curl_output=$(curl $curl_options "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
        echo "$curl_output"
    else
        curl_output=$(curl $curl_options -o "$out_path" "$remote_path_with_credential" 2>&1)
        curl_exit_code=$?
    fi

    # Regression in curl causes curl with --retry to return a 0 exit code even when it fails to download a file - https://github.com/curl/curl/issues/17554
    if [ $curl_exit_code -eq 0 ] && echo "$curl_output" | grep -q "^curl: ([0-9]*) "; then
        curl_exit_code=$(echo "$curl_output" | sed 's/curl: (\([0-9]*\)).*/\1/')
    fi

    if [ $curl_exit_code -gt 0 ]; then
        download_error_msg="Unable to download $remote_path."
        # Check for curl timeout codes
        if [[ $curl_exit_code == 7 || $curl_exit_code == 28 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        else
            local disable_feed_credential=false
            local response=$(get_http_header_curl $remote_path $disable_feed_credential)
            http_code=$( echo "$response" | awk '/^HTTP/{print $2}' | tail -1 )
            if  [[ ! -z $http_code && $http_code != 2* ]]; then
                download_error_msg+=" Returned HTTP status code: $http_code."
            fi
        fi
        say_verbose "$download_error_msg"
        return 1
    fi
    return 0
}


# Updates global variables $http_code and $download_error_msg
downloadwget() {
    eval $invocation
    unset http_code
    unset download_error_msg
    local remote_path="$1"
    local out_path="${2:-}"
    # Append feed_credential as late as possible before calling wget to avoid logging feed_credential
    local remote_path_with_credential="${remote_path}${feed_credential}"
    local wget_options="--tries 20 "

    local wget_options_extra=''
    local wget_result=''

    # Test for options that aren't supported on all wget implementations.
    if [[ $(wget -h 2>&1 | grep -E 'waitretry|connect-timeout') ]]; then
        wget_options_extra="--waitretry 2 --connect-timeout 15 "
    else
        say "wget extra options are unavailable for this environment"
    fi

    if [ -z "$out_path" ]; then
        wget -q $wget_options $wget_options_extra -O - "$remote_path_with_credential" 2>&1
        wget_result=$?
    else
        wget $wget_options $wget_options_extra -O "$out_path" "$remote_path_with_credential" 2>&1
        wget_result=$?
    fi

    if [[ $wget_result != 0 ]]; then
        local disable_feed_credential=false
        local response=$(get_http_header_wget $remote_path $disable_feed_credential)
        http_code=$( echo "$response" | awk '/^  HTTP/{print $2}' | tail -1 )
        download_error_msg="Unable to download $remote_path."
        if  [[ ! -z $http_code && $http_code != 2* ]]; then
            download_error_msg+=" Returned HTTP status code: $http_code."
        # wget exit code 4 stands for network-issue
        elif [[ $wget_result == 4 ]]; then
            download_error_msg+=" Failed to reach the server: connection timeout."
        fi
        say_verbose "$download_error_msg"
        return 1
    fi

    return 0
}

get_download_link_from_aka_ms() {
    eval $invocation

    #quality is not supported for LTS or STS channel
    #STS maps to current
    if [[ ! -z "$normalized_quality"  && ("$normalized_channel" == "LTS" || "$normalized_channel" == "STS") ]]; then
        normalized_quality=""
        say_warning "Specifying quality for STS or LTS channel is not supported, the quality will be ignored."
    fi

    say_verbose "Retrieving primary payload URL from aka.ms for channel: '$normalized_channel', quality: '$normalized_quality', product: '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'." 

    #construct aka.ms link
    aka_ms_link="https://aka.ms/dotnet"
    if  [ "$internal" = true ]; then
        aka_ms_link="$aka_ms_link/internal"
    fi
    aka_ms_link="$aka_ms_link/$normalized_channel"
    if [[ ! -z "$normalized_quality" ]]; then
        aka_ms_link="$aka_ms_link/$normalized_quality"
    fi
    aka_ms_link="$aka_ms_link/$normalized_product-$normalized_os-$normalized_architecture.tar.gz"
    say_verbose "Constructed aka.ms link: '$aka_ms_link'."

    #get HTTP response
    #do not pass credentials as a part of the $aka_ms_link and do not apply credentials in the get_http_header function
    #otherwise the redirect link would have credentials as well
    #it would result in applying credentials twice to the resulting link and thus breaking it, and in echoing credentials to the output as a part of redirect link
    disable_feed_credential=true
    response="$(get_http_header $aka_ms_link $disable_feed_credential)"

    say_verbose "Received response: $response"
    # Get results of all the redirects.
    http_codes=$( echo "$response" | awk '$1 ~ /^HTTP/ {print $2}' )
    # Allow intermediate 301 redirects and tolerate proxy-injected 200s
    broken_redirects=$( echo "$http_codes" | sed '$d' | grep -vE '^(301|200)$' )
    # The response may end without final code 2xx/4xx/5xx somehow, e.g. network restrictions on www.bing.com causes redirecting to bing.com fails with connection refused.
    # In this case it should not exclude the last.
    last_http_code=$(  echo "$http_codes" | tail -n 1 )
    if ! [[ $last_http_code =~ ^(2|4|5)[0-9][0-9]$ ]]; then
        broken_redirects=$( echo "$http_codes" | grep -vE '^(301|200)$' )
    fi

    # All HTTP codes are 301 (Moved Permanently), the redirect link exists.
    if [[ -z "$broken_redirects" ]]; then
        aka_ms_download_link=$( echo "$response" | awk '$1 ~ /^Location/{print $2}' | tail -1 | tr -d '\r')

        if [[ -z "$aka_ms_download_link" ]]; then
            say_verbose "The aka.ms link '$aka_ms_link' is not valid: failed to get redirect location."
            return 1
        fi

        say_verbose "The redirect location retrieved: '$aka_ms_download_link'."
        return 0
    else
        say_verbose "The aka.ms link '$aka_ms_link' is not valid: received HTTP code: $(echo "$broken_redirects" | paste -sd "," -)."
        return 1
    fi
}

get_feeds_to_use()
{
    feeds=(
    "https://builds.dotnet.microsoft.com/dotnet"
    "https://ci.dot.net/public"
    )

    if [[ -n "$azure_feed" ]]; then
        feeds=("$azure_feed")
    fi

    if [[ -n "$uncached_feed" ]]; then
        feeds=("$uncached_feed")
    fi
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_download_links() {

    download_links=()
    specific_versions=()
    effective_versions=()
    link_types=()

    # If generate_akams_links returns false, no fallback to old links. Just terminate.
    # This function may also 'exit' (if the determined version is already installed).
    generate_akams_links || return

    # Check other feeds only if we haven't been able to find an aka.ms link.
    if [[ "${#download_links[@]}" -lt 1 ]]; then
        for feed in ${feeds[@]}
        do
            # generate_regular_links may also 'exit' (if the determined version is already installed).
            generate_regular_links $feed || return
        done
    fi

    if [[ "${#download_links[@]}" -eq 0 ]]; then
        say_err "Failed to resolve the exact version number."
        return 1
    fi

    say_verbose "Generated ${#download_links[@]} links."
    for link_index in ${!download_links[@]}
    do
        say_verbose "Link $link_index: ${link_types[$link_index]}, ${effective_versions[$link_index]}, ${download_links[$link_index]}"
    done
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed).
generate_akams_links() {
    local valid_aka_ms_link=true;

    normalized_version="$(to_lowercase "$version")"
    if [[ "$normalized_version" != "latest" ]] && [ -n "$normalized_quality" ]; then
        say_err "Quality and Version options are not allowed to be specified simultaneously. See https://learn.microsoft.com/dotnet/core/tools/dotnet-install-script#options for details."
        return 1
    fi

    if [[ -n "$json_file" || "$normalized_version" != "latest" ]]; then
        # aka.ms links are not needed when exact version is specified via command or json file
        return
    fi

    get_download_link_from_aka_ms || valid_aka_ms_link=false

    if [[ "$valid_aka_ms_link" == true ]]; then
        say_verbose "Retrieved primary payload URL from aka.ms link: '$aka_ms_download_link'."
        say_verbose "Downloading using legacy url will not be attempted."

        download_link=$aka_ms_download_link

        #get version from the path
        IFS='/'
        read -ra pathElems <<< "$download_link"
        count=${#pathElems[@]}
        specific_version="${pathElems[count-2]}"
        unset IFS;
        say_verbose "Version: '$specific_version'."

        #Retrieve effective version
        effective_version="$(get_specific_product_version "$azure_feed" "$specific_version" "$download_link")"

        # Add link info to arrays
        download_links+=($download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("aka.ms")

        #  Check if the SDK version is already installed.
        if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
            say "$asset_name with version '$effective_version' is already installed."
            exit 0
        fi

        return 0
    fi

    # if quality is specified - exit with error - there is no fallback approach
    if [ ! -z "$normalized_quality" ]; then
        say_err "Failed to locate the latest version in the channel '$normalized_channel' with '$normalized_quality' quality for '$normalized_product', os: '$normalized_os', architecture: '$normalized_architecture'."
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support."
        return 1
    fi
    say_verbose "Falling back to latest.version file approach."
}

# THIS FUNCTION MAY EXIT (if the determined version is already installed)
# args:
# feed - $1
generate_regular_links() {
    local feed="$1"
    local valid_legacy_download_link=true

    specific_version=$(get_specific_version_from_version "$feed" "$channel" "$normalized_architecture" "$version" "$json_file") || specific_version='0'

    if [[ "$specific_version" == '0' ]]; then
        say_verbose "Failed to resolve the specific version number using feed '$feed'"
        return
    fi

    effective_version="$(get_specific_product_version "$feed" "$specific_version")"
    say_verbose "specific_version=$specific_version"

    download_link="$(construct_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version" "$normalized_os")"
    say_verbose "Constructed primary named payload URL: $download_link"

    # Add link info to arrays
    download_links+=($download_link)
    specific_versions+=($specific_version)
    effective_versions+=($effective_version)
    link_types+=("primary")

    legacy_download_link="$(construct_legacy_download_link "$feed" "$channel" "$normalized_architecture" "$specific_version")" || valid_legacy_download_link=false

    if [ "$valid_legacy_download_link" = true ]; then
        say_verbose "Constructed legacy named payload URL: $legacy_download_link"
    
        download_links+=($legacy_download_link)
        specific_versions+=($specific_version)
        effective_versions+=($effective_version)
        link_types+=("legacy")
    else
        legacy_download_link=""
        say_verbose "Could not construct a legacy_download_link; omitting..."
    fi

    #  Check if the SDK version is already installed.
    if [[ "$dry_run" != true ]] && is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "$asset_name with version '$effective_version' is already installed."
        exit 0
    fi
}

print_dry_run() {

    say "Payload URLs:"

    for link_index in "${!download_links[@]}"
        do
            say "URL #$link_index - ${link_types[$link_index]}: ${download_links[$link_index]}"
    done

    resolved_version=${specific_versions[0]}
    repeatable_command="./$script_name --version "\""$resolved_version"\"" --install-dir "\""$install_root"\"" --architecture "\""$normalized_architecture"\"" --os "\""$normalized_os"\"""
    
    if [ ! -z "$normalized_quality" ]; then
        repeatable_command+=" --quality "\""$normalized_quality"\"""
    fi

    if [[ "$runtime" == "dotnet" ]]; then
        repeatable_command+=" --runtime "\""dotnet"\"""
    elif [[ "$runtime" == "aspnetcore" ]]; then
        repeatable_command+=" --runtime "\""aspnetcore"\"""
    fi

    repeatable_command+="$non_dynamic_parameters"

    if [ -n "$feed_credential" ]; then
        repeatable_command+=" --feed-credential "\""<feed_credential>"\"""
    fi

    say "Repeatable invocation: $repeatable_command"
}

calculate_vars() {
    eval $invocation

    script_name=$(basename "$0")
    normalized_architecture="$(get_normalized_architecture_from_architecture "$architecture")"
    say_verbose "Normalized architecture: '$normalized_architecture'."
    normalized_os="$(get_normalized_os "$user_defined_os")"
    say_verbose "Normalized OS: '$normalized_os'."
    normalized_quality="$(get_normalized_quality "$quality")"
    say_verbose "Normalized quality: '$normalized_quality'."
    normalized_channel="$(get_normalized_channel "$channel")"
    say_verbose "Normalized channel: '$normalized_channel'."
    normalized_product="$(get_normalized_product "$runtime")"
    say_verbose "Normalized product: '$normalized_product'."
    install_root="$(resolve_installation_path "$install_dir")"
    say_verbose "InstallRoot: '$install_root'."

    normalized_architecture="$(get_normalized_architecture_for_specific_sdk_version "$version" "$normalized_channel" "$normalized_architecture")"

    if [[ "$runtime" == "dotnet" ]]; then
        asset_relative_path="shared/Microsoft.NETCore.App"
        asset_name=".NET Core Runtime"
    elif [[ "$runtime" == "aspnetcore" ]]; then
        asset_relative_path="shared/Microsoft.AspNetCore.App"
        asset_name="ASP.NET Core Runtime"
    elif [ -z "$runtime" ]; then
        asset_relative_path="sdk"
        asset_name=".NET Core SDK"
    fi

    get_feeds_to_use
}

install_dotnet() {
    eval $invocation
    local download_failed=false
    local download_completed=false
    local remote_file_size=0

    mkdir -p "$install_root"
    zip_path="${zip_path:-$(mktemp "$temporary_file_template")}"
    say_verbose "Archive path: $zip_path"

    for link_index in "${!download_links[@]}"
    do
        download_link="${download_links[$link_index]}"
        specific_version="${specific_versions[$link_index]}"
        effective_version="${effective_versions[$link_index]}"
        link_type="${link_types[$link_index]}"

        say "Attempting to download using $link_type link $download_link"

        # The download function will set variables $http_code and $download_error_msg in case of failure.
        download_failed=false
        download "$download_link" "$zip_path" 2>&1 || download_failed=true

        if [ "$download_failed" = true ]; then
            case ${http_code-} in
            404)
                say "The resource at $link_type link '$download_link' is not available."
                ;;
            *)
                say "Failed to download $link_type link '$download_link': ${http_code-} ${download_error_msg-}"
                ;;
            esac
            rm -f "$zip_path" 2>&1 && say_verbose "Temporary archive file $zip_path was removed"
        else
            download_completed=true
            break
        fi
    done

    if [[ "$download_completed" == false ]]; then
        say_err "Could not find \`$asset_name\` with version = $specific_version"
        say_err "Refer to: https://aka.ms/dotnet-os-lifecycle for information on .NET Core support"
        return 1
    fi

    remote_file_size="$(get_remote_file_size "$download_link")"

    say "Extracting archive from $download_link"
    extract_dotnet_package "$zip_path" "$install_root" "$remote_file_size" || return 1

    #  Check if the SDK version is installed; if not, fail the installation.
    # if the version contains "RTM" or "servicing"; check if a 'release-type' SDK version is installed.
    if [[ $specific_version == *"rtm"* || $specific_version == *"servicing"* ]]; then
        IFS='-'
        read -ra verArr <<< "$specific_version"
        release_version="${verArr[0]}"
        unset IFS;
        say_verbose "Checking installation: version = $release_version"
        if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$release_version"; then
            say "Installed version is $effective_version"
            return 0
        fi
    fi

    #  Check if the standard SDK version is installed.
    say_verbose "Checking installation: version = $effective_version"
    if is_dotnet_package_installed "$install_root" "$asset_relative_path" "$effective_version"; then
        say "Installed version is $effective_version"
        return 0
    fi

    # Version verification failed. More likely something is wrong either with the downloaded content or with the verification algorithm.
    say_err "Failed to verify the version of installed \`$asset_name\`.\nInstallation source: $download_link.\nInstallation location: $install_root.\nReport the bug at https://github.com/dotnet/install-scripts/issues."
    say_err "\`$asset_name\` with version = $effective_version failed to install with an error."
    return 1
}

args=("$@")

local_version_file_relative_path="/.version"
bin_folder_relative_path=""
temporary_file_template="${TMPDIR:-/tmp}/dotnet.XXXXXXXXX"

channel="LTS"
version="Latest"
json_file=""
install_dir="<auto>"
architecture="<auto>"
dry_run=false
no_path=false
azure_feed=""
uncached_feed=""
feed_credential=""
verbose=false
runtime=""
runtime_id=""
quality=""
internal=false
override_non_versioned_files=true
non_dynamic_parameters=""
user_defined_os=""

while [ $# -ne 0 ]
do
    name="$1"
    case "$name" in
        -c|--channel|-[Cc]hannel)
            shift
            channel="$1"
            ;;
        -v|--version|-[Vv]ersion)
            shift
            version="$1"
            ;;
        -q|--quality|-[Qq]uality)
            shift
            quality="$1"
            ;;
        --internal|-[Ii]nternal)
            internal=true
            non_dynamic_parameters+=" $name"
            ;;
        -i|--install-dir|-[Ii]nstall[Dd]ir)
            shift
            install_dir="$1"
            ;;
        --arch|--architecture|-[Aa]rch|-[Aa]rchitecture)
            shift
            architecture="$1"
            ;;
        --os|-[Oo][SS])
            shift
            user_defined_os="$1"
            ;;
        --shared-runtime|-[Ss]hared[Rr]untime)
            say_warning "The --shared-runtime flag is obsolete and may be removed in a future version of this script. The recommended usage is to specify '--runtime dotnet'."
            if [ -z "$runtime" ]; then
                runtime="dotnet"
            fi
            ;;
        --runtime|-[Rr]untime)
            shift
            runtime="$1"
            if [[ "$runtime" != "dotnet" ]] && [[ "$runtime" != "aspnetcore" ]]; then
                say_err "Unsupported value for --runtime: '$1'. Valid values are 'dotnet' and 'aspnetcore'."
                if [[ "$runtime" == "windowsdesktop" ]]; then
                    say_err "WindowsDesktop archives are manufactured for Windows platforms only."
                fi
                exit 1
            fi
            ;;
        --dry-run|-[Dd]ry[Rr]un)
            dry_run=true
            ;;
        --no-path|-[Nn]o[Pp]ath)
            no_path=true
            non_dynamic_parameters+=" $name"
            ;;
        --verbose|-[Vv]erbose)
            verbose=true
            non_dynamic_parameters+=" $name"
            ;;
        --azure-feed|-[Aa]zure[Ff]eed)
            shift
            azure_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --uncached-feed|-[Uu]ncached[Ff]eed)
            shift
            uncached_feed="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            ;;
        --feed-credential|-[Ff]eed[Cc]redential)
            shift
            feed_credential="$1"
            #feed_credential should start with "?", for it to be added to the end of the link.
            #adding "?" at the beginning of the feed_credential if needed.
            [[ -z "$(echo $feed_credential)" ]] || [[ $feed_credential == \?* ]] || feed_credential="?$feed_credential"
            ;;
        --runtime-id|-[Rr]untime[Ii]d)
            shift
            runtime_id="$1"
            non_dynamic_parameters+=" $name "\""$1"\"""
            say_warning "Use of --runtime-id is obsolete and should be limited to the versions below 2.1. To override architecture, use --architecture option instead. To override OS, use --os option instead."
            ;;
        --jsonfile|-[Jj][Ss]on[Ff]ile)
            shift
            json_file="$1"
            ;;
        --skip-non-versioned-files|-[Ss]kip[Nn]on[Vv]ersioned[Ff]iles)
            override_non_versioned_files=false
            non_dynamic_parameters+=" $name"
            ;;
        --keep-zip|-[Kk]eep[Zz]ip)
            keep_zip=true
            non_dynamic_parameters+=" $name"
            ;;
        --zip-path|-[Zz]ip[Pp]ath)
            shift
            zip_path="$1"
            ;;
        -?|--?|-h|--help|-[Hh]elp)
            script_name="dotnet-install.sh"
            echo ".NET Tools Installer"
            echo "Usage:"
            echo "       # Install a .NET SDK of a given Quality from a given Channel"
            echo "       $script_name [-c|--channel <CHANNEL>] [-q|--quality <QUALITY>]"
            echo "       # Install a .NET SDK of a specific public version"
            echo "       $script_name [-v|--version <VERSION>]"
            echo "       $script_name -h|-?|--help"
            echo ""
            echo "$script_name is a simple command line interface for obtaining dotnet cli."
            echo "    Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
            echo "    - The SDK needs to be installed without user interaction and without admin rights."
            echo "    - The SDK installation doesn't need to persist across multiple CI runs."
            echo "    To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer."
            echo ""
            echo "Options:"
            echo "  -c,--channel <CHANNEL>         Download from the channel specified, Defaults to \`$channel\`."
            echo "      -Channel"
            echo "          Possible values:"
            echo "          - STS - the most recent Standard Term Support release"
            echo "          - LTS - the most recent Long Term Support release"
            echo "          - 2-part version in a format A.B - represents a specific release"
            echo "              examples: 2.0; 1.0"
            echo "          - 3-part version in a format A.B.Cxx - represents a specific SDK release"
            echo "              examples: 5.0.1xx, 5.0.2xx."
            echo "              Supported since 5.0 release"
            echo "          Warning: Value 'Current' is deprecated for the Channel parameter. Use 'STS' instead."
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used."
            echo "  -v,--version <VERSION>         Use specific VERSION, Defaults to \`$version\`."
            echo "      -Version"
            echo "          Possible values:"
            echo "          - latest - the latest build on specific channel"
            echo "          - 3-part version in a format A.B.C - represents specific version of build"
            echo "              examples: 2.0.0-preview2-006120; 1.1.0"
            echo "  -q,--quality <quality>         Download the latest build of specified quality in the channel."
            echo "      -Quality"
            echo "          The possible values are: daily, preview, GA."
            echo "          Works only in combination with channel. Not applicable for STS and LTS channels and will be ignored if those channels are used." 
            echo "          Supported since 5.0 release." 
            echo "          Note: The version parameter overrides the channel parameter when any version other than 'latest' is used, and therefore overrides the quality."
            echo "  --internal,-Internal               Download internal builds. Requires providing credentials via --feed-credential parameter."
            echo "  --feed-credential <FEEDCREDENTIAL> Token to access Azure feed. Used as a query string to append to the Azure feed."
            echo "      -FeedCredential                This parameter typically is not specified."
            echo "  -i,--install-dir <DIR>             Install under specified location (see Install Location below)"
            echo "      -InstallDir"
            echo "  --architecture <ARCHITECTURE>      Architecture of dotnet binaries to be installed, Defaults to \`$architecture\`."
            echo "      --arch,-Architecture,-Arch"
            echo "          Possible values: x64, arm, arm64, s390x, ppc64le and loongarch64"
            echo "  --os <system>                    Specifies operating system to be used when selecting the installer."
            echo "          Overrides the OS determination approach used by the script. Supported values: osx, linux, linux-musl, freebsd, rhel.6."
            echo "          In case any other value is provided, the platform will be determined by the script based on machine configuration."
            echo "          Not supported for legacy links. Use --runtime-id to specify platform for legacy links."
            echo "          Refer to: https://aka.ms/dotnet-os-lifecycle for more information."
            echo "  --runtime <RUNTIME>                Installs a shared runtime only, without the SDK."
            echo "      -Runtime"
            echo "          Possible values:"
            echo "          - dotnet     - the Microsoft.NETCore.App shared runtime"
            echo "          - aspnetcore - the Microsoft.AspNetCore.App shared runtime"
            echo "  --dry-run,-DryRun                  Do not perform installation. Display download link."
            echo "  --no-path, -NoPath                 Do not set PATH for the current process."
            echo "  --verbose,-Verbose                 Display diagnostics information."
            echo "  --azure-feed,-AzureFeed            For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --uncached-feed,-UncachedFeed      For internal use only."
            echo "                                     Allows using a different storage to download SDK archives from."
            echo "  --skip-non-versioned-files         Skips non-versioned files if they already exist, such as the dotnet executable."
            echo "      -SkipNonVersionedFiles"
            echo "  --jsonfile <JSONFILE>              Determines the SDK version from a user specified global.json file."
            echo "                                     Note: global.json must have a value for 'SDK:Version'"
            echo "  --keep-zip,-KeepZip                If set, downloaded file is kept."
            echo "  --zip-path, -ZipPath               If set, downloaded file is stored at the specified path."
            echo "  -?,--?,-h,--help,-Help             Shows this help message"
            echo ""
            echo "Install Location:"
            echo "  Location is chosen in following order:"
            echo "    - --install-dir option"
            echo "    - Environmental variable DOTNET_INSTALL_DIR"
            echo "    - $HOME/.dotnet"
            exit 0
            ;;
        *)
            say_err "Unknown argument \`$name\`"
            exit 1
            ;;
    esac

    shift
done

say_verbose "Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:"
say_verbose "- The SDK needs to be installed without user interaction and without admin rights."
say_verbose "- The SDK installation doesn't need to persist across multiple CI runs."
say_verbose "To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\n"

if [ "$internal" = true ] && [ -z "$(echo $feed_credential)" ]; then
    message="Provide credentials via --feed-credential parameter."
    if [ "$dry_run" = true ]; then
        say_warning "$message"
    else
        say_err "$message"
        exit 1
    fi
fi

check_min_reqs
calculate_vars
# generate_regular_links call below will 'exit' if the determined version is already installed.
generate_download_links

if [[ "$dry_run" = true ]]; then
    print_dry_run
    exit 0
fi

install_dotnet

bin_path="$(get_absolute_path "$(combine_paths "$install_root" "$bin_folder_relative_path")")"
if [ "$no_path" = false ]; then
    say "Adding to current process PATH: \`$bin_path\`. Note: This change will be visible only when sourcing script."
    export PATH="$bin_path":"$PATH"
else
    say "Binaries of dotnet can be found in $bin_path"
fi

say "Note that the script does not resolve dependencies during installation."
say "To check the list of dependencies, go to https://learn.microsoft.com/dotnet/core/install, select your operating system and check the \"Dependencies\" section."
say "Installation finished successfully."








































































================================================================================
FILE: llm/zzz-log-2026-02-12-21-38-45.txt
================================================================================
  __  __           _   _     _   ____    _       ____
 |  \/  |  _   _  | | | |_  (_) |  _ \  | |__   / ___|   _   _   _ __     ___
 | |\/| | | | | | | | | __| | | | | | | | '_ \  \___ \  | | | | | '_ \   / __|
 | |  | | | |_| | | | | |_  | | | |_| | | |_) |  ___) | | |_| | | | | | | (__
 |_|  |_|  \__,_| |_|  \__| |_| |____/  |_.__/  |____/   \__, | |_| |_|  \___|
                                                         |___/

\ Creating node1...
                   EF ENTITY: MultiDbSync.Domain.Entities.Customer
EF ENTITY: MultiDbSync.Domain.Entities.DatabaseNode
EF ENTITY: MultiDbSync.Domain.Entities.Order
EF ENTITY: MultiDbSync.Domain.Entities.OrderItem
âˆš Database nodes initialized successfully!

Automated CI/CD Demo - High Volume Data Operations


Creating 100 products ----------------------------------------   0% --:--:-- \
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ----------------------------------------   9% 00:00:00 |
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ----------------------------------------  38% 00:00:00 /
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ----------------------------------------  63% 00:00:00 -
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ----------------------------------------  88% 00:00:00 \
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00
                                                                              warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Creating 100 products ---------------------------------------- 100% 00:00:00

âˆš Created 100 products

â”Œâ”€Database Statisticsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚        Metric         â”‚       Value       â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚    Total Products     â”‚       33898       â”‚ â”‚
â”‚ â”‚   Total Stock Units   â”‚     8,442,387     â”‚ â”‚
â”‚ â”‚       Avg Price       â”‚     $1,011.55     â”‚ â”‚
â”‚ â”‚ Total Inventory Value â”‚ $8,510,947,438.19 â”‚ â”‚
â”‚ â”‚      Categories       â”‚         5         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Products by Category:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category    â”‚ Count â”‚ Total Value       â”‚ Avg Stock â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accessories â”‚ 6913  â”‚ $1,724,633,178.62 â”‚ 251       â”‚
â”‚ Software    â”‚ 6821  â”‚ $1,703,115,975.88 â”‚ 247       â”‚
â”‚ Electronics â”‚ 6759  â”‚ $1,694,702,966.96 â”‚ 247       â”‚
â”‚ Components  â”‚ 6730  â”‚ $1,684,619,698.62 â”‚ 248       â”‚
â”‚ Peripherals â”‚ 6675  â”‚ $1,703,875,618.11 â”‚ 253       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 3: Performing bulk stock updates...

Updating stock levels ----------------------------------------   0%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------   4%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------   6%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  10%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  12%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  16%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  20%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  22%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  26%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  30%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  32%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  36%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  40%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  42%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  46%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  50%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  52%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  56%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  57%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  62%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  66%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  68%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  72%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  74%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  78%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  82%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  84%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  86%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  90%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  92%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Updating stock levels ----------------------------------------  96%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ----------------------------------------  98%
                                                                   warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Updating stock levels ---------------------------------------- 100%

âˆš Updated 50 product stock levels

Phase 4: Adjusting prices...
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------   3%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  10%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  13%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  20%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  26%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  30%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  36%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  40%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  46%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  53%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  56%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  63%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  70%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  73%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  80%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  83%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
Applying price changes ----------------------------------------  86%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ----------------------------------------  93%
                                                                    warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization

Applying price changes ---------------------------------------- 100%

âˆš Updated 30 product prices

Phase 5: Removing discontinued products...
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
warn: MultiDbSync.Infrastructure.Services.SynchronizationService[0]
      No healthy nodes available for synchronization
âˆš Removed 5 discontinued products

â”Œâ”€Before & After Comparisonâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Metric         â”‚ Before    â”‚ After     â”‚ Change â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚ Total Products â”‚ 33898     â”‚ 33893     â”‚ -5     â”‚ â”‚
â”‚ â”‚ Total Stock    â”‚ 8,442,387 â”‚ 8,442,387 â”‚ +0     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Sample Products (Top 10 by Value):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Name                      â”‚ Category    â”‚ Price     â”‚ Stock â”‚ Value       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Budget Microphone 15585   â”‚ Components  â”‚ $1,985.39 â”‚ 499   â”‚ $990,709.61 â”‚
â”‚ Professional Laptop 8635  â”‚ Peripherals â”‚ $2,008.55 â”‚ 493   â”‚ $990,215.15 â”‚
â”‚ Compact Monitor 18661     â”‚ Electronics â”‚ $1,994.60 â”‚ 494   â”‚ $985,332.40 â”‚
â”‚ Professional Webcam 25113 â”‚ Electronics â”‚ $2,005.68 â”‚ 490   â”‚ $982,783.20 â”‚
â”‚ Gaming Keyboard 2777      â”‚ Components  â”‚ $1,996.38 â”‚ 492   â”‚ $982,218.96 â”‚
â”‚ Premium Keyboard 16087    â”‚ Peripherals â”‚ $1,995.17 â”‚ 492   â”‚ $981,623.64 â”‚
â”‚ Compact Cable 3209        â”‚ Electronics â”‚ $1,970.36 â”‚ 498   â”‚ $981,239.28 â”‚
â”‚ Gaming Microphone 18027   â”‚ Peripherals â”‚ $1,980.16 â”‚ 495   â”‚ $980,179.20 â”‚
â”‚ Ultra Headset 27093       â”‚ Software    â”‚ $2,005.62 â”‚ 488   â”‚ $978,742.56 â”‚
â”‚ Budget Microphone 18187   â”‚ Electronics â”‚ $1,996.94 â”‚ 490   â”‚ $978,500.60 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âˆš Automated demo completed successfully!
All operations logged and synchronized across nodes.

D:\DEV\personal\cqrstest\MultiDbSync\MultiDbSync.Console\bin\Debug\net10.0\MultiDbSync.Console.exe (process 6356) exited with code 0 (0x0).
To automatically close the console when debugging stops, enable Tools->Options->Debugging->Automatically close the console when debugging stops.
Press any key to close this window . . .




